[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Statistics",
    "section": "",
    "text": "Preface\nThis document is a set of course notes for several Applied Statistics courses at California State University, Chico. This is not a textbook replacement, and topics covered will vary depending on the instructor. To make this clear we use the term notebook to refer to this document so as not to be confused with a traditional textbook.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#data",
    "href": "index.html#data",
    "title": "Applied Statistics",
    "section": "Data",
    "text": "Data\nSome data and examples in this notebook are drawn from Practical Multivariate Analysis, 6th ed, Afifi, May, Donatello, Clark and used with permission by the authors. The data with corresponding codebooks can be downloaded from https://norcalbiostat.github.io/pma6_code/\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Applied Statistics",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nAnnabelle Feller (@annakfell)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "dataprep.html",
    "href": "dataprep.html",
    "title": "1  Workflow and Data Cleaning",
    "section": "",
    "text": "1.1 Reproducible workflows\nReproducibility is the ability for any researcher to take the same data set and run the same set of software program instructions as another researcher and achieve the same results.\nThe goal is to create an exact record of what was done to a data set to produce a specific result. To achieve reproducibility, we believe that three things must be present:",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#reproducible-workflows",
    "href": "dataprep.html#reproducible-workflows",
    "title": "1  Workflow and Data Cleaning",
    "section": "",
    "text": "The unprocessed data are connected directly to software code file(s) that perform data preparation techniques.\nThe processed data are connected directly to other software code file(s) that perform the analyses.\nAll data and code files are self-contained such that they could be given to another researcher to execute the code commands on a separate computer and achieve the same results as the original author.\n\n\n\n\n\n\n\n\nThink about it\n\n\n\nWhy do we need a codebook?\n\nYou are your own collaborator 6 months from now. Make sure you will be able to understand what you were doing.\nInvesting the time to do things clearly and in a reproducible manner will make your future self happy.\nComment your code with explanations and instructions.\n\nHow did you get from point A to B?\nWhy did you recode this variable in this manner?\n\nWe need to record those steps (not just for posterity).\nThis means your code must be saved in a script file.\n\nInclude sufficient notes to yourself describing what you are doing and why.\nFor R, this can be in a .R, .Rmd or .qmd file. I always prefer the latter.\nFor SAS you’ll use a .sas file\nFor STATA this will be a .do file\n\n\n\n\n\n\n\nFigure Credits: Roger Peng\n\n\n\n1.1.1 Literate programming\n\nProgramming paradigm introduced by Knuth (1984)\nExplain the logic of the program or analysis process in a natural language\nSmall code snippets included at each step act as a full set of instructions that can be executed to reproduce the result/analysis being discussed.\n\nLiterate programming tools are integrated into most common statistical packages, including:\n\nMarkdown (R, Stata), Quarto (R, Python, Julia, and JavaScript)\n\\(\\LaTeX\\) (R, SAS, Stata)\n\n\n\n\n\n\n\nLearn more\n\n\n\nThe current gold standard for writing reproducible literate documents in R is to use Quarto. Quarto documents can integrate code snippets from several languages and other code editing platforms, like Jupyter Notebook.\n\n\nPracticing reproducible research techniques using literate programming tools allows such major updates to be a simple matter of recompiling all coded instructions using the updated data set.\nThe effort then is reduced to a careful review and update of any written results.\nUsing literate programming tools, you can create formatted documents with\n\nsection headers\nbold and italicized words\ntables and graphics with built-in captions\n\nin a streamlined manner that is fully synchronized with the code itself.\nThe author writes the text explanations, interpretations, and code in the statistical software program itself, and the program will execute all commands and combine the text, code and output all together into a final dynamic document.\n\n\n\n\n\n\nThink about it\n\n\n\nWhat stages of the pipeline shown above can we conduct using literate programming tools?",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#import-data",
    "href": "dataprep.html#import-data",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.2 Import data",
    "text": "1.2 Import data\nThis section uses the raw depression data set from the Afifi et. al. textbook. This is a tab-delimited data set, so we opt to use read.table here. We include arguments sep=\"\\t\" to indicate columns are separated with tabs and header=TRUE to indicate the first row of the data is the variable names.\n\ndepress_raw &lt;- read.table(here::here(\"data/Depress.txt\"), \n                      sep=\"\\t\", header=TRUE)  \n\n\n\n\n\n\n\nLearn more\n\n\n\nSee R for Data Science (2e) for more instruction on importing different types of data and ways you can streamline your data import.\n\n\nThe absolute first thing you should do is to look at your raw data table. Are the column headers variable names? Did all the rows get read in? Are there any extra columns or rows included?",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#data-management",
    "href": "dataprep.html#data-management",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.3 Data management",
    "text": "1.3 Data management\nQuestions to ask yourself while reviewing the codebook to choose variables to be used in an analysis.\n\nAre there codes that indicate missing data? E.g. MISSING or -99?\nDo you need to make response codes more logical?\n\nSome systems will record 1=YES and 2=NO. This should be changed to 0=NO.\n\nDo you need to recode numerical variables to categorical?\n\nSometimes categorical data will be recorded as 1, 2, 3 etc. when those numbers represent named categories.\n\nDo you need to create secondary variables such as an average across measures to create a score?\nAre the variable names user-friendly? Mixtures of CAPS and lower case, names with spaces or special characters should all be changed.\n\nSome of these answers will come only after you look at your data. This can be looking at the raw data itself but also looking at tables and charts generated from the data. Often when you try to create a plot or table you will encounter an error or something odd looking that will be the notification that something has to be adjusted.\nThe next sections go over a few of the common data management processes, but is not comprehensive, and may only show one method for cleaning. There are always different ways to accomplish tasks.\n\n1.3.1 Renaming variable names for sanity’s sake\n\nhead(names(depress_raw))\n\n[1] \"ID\"      \"SEX\"     \"AGE\"     \"MARITAL\" \"EDUCAT\"  \"EMPLOY\" \n\n\nPeeking at the names of the variables we note that they are all in upper case. If that is fine with you, awesome. I prefer to have everything lower case so that I don’t ever have to remember which are the capital letters. Here are two ways to accomplish this:\n\nbasejanitor\n\n\nA base R solution is to use tolower() to turn all variable names to lower case. This code is not run here because it would overwrite the variable names in the same data set (depress_raw). Keep the imported (aka. “raw”) data untouched, and then make a copy of the data once you start making changes.\n\nnames(depress_raw) &lt;- tolower(names(depress_raw))\n\n\n\nA highly recommended method is to use the clean_names() function from the janitor package. This will also remove any special characters, spaces and capital letters from your variable names.\n\ndepress &lt;- depress_raw %&gt;% janitor::clean_names()\n\nI am “staging” the data set at this point because i’m making a major change away from the ‘raw’ data. So i’m saving the changes to the variable names in a new data set called depress.\n\n\n\n\n\n\nNote the use of :: between the package name janitor and the function within that package clean_names. This is a shortcut that allows you to use a function from a specific package without loading the entire package. This can also reduce in function name conflicts that we’ll mention below.\n\n\n\n\n\n\n\n\n1.3.2 Identifying variable types\n\nbasetidyverse\n\n\nThe str function is short for structure. This shows you the variable names, what data types R thinks each variable are, and some of the raw data.\n\nstr(depress)\n\n'data.frame':   294 obs. of  37 variables:\n $ id      : int  1 2 3 4 5 6 7 8 9 10 ...\n $ sex     : int  2 1 2 2 2 1 2 1 2 1 ...\n $ age     : int  68 58 45 50 33 24 58 22 47 30 ...\n $ marital : int  5 3 2 3 4 2 2 1 2 2 ...\n $ educat  : int  2 4 3 3 3 3 2 3 3 2 ...\n $ employ  : int  4 1 1 3 1 1 5 1 4 1 ...\n $ income  : int  4 15 28 9 35 11 11 9 23 35 ...\n $ relig   : int  1 1 1 1 1 1 1 1 2 4 ...\n $ c1      : int  0 0 0 0 0 0 2 0 0 0 ...\n $ c2      : int  0 0 0 0 0 0 1 1 1 0 ...\n $ c3      : int  0 1 0 0 0 0 1 2 1 0 ...\n $ c4      : int  0 0 0 0 0 0 2 0 0 0 ...\n $ c5      : int  0 0 1 1 0 0 1 2 0 0 ...\n $ c6      : int  0 0 0 1 0 0 0 1 3 0 ...\n $ c7      : int  0 0 0 0 0 0 0 0 0 0 ...\n $ c8      : int  0 0 0 3 3 0 2 0 0 0 ...\n $ c9      : int  0 0 0 0 3 1 2 0 0 0 ...\n $ c10     : int  0 0 0 0 0 0 0 0 0 0 ...\n $ c11     : int  0 0 0 0 0 0 0 0 0 0 ...\n $ c12     : int  0 1 0 0 0 1 0 0 3 0 ...\n $ c13     : int  0 0 0 0 0 2 0 0 0 0 ...\n $ c14     : int  0 0 1 0 0 0 0 0 3 0 ...\n $ c15     : int  0 1 1 0 0 0 3 0 2 0 ...\n $ c16     : int  0 0 1 0 0 2 0 1 3 0 ...\n $ c17     : int  0 1 0 0 0 1 0 1 0 0 ...\n $ c18     : int  0 0 0 0 0 0 0 1 0 0 ...\n $ c19     : int  0 0 0 0 0 0 0 1 0 0 ...\n $ c20     : int  0 0 0 0 0 0 1 0 0 0 ...\n $ cesd    : int  0 4 4 5 6 7 15 10 16 0 ...\n $ cases   : int  0 0 0 0 0 0 0 0 1 0 ...\n $ drink   : int  2 1 1 2 1 1 2 2 1 1 ...\n $ health  : int  2 1 2 1 1 1 3 1 4 1 ...\n $ regdoc  : int  1 1 1 1 1 1 1 2 1 1 ...\n $ treat   : int  1 1 1 2 1 1 1 2 1 2 ...\n $ beddays : int  0 0 0 0 1 0 0 0 1 0 ...\n $ acuteill: int  0 0 0 0 1 1 1 1 0 0 ...\n $ chronill: int  1 1 0 1 0 1 1 0 1 0 ...\n\n\nTo check the data type of just one variable, you have two options:\n\nThe typeof function\n\n\ntypeof(depress$marital)\n\n[1] \"integer\"\n\n\n\nThe class function\n\n\nclass(depress$age)\n\n[1] \"integer\"\n\n\n\n\nA tidyverse alternative is glimpse()\n\nglimpse(depress)\n\nRows: 294\nColumns: 37\n$ id       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ sex      &lt;int&gt; 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2…\n$ age      &lt;int&gt; 68, 58, 45, 50, 33, 24, 58, 22, 47, 30, 20, 57, 39, 61, 23, 2…\n$ marital  &lt;int&gt; 5, 3, 2, 3, 4, 2, 2, 1, 2, 2, 1, 2, 2, 5, 2, 1, 1, 4, 1, 5, 1…\n$ educat   &lt;int&gt; 2, 4, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 3, 3, 2, 4, 2, 6, 2, 3…\n$ employ   &lt;int&gt; 4, 1, 1, 3, 1, 1, 5, 1, 4, 1, 3, 2, 1, 4, 1, 1, 1, 3, 1, 4, 1…\n$ income   &lt;int&gt; 4, 15, 28, 9, 35, 11, 11, 9, 23, 35, 25, 24, 28, 13, 15, 6, 8…\n$ relig    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 2, 1, 1, 1, 1, 4, 2…\n$ c1       &lt;int&gt; 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 3, 1, 0, 0, 0…\n$ c2       &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 3, 0, 0, 0, 0…\n$ c3       &lt;int&gt; 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0…\n$ c4       &lt;int&gt; 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0…\n$ c5       &lt;int&gt; 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1, 3, 1, 0, 0, 0…\n$ c6       &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 1, 3, 0, 2, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0…\n$ c7       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0…\n$ c8       &lt;int&gt; 0, 0, 0, 3, 3, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 3, 0…\n$ c9       &lt;int&gt; 0, 0, 0, 0, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 3…\n$ c10      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0…\n$ c11      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0…\n$ c12      &lt;int&gt; 0, 1, 0, 0, 0, 1, 0, 0, 3, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 0, 0…\n$ c13      &lt;int&gt; 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0…\n$ c14      &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0…\n$ c15      &lt;int&gt; 0, 1, 1, 0, 0, 0, 3, 0, 2, 0, 1, 2, 0, 0, 1, 1, 3, 0, 0, 0, 0…\n$ c16      &lt;int&gt; 0, 0, 1, 0, 0, 2, 0, 1, 3, 0, 1, 2, 1, 0, 3, 1, 2, 0, 0, 0, 0…\n$ c17      &lt;int&gt; 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0…\n$ c18      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0…\n$ c19      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0…\n$ c20      &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 3, 0, 0, 0, 0…\n$ cesd     &lt;int&gt; 0, 4, 4, 5, 6, 7, 15, 10, 16, 0, 18, 4, 8, 4, 8, 21, 42, 6, 0…\n$ cases    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0…\n$ drink    &lt;int&gt; 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1…\n$ health   &lt;int&gt; 2, 1, 2, 1, 1, 1, 3, 1, 4, 1, 2, 2, 3, 1, 1, 3, 1, 3, 2, 2, 1…\n$ regdoc   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1…\n$ treat    &lt;int&gt; 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1…\n$ beddays  &lt;int&gt; 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0…\n$ acuteill &lt;int&gt; 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0…\n$ chronill &lt;int&gt; 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1…\n\n\n\n\n\nRight away this tells me that R thinks all variables are numeric integers, not categorical variables. Many of these will have to be changed. We’ll get to that in a moment.\n\n\n1.3.3 Convert number to factor\nWhen variables have numerical levels it is necessary to ensure that the program knows it is a factor variable.\nThe following code uses the factor() function to take the marital status variable and convert it into a factor variable with specified labels that match the codebook.\n\ndepress$marital &lt;- factor(depress$marital, \n      labels = c(\"Never Married\", \"Married\", \"Divorced\", \"Separated\", \"Widowed\"))\n\nNote that I am not making a new variable here, but overwriting the same marital variable. If If it did not you will have to re-run the lread in the raw data set again since the variable marital was replaced.\nIt is important to confirm the recode worked. I do this by creating a two-way table between the variable as it exists on the raw data, and how it exists after this line of code. What we are looking for is that all values on the left/rows (original version) line up with what we want them to say on the right (new version), and that no missing data was created or destroyed.\n\ntable(depress_raw$MARITAL, depress$marital, useNA = \"always\")\n\n      \n       Never Married Married Divorced Separated Widowed &lt;NA&gt;\n  1               73       0        0         0       0    0\n  2                0     127        0         0       0    0\n  3                0       0       43         0       0    0\n  4                0       0        0        13       0    0\n  5                0       0        0         0      38    0\n  &lt;NA&gt;             0       0        0         0       0    0\n\n\n\n\n\n\n\n\nLearn more\n\n\n\nSee more examples on Math 130 Lesson 06\n\n\n\n\n1.3.4 Identifying outliers\nLet’s look at the age variable in the depression data set.\n\npar(mfrow=c(1,2))\nboxplot(depress$age)\nhist(depress$age)\n\n\n\n\n\n\n\n\nJust looking at the data graphically raises no red flags. The boxplot shows no outlying values and the histogram does not look wildly skewed. This is where knowledge about the data set is essential. The codebook does not provide a valid range for the data, but the description of the data starting on page 3 in the textbook clarifies that this data set is on adults. In the research world, this specifies 18 years or older.\nNow look back at the graphics. See anything odd? It appears as if the data go pretty far below 20, possibly below 18. Let’s check the numerical summary to get more details.\n\nsummary(depress$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   28.00   42.50   44.38   59.00   89.00 \n\n\nThe minimum value is a 9, which is outside the range of valid values for this variable. This is where you, as a statistician, data analyst or researcher goes back to the PI and asks for advice. Should this data be set to missing, or edited in a way that changes this data point into a valid piece of data?\nAnother example\n\nboxplot(depress$income)\n\n\n\n\n\n\n\n\nWhile there is at least one potential outliers (denoted by the dots), there are none so far away from the rest of the group (or at values such as 99 or -99 that may indicate missing codes) that we need to be concerned about.\n\n\n1.3.5 Changing numeric values\nWhat you didn’t know until now, is that for demonstration purposes I went in and changed a 19 to a 9. So the correct thing to do here is to change that 9, back to a 19.\n\nifelse()direct assign\n\n\nThis is a very good use of the ifelse() function.\n\ndepress$age &lt;- ifelse(depress$age==9, 19, depress$age)\n\nThe logical statement is depress$age9. Wherever this is true, replace the value of depress$age with 19, and wherever this is false keep the value of depress$age unchanged (by “replacing” the new value with the same old value).\n\n\nAlternatively, you can change that one value using bracket notation. Here you are specifying that you only want the rows where age==9, and directly assign a value of 19 to those rows.\n\ndepress$age[depress$age==9] &lt;- 19\n\nConfirm the recode.\n\nsummary(depress$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   28.00   42.50   44.41   59.00   89.00 \n\n\nLooks like it worked.\n\n\n\n\n\n1.3.6 Creating secondary variables\n\n\n1.3.7 Create a binary indicator\nFor analysis purposes you may need to have a numeric binary indicator (0/1) of a variable.\n\ntable(addhealth$eversmoke_c)\n\n\nNon Smoker     Smoker \n      1773       3324 \n\naddhealth$smoker &lt;- ifelse(addhealth$eversmoke_c==\"Smoker\", 1, 0)\ntable(addhealth$eversmoke_c, addhealth$smoker, useNA=\"always\")\n\n            \n                0    1 &lt;NA&gt;\n  Non Smoker 1773    0    0\n  Smoker        0 3324    0\n  &lt;NA&gt;          0    0 1407\n\n\n\n\n\n\n\n\nLearn more\n\n\n\nSee Math 130 lesson 05 for now.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#wrangling-factors",
    "href": "dataprep.html#wrangling-factors",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.4 Wrangling factors",
    "text": "1.4 Wrangling factors\n\n\n\n\n\n\nLearn more\n\n\n\nFor more help on renaming, releveling, lumping, and removing levels see Math 130 lesson 06 for now. Also the forcats vignette.\n\n\n\n1.4.1 Collapsing categorical variables into fewer categories\nFor unbiased and accurate results of a statistical analysis, sufficient data has to be present. Often times once you start slicing and dicing the data to only look at certain groups, or if you are interested in the behavior of certain variables across levels of another variable, sometimes you start to run into small sample size problems.\nFor example, consider marital status again. There are only 13 people who report being separated. This could potentially be too small of a group size for valid statistical analysis. One way to deal with insufficient data within a certain category is to collapse categories.\n\n\n\n\n\n\nNote\n\n\n\nNote I am choosing to ‘stage’ my data here. So if I mess something up in this section, I don’t have to re-read in the raw data again or go back and rerun ALL the code, but just up until depress1 is created.\n\n\n\ndepress1 &lt;- depress\n\n\ncarforcats\n\n\nThe following example code uses the recode() function from the car package to create a new variable that I am calling marital2 that combines the Divorced and Separated levels.\n\ndepress1$marital &lt;- car::recode(depress1$marital, \"'Divorced' = 'Sep/Div'; 'Separated' = 'Sep/Div'\")\n\n\n\n\n\n\n\nNote the use of the :: again. Here it is even more important to use this shortcut because the specific recode function we want to use comes from the car package. There are other packages (probably dplyr) that also have a function called recode. So here I use :: as a way to be SUPER EXPLICIT on which function I want to use.\n\n\n\nAlways confirm your recodes. Check a table of the old variable (depress$marital) against the new one depress1$marital.\n\ntable(depress$marital, depress1$marital , useNA=\"always\")\n\n               \n                Married Never Married Sep/Div Widowed &lt;NA&gt;\n  Never Married       0            73       0       0    0\n  Married           127             0       0       0    0\n  Divorced            0             0      43       0    0\n  Separated           0             0      13       0    0\n  Widowed             0             0       0      38    0\n  &lt;NA&gt;                0             0       0       0    0\n\n\nThis confirms that records where depress$marital (rows) is Divorced or Separated have the value of Sep/Div for depress1$marital (columns). And that no missing data crept up in the process.\n\n\nThe fct_collapse() function from the forcats package can do the same process, without worrying about a package/function conflict.\n\ndepress1$marital &lt;- fct_collapse(depress$marital, SepDiv = c(\"Divorced\", \"Separated\"))\n\nAgain, you should always confirm your recodes. Check a table of the old variable (depress$marital) against the new one depress1$marital\n\ntable(depress$marital, depress1$marital , useNA=\"always\")\n\n               \n                Never Married Married SepDiv Widowed &lt;NA&gt;\n  Never Married            73       0      0       0    0\n  Married                   0     127      0       0    0\n  Divorced                  0       0     43       0    0\n  Separated                 0       0     13       0    0\n  Widowed                   0       0      0      38    0\n  &lt;NA&gt;                      0       0      0       0    0\n\n\n\n\n\n\n\n1.4.2 Binning a continuous variable into categorical ranges.\nWe can use the cut function to create a new variable that categorizes income into the following ranges: &lt;30, [30, 40), [40,50), [50, 60), 60+.\n\ndepress1$inc_cut &lt;- cut(depress1$income, breaks=c(0, 30,40,50,60, 100))\ntable(depress1$inc_cut)\n\n\n  (0,30]  (30,40]  (40,50]  (50,60] (60,100] \n     231       28       16        9       10 \n\n\n\n\n1.4.3 Dichotomizing a measure into 2 categories\nDichotomous variables tend to be binary indicator variables where a code of 1 is the level you’re interested in.\n\nExample 1Example 2\n\n\n\n\n\n\n\n\n\nSwitch example from binary gender to different characteristic\n\n\n\n\nIn this study gender is coded as 2=Female and 1=Male. (This data was collected in the ’70s, and so only two genders were provided as options). We want to convert this be a binary indicator of female, where 1=Female and 0=Male.\n\ndepress1$female &lt;- depress1$sex -1 \ntable(depress1$female)\n\n\n  0   1 \n111 183 \n\n\n0/1 binary coding is mandatory for many analyses. One simple reason is that now you can calculate the mean and interpret it as a proportion.\n\nmean(depress1$female)\n\n[1] 0.622449\n\n\n62% of individuals in this data set are female.\n\n\nSometimes the data is recorded as 1/2 (Yes/No), so just subtracting from 1 doesn’t create a positive indicator of the variable. For example, drink=1 if they are a regular drinker, and drink=2 if they are not. We want not drinking to be coded as 0, not 2.\n\ntable(depress_raw$DRINK)\n\n\n  1   2 \n234  60 \n\n\nThe ifelse() function says that if depress$drink has a value equal to 2 ==2, then change the value to 0. Otherwise leave it alone.\n\ndepress1$drink &lt;- ifelse(depress1$drink==2, 0, depress1$drink)\ntable(depress1$drink, depress$drink)\n\n   \n      1   2\n  0   0  60\n  1 234   0",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#combining-values-across-multiple-variables",
    "href": "dataprep.html#combining-values-across-multiple-variables",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.5 Combining values across multiple variables",
    "text": "1.5 Combining values across multiple variables\nLet’s stage the data again for this section.\n\ndepress2 &lt;- depress1\n\n\n1.5.1 Row-wise sum or average\nThe Center for Epidemiological Studies Depression Scale (CESD) is series of questions asked to a person to measure their level of depression. CESD is calculated as the sum of all 20 component variables, and is already on this data set. Let’s create a new variable named sleep as subscale for sleep quality by adding up question numbers 5, 11, and 19.\nReference: CESD-R\n\nBasemutate + manual\n\n\n\ndepress2$sleep &lt;- depress2$c5 + depress2$c11 + depress2$c19\n\nI’ll confirm it works by looking at a few rows and making sure they all add up.\n\nhead(depress2[c('c5', 'c11', 'c19', 'sleep')])\n\n  c5 c11 c19 sleep\n1  0   0   0     0\n2  0   0   0     0\n3  1   0   0     1\n4  1   0   0     1\n5  0   0   0     0\n6  0   0   0     0\n\n\n\n\n\ndepress2 &lt;- depress %&gt;% mutate(sleep = c5+c11+c19)\nhead(depress2[c('c5', 'c11', 'c19', 'sleep')])\n\n  c5 c11 c19 sleep\n1  0   0   0     0\n2  0   0   0     0\n3  1   0   0     1\n4  1   0   0     1\n5  0   0   0     0\n6  0   0   0     0",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#assessing-normality",
    "href": "dataprep.html#assessing-normality",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.6 Assessing Normality",
    "text": "1.6 Assessing Normality\n\n1.6.1 Histogram and density plots\n\nhist(depress2$income, prob=TRUE, xlab=\"Annual income (in thousands)\", \n     main=\"Histogram and Density curve of Income\", ylab=\"\")\nlines(density(depress2$income), col=\"blue\")\n\n\n\n\n\n\n\nsummary(depress2$income)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.00    9.00   15.00   20.57   28.00   65.00 \n\n\nThe distribution of annual income is slightly skewed right with a mean of $20.5k per year and a median of $15k per year income. The range of values goes from $2k to $65k. Reported income above $40k appear to have been rounded to the nearest $10k, because there are noticeable peaks at $40k, $50k, and $60k.\n\n\n1.6.2 Q-Q plot\nAnother common method of assessing normality is to create a normal probability (or normal quantile) plot.\n\nqqnorm(depress2$income);qqline(depress2$income, col=\"red\")\n\n\n\n\n\n\n\n\nThe points on the normal probability plot do not follow the red reference line very well. The dots show a more curved, or U shaped form rather than following a linear line. This is another indication that the data is skewed and a transformation for normality should be created.\n\n\n1.6.3 Transformations\nAs a demonstration of transformations that can be used to shift a distribution more towards a normal shape, here we create three new variables: log10inc as the log base 10 of Income, loginc as the natural log of Income, and xincome which is equal to the negative of one divided by the cubic root of income.\n\nlog10inc &lt;- log10(depress2$income)\nloginc   &lt;- log(depress2$income)\nxincome  &lt;- -1/(depress2$income)^(-1/3)\n\nCreate a single plot that display normal probability plots for the original, and each of the three transformations of income. Use the base graphics grid organizer par(mfrow=c(r,c)) where r is the number of rows and c is the number of columns. Which transformation does a better job of normalizing the distribution of Income?\n\npar(mfrow=c(2,2)) # Try (4,1) and (1,4) to see how this works. \nqqnorm(depress2$income, main=\"Income\"); qqline(depress2$income,col=\"blue\")\nqqnorm(log10inc, main=\"Log 10\"); qqline(log10inc, col=\"blue\")\nqqnorm(loginc, main = \"Natural Log\"); qqline(loginc, col=\"blue\")\nqqnorm(xincome, main=\"-1/cuberoot(income)\"); qqline(xincome, col=\"blue\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo transform or not to transform\n\n\n\nIn general, transformations are more effective when the the standard deviation is large relative to the mean. One rule of thumb is if the sd/mean ratio is less than 1/4, a transformation may not be necessary.\n\nsd(depress2$income) / mean(depress2$income)\n\n[1] 0.743147\n\n\nAlternatively Hoaglin, Mosteller and Tukey (1985) showed that if the largest observation divided by the smallest observation is over 2, then the data may not be sufficiently variable for the transformation to be decisive.\n\nmax(depress2$income) / (min(depress2$income)+.1)\n\n[1] 30.95238\n\n\nNote that these rules are not meaningful for data without a natural zero.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#missing-data",
    "href": "dataprep.html#missing-data",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.7 Missing data",
    "text": "1.7 Missing data\n\n1.7.1 Identifying missing data\nIn Excel, missing data can show up as a blank cell. R displays missing data as NA values.\nWhy would data be missing? Other than the obvious data entry errors, tech glitches or just non-cooperative plants or people, sometimes values are out of range and you would rather delete them than change their value (data edit).\n\nCategoricalContinuous\n\n\nLets look at the religion variable in the depression data set.\n\ntable(depress2$relig, useNA=\"always\")\n\n\n   1    2    3    4    6 &lt;NA&gt; \n 155   51   30   56    2    0 \n\n\nLooking at the codebook, there is no category 6 for religion. Let’s change all values to NA.\n\ndepress2$relig[depress2$relig==6] &lt;- NA\n\nThis code says take all rows where relig is equal to 6, and change them to NA.\nConfirm recode.\n\ntable(depress2$relig, useNA=\"always\")\n\n\n   1    2    3    4 &lt;NA&gt; \n 155   51   30   56    2 \n\n\nNotice the use of the useNA=\"always\" argument. If we just looked at the base table without this argument, we would have never known there was missing data!\n\ntable(depress2$relig)\n\n\n  1   2   3   4 \n155  51  30  56 \n\n\n\n\nWhat about continuous variables? Well there happens to be no other missing data in this data set, so let’s make up a set of 7 data points stored in a variable named y.\n\ny &lt;- c(1, 2, 3, NA, 4, NA, 6)\ny\n\n[1]  1  2  3 NA  4 NA  6\n\n\nThe #1 way to identify missing data in a continuous variable is by looking at the summary() values.\n\nmean(y)\n\n[1] NA\n\nsummary(y)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n    1.0     2.0     3.0     3.2     4.0     6.0       2 \n\nmean(y, na.rm=TRUE)\n\n[1] 3.2\n\n\nIn R, any arithmetic function (like addition, multiplication) on missing data results in a missing value. The na.rm=TRUE toggle tells R to calculate the complete case mean. This is a biased measure of the mean, but missing data is a topic worthy of it’s own course and is introduced in Chapter 12.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#export-and-save",
    "href": "dataprep.html#export-and-save",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.8 Export and save",
    "text": "1.8 Export and save\nYou’ve just made a ton of changes!\n\nSave or export the new data set to your computer.\nEdit the codebook to reflect the changes that you made.\nKeep the data, codebook and data management file in the same folder.\n\n\ndepress_clean &lt;- depress2\n\n# Save as a .Rdata file for later use in R\nsave(depress_clean, file = \"data/depress_clean.Rdata\") \n\nNow every time you run your data cleaning script file, it will make all the changes and save/overwrite the depress_clean.Rdata data file. This ensures that any analysis script that uses this data has the most up to date variables.\nWe can use dplyr::select to select and save individual variables without storing the entire data frame.\n\nout &lt;- depress %&gt;% select(list of variables)\nsave(out, \"data/var1.Rdata\")\n\n\n\n\n\n\n\nLearn more\n\n\n\nNeed to export to a different software program? Look into the haven package.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#wide-long",
    "href": "dataprep.html#wide-long",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.9 Wide vs. long data",
    "text": "1.9 Wide vs. long data\nThe data on Lung function originally was recorded in wide format, with separate variables for mother’s and father’s FEV1 score (MFEV1 and FFEV). In this format, the data is one record per family.\n\nfev &lt;- read.delim(here::here(\"data/Lung.txt\"), sep=\"\\t\", header=TRUE)\nhead(fev[,1:15])\n\n  ID AREA FSEX FAGE FHEIGHT FWEIGHT FFVC FFEV1 MSEX MAGE MHEIGHT MWEIGHT MFVC\n1  1    1    1   53      61     161  391  3.23    2   43      62     136  370\n2  2    1    1   40      72     198  441  3.95    2   38      66     160  411\n3  3    1    1   26      69     210  445  3.47    2   27      59     114  309\n4  4    1    1   34      68     187  433  3.74    2   36      58     123  265\n5  5    1    1   46      61     121  354  2.90    2   39      62     128  245\n6  6    1    1   44      72     153  610  4.91    2   36      66     125  349\n  MFEV1 OCSEX\n1  3.31     2\n2  3.47     1\n3  2.65     1\n4  2.06     2\n5  2.33     1\n6  3.06     1\n\n\nTo analyze the effect of gender on FEV, the data need to be in long format, with a single variable for fev and a separate variable for gender. The following code chunk demonstrates one method of combining data on height, gender, age and FEV1 for both males and females.\n\nfev2 &lt;- data.frame(gender = c(fev$FSEX, fev$MSEX), \n                   rev = c(fev$FFEV1, fev$MFEV1), \n                   ht = c(fev$FHEIGHT, fev$MHEIGHT), \n                   age = c(fev$FAGE, fev$MAGE))\nfev2$gender &lt;- factor(fev2$gender, labels=c(\"M\", \"F\"))\nhead(fev2)  \n\n  gender  rev ht age\n1      M 3.23 61  53\n2      M 3.95 72  40\n3      M 3.47 69  26\n4      M 3.74 68  34\n5      M 2.90 61  46\n6      M 4.91 72  44\n\n\nNearly all analysis procedures and most graphing procedures require the data to be in long format. There are several R packages that can help with this including reshape2 and tidyr.\n\n\n\n\n\n\nLearn more\n\n\n\nRead more on tidy data in R for Data Science 2e, or look into the mice package vignettes.\n\n\n\n1.9.1 Model predictions\nSituation: You want to add model predictions to the data set, but you have missing data that was automatically dropped prior to analysis.\n\n\n\n\n\n\nWarning\n\n\n\n\nAdd methods for dealing with this, once added reference Chapter 12\n\n\n\nR objects created by methods such as lm and glm will store the data used in the model in the model object itself in model$data.\n\n\n1.9.2 Factor analysis and principal components\nIf your original data had missing values, here are two methods to get the PC’s / factor scores for available data back onto the data set.\n\nMethod 1Method 2\n\n\nCreate an ID column and merge new variables onto original data. (add columns)\n\nIf no ID column exists, create one on the original dataset id = 1:NROW(data)\nUse select() to extract the ID and all variables used in the factor analysis, then do a na.omit() to drop rows with any missing data. Save this as a new complete case data set.\nConduct PCA / Factor analysis on this new complete case data set (MINUS THE ID). Extract the PCs or factor scores.\nUse bind_cols() to add the ID variable to the data containing factor scores.\nThen left_join(original_data, factor_score_data) the factor scores back to the original data, using the ID variable as the joining key.\n\n\n\nSplit the data, analyze one part then concatenate back together. (add rows)\n\nUse the complete.cases() function to create a boolean vector for if each row is complete\nSplit the data into complete and incomplete.\nDo the analysis on the complete rows, extracting the PC’s/Factors\nAdd the PC/Factor data onto the complete rows using bind_cols\nThen bind_rows the two parts back together.\n\n\ncc.idx &lt;- hiv %&gt;% select(starts_with(\"pb\")) %&gt;% complete.cases() # 1\n\ncomplete.rows &lt;- hiv[cc.idx,] #2\nincomplete.rows &lt;- hiv[!cc.idx,]\n\npc.scores &lt;- princomp(pb)$scores #3 \n\ncomplete.add.pc &lt;- bind_cols(complete.rows, pc.scores) #4\n\nhiv.with.pcs &lt;- bind_rows(complete.add.pc, incomplete.rows) #5",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "data_viz.html",
    "href": "data_viz.html",
    "title": "2  Visualizing Data",
    "section": "",
    "text": "2.1 Choosing your audience\nThe level of detail you put into your graphs/tables will depend on who the graph/table is for. In general, you will be visualizing data for three audience types: yourself and/or your data management team, an internal audience (other specialties within your organization, research coordinators), and external, professional audiences. The tabs below describe the three audience types and show an example graph for each.\nWho is your audience?",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#choosing-your-audience",
    "href": "data_viz.html#choosing-your-audience",
    "title": "2  Visualizing Data",
    "section": "",
    "text": "YourselfInternal AudienceProfessional\n\n\nGraphs/tables for yourself and/or your working team can be “quick and dirty.” These graphs are for getting a quick look at the data and are meant for people who are already familiar with the data.\n\n\nShow the code\nplot_frq(pen$island)\n\n\n\n\n\n\n\n\n\n\n\nWhen presenting for an audience with some familiarity with the project and the data analysis process, your graphs don’t have to be completely perfect, but they should be fairly polished and be understandable. A good rule of thumb for these graphs is if they were to end up being published as-is without your knowledge, you wouldn’t be completely embarrassed to see them in print.\n\n\nShow the code\nplot_frq(pen$island, title = \"Count of Penguins by Island\") +\n        xlab(\"Island\") +\n        theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nProfessional quality graphs and tables have the highest amount of detail and take the most amount of time to make. They should be able to be interpreted by people not familiar with the project or data analysis, even without reading the rest of the report.\n\n\nShow the code\nplot_frq(pen$island, title = \"Count of Penguins by Island\") +\n          labs(subtitle = \"Includes penguins of Adelie, Gentoo, and Chinstrap species\") +\n          xlab(\"Island\") +\n          ylab(\"Penguin Count\") + \n          theme_minimal()",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#the-data",
    "href": "data_viz.html#the-data",
    "title": "2  Visualizing Data",
    "section": "2.2 The Data",
    "text": "2.2 The Data\nWe will use the penguins dataset that comes with the palmerpenguins package. This dataset contains size measurements for three penguin species observed on three islands in the Palmer Archipelago, Antarctica. Review ?penguins to learn about the variables we will be using.\n\npen &lt;- palmerpenguins::penguins\n\n\n\n\n\n\n\n\n[RAD] write a paragraph here about how this section is organized.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#one-categorical-variable",
    "href": "data_viz.html#one-categorical-variable",
    "title": "2  Visualizing Data",
    "section": "2.3 One Categorical Variable",
    "text": "2.3 One Categorical Variable\nBoth Nominal and Ordinal data types can be visualized using the same methods: tables, barcharts and pie charts.\n\n2.3.1 Tables\nFrequency and proportion (relative frequency) tables are the most common way to get summary statistics of a categorical variable.\n\nbasegtsummary\n\n\nThe table() function produces a frequency table, where each entry represents the number of records in the data set holding the corresponding labeled value.\n\ntable(pen$species)\n\n\n   Adelie Chinstrap    Gentoo \n      152        68       124 \n\n\nThere are 152 Adelie penguins, 68 Chinstrap penguins, and 124 Gentoo penguins in this dataset.\n\n\n\n\n\n\n\n\n\nRobin add text here.\n\nbrief explanation of how it works. Defaults to creating a summary table of the entire data set, so you have to pre-select out only the variables you want to get a summary of. Direct link to function tbl_summary\n\n\n\n\npen |&gt; select(species) |&gt; tbl_summary()\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 3441\n\n\n\n\nspecies\n\n\n\n\n    Adelie\n152 (44%)\n\n\n    Chinstrap\n68 (20%)\n\n\n    Gentoo\n124 (36%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\npen |&gt; select(species, island) |&gt; tbl_summary()\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 3441\n\n\n\n\nspecies\n\n\n\n\n    Adelie\n152 (44%)\n\n\n    Chinstrap\n68 (20%)\n\n\n    Gentoo\n124 (36%)\n\n\nisland\n\n\n\n\n    Biscoe\n168 (49%)\n\n\n    Dream\n124 (36%)\n\n\n    Torgersen\n52 (15%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\nThis can be advantageous if you want to have a single table showing the frequency distribution of multiple variables.\n\n\n\n\n\n2.3.2 Frequency Barcharts / Barplots\n\n\n\n\n\n\n\nadjust explanatory text here\n\n\n\n\nA Barchart or barplot takes these frequencies, and draws bars along the X-axis where the height of the bars is determined by the frequencies seen in the table.\n\nbaseggplotsjPlot\n\n\nTo create a barplot/barchart in base graphics requires the data to be in summarized in a table form first. Then the result of the table is plotted. The first argument is the table to be plotted, the main argument controls the title.\n\nps &lt;- table(pen$species)\nbarplot(ps, main=\"Barchart using base graphics\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnote yaxis direction and no labels at top of bar\n\n\n\n\n\n\nThe geometry needed to draw a barchart in ggplot is geom_bar().\n\nggplot(pen, aes(x=species)) + geom_bar()\n\n\n\n\n\n\n\n\nAdding Annotation\nThe biggest addition to increase the readability of a barchart is to add the frequencies on top of the bars.\n\nggplot(pen, aes(x=species)) + theme_bw() + \n    geom_bar(aes(y = ..count..)) + ggtitle(\"Frequency of penguins by species\") + \n    geom_text(aes(y=..count.. + 10, label=..count..), stat='count', size = 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexplain why this is the current best option\n\n\n\n\n\nplot_frq(pen, species,\n         title = \"Count of penguins by species\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.3 Proportion Barcharts\n\nggplotbasesjplot\n\n\nOften you don’t want to compare counts but percents. To accomplish this, we have to aggregate the data to calculate the proportions first, then plot the aggregated data using geom_col to create the columns.\n\nspec.props &lt;- data.frame(prop.table(table(pen$species)))\nspec.props # what does this data look like? \n\n       Var1      Freq\n1    Adelie 0.4418605\n2 Chinstrap 0.1976744\n3    Gentoo 0.3604651\n\nggplot(spec.props, aes(x=Var1, y=Freq)) + geom_col() + \n  ylab(\"Proportion\") + xlab(\"Species\") + \n  ggtitle(\"Proportion of penguins by species\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncreate a ‘base’ tab, but with only space for robin to write\n\n\n\n\n\n\nThis is the same barchart generated by the frequency example, with proportion shown as a percentage below each species’ count.\n\nplot_frq(pen, species,\n         title = \"Count of penguins by species\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.4 Other\n\n\n\n\n\n\n\nRAD add some intro text here.\n\n\n\n\n\nCleveland Dot PlotsPie ChartWaffle Chart\n\n\nAnother way to visualize categorical data that takes up less ink than bars is a Cleveland dot plot. Here again we are plotting summary data instead of the raw data. This uses the geom_segment that draws the lines from x=0 to the value of the proportion (named Freq because of the way data.frame works).\n\nggplot(spec.props, aes(x=Freq, y=Var1)) +  \n  geom_point(size = 3) + xlab(\"Proportion of penguins\") + \n  theme_bw() + ylab(\"Species\") +\n  geom_segment(aes(x=0, xend=Freq, y=Var1, yend=Var1), color='grey50')\n\n\n\n\n\n\n\n\n\n\nJust like barplot(), pie() takes a table object as it’s argument.\nbase\n\nps &lt;- table(pen$species)\npie(ps)\n\n\n\n\n\n\n\n\nPie charts are my least favorite plotting type. Human eyeballs can’t distinguish between angles as well as we can with heights. A mandatory piece needed to make the wedges readable is to add the percentages of each wedge.\n\npie(ps, labels = paste0(names(ps), ' (', prop.table(ps)*100, \"%)\"))\n\n\n\n\n\n\n\n\nggplot\nAnd here I thought pie charts couldn’t get worse… I’m not a fan at all of the ggplot version. So i’m not even going to show it. STHDA has a great tutorial that does show you how to make one.\nHowever – Never say never. Storytelling with data has a blog post with an example of a good use of pie charts.\n\n\nThis type of chart is not natively found in the ggplot2 package, but its own waffle package. These are great for infographics.\n\nwaffle(ps/10, rows=5, size=0.5, \n       title=\"Species of penguins\", \n       xlab=\"1 square == 10 penguins\")",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#one-continuous-variable",
    "href": "data_viz.html#one-continuous-variable",
    "title": "2  Visualizing Data",
    "section": "2.4 One Continuous Variable",
    "text": "2.4 One Continuous Variable\nHere we can look at the bill length and depth, flipper length, and body mass of the penguins.\n\n2.4.1 Dotplot\n\n\n\n\n\n\n\nRAD change this to an introduction/motivating example instead of describing a plot type.\n\n\n\n\n\nplot(pen$bill_length_mm)\n\n\n\n\n\n\n\n\nThe base function plot() creates a dotplot for a continuous variable. The value of the variable is plotted on the y axis, and the index, or row number, is plotted on the x axis. This gives you a nice, quick way to see the values of the data.\nOften you are not interested in the individual values of each data point, but the distribution of the data. In other words, where is the majority of the data? Does it look symmetric around some central point? Around what values do the bulk of the data lie?\n\n\n2.4.2 Histograms\nRather than showing the value of each observation, we prefer to think of the value as belonging to a bin. The height of the bars in a histogram display the frequency of values that fall into those of those bins. For example if we cut the bill length distribution into 7 bins of equal width, the frequency table would look like this:\n\ntable(cut(pen$bill_length_mm, 7))\n\n\n  (32.1,36]     (36,40]   (40,43.9] (43.9,47.8] (47.8,51.7] (51.7,55.7] \n         26          74          67          81          75          15 \n(55.7,59.6] \n          4 \n\n\nIn a histogram, the binned counts are plotted as bars into a histogram. Note that the x-axis is continuous, so the bars touch. This is unlike the barchart that has a categorical x-axis, and vertical bars that are separated.\n\nbaseggplotggpubr\n\n\nYou can make a histogram in base graphics super easy.\n\nhist(pen$bill_length_mm)\n\n\n\n\n\n\n\n\nAnd it doesn’t take too much to clean it up. Here you can specify the number of bins by specifying how many breaks should be made in the data (the number of breaks controls the number of bins, and bin width) and use col for the fill color.\n\nhist(pen$bill_length_mm, xlab=\"Bill length in mm\", main=\"Histogram of penguin bill lengths\", col=\"cyan\", breaks=20)\n\n\n\n\n\n\n\n\n\n\n\nggplot(pen, aes(x=bill_length_mm)) + geom_histogram(binwidth = 2.2)\n\n\n\n\n\n\n\n\nThe binwidth here is set by looking at the cut points above that were used to create 7 bins. Notice that darkgrey is the default fill color, but makes it hard to differentiate between the bars. So we’ll make the outline black using colour, and fill the bars with white.\n\nggplot(pen, aes(x=bill_length_mm)) + geom_histogram(colour=\"black\", fill=\"white\") + \n  ggtitle(\"Distribution of penguin bill lengths\")\n\n\n\n\n\n\n\n\nNote I did not specify the binwidth argument here. The size of the bins can hide features from your graph, the default value for ggplot2 is range/30 and usually is a good choice.\n\n\nThe ggpubr package is based on ggplot2, with simpler syntax for quickly generating polished graphs.\n\ngghistogram(pen, x = \"bill_length_mm\",\n            title = \"Distribution of penguin bill lengths\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.3 Density plots\nTo get a better idea of the true shape of the distribution we can “smooth” out the bins and create what’s called a density plot or curve. Notice that the shape of this distribution curve is much more… “wigglier” than the histogram may have implied.\n\nbaseggplot2ggpubr\n\n\n\n# plot(density(na.omit(pen$bill_length_mm))) \npen$bill_length_mm |&gt; na.omit() |&gt; density() |&gt; plot()\n\n\n\n\n\n\n\n\nAwesome title huh? (NOT)\n\n\n\n\n\n\n\ndiscuss why na.omit and nesting vs pipe example\n\nUsing na.omit() is dangerous! This will remove ALL rows with ANY missing data in it. Regardless if the missing values are contained in the variables you are interested in. The example below employs a trick/work around to not have NA values show in the output. We take the data set addhealth and then select the variables we want to plot, and then we use na.omit() to delete all rows with missing data. Then that is saved as a new, temporary data frame specifically named for this case (plot.bmi.smoke).\n\n\n\n\n\n\nggplot(pen, aes(x=bill_length_mm)) + geom_density()\n\n\n\n\n\n\n\n\n\n\n\nggdensity(pen, x = \"bill_length_mm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.4 Histograms + density\nOften is is more helpful to have the density (or kernel density) plot on top of a histogram plot.\n\nbaseggplotggpubr\n\n\nSince the height of the bars in a histogram default to showing the frequency of records in the data set within that bin, we need to 1) scale the height so that it’s a relative frequency, and then use the lines() function to add a density() line on top.\n\nhist(pen$bill_length_mm, prob=TRUE)\nlines(density(na.omit(pen$bill_length_mm)), col=\"blue\")\n\n\n\n\n\n\n\n\n\n\nThe syntax starts the same, we’ll add a new geom, geom_density and color the line blue. Then we add the histogram geom using geom_histogram but must specify that the y axis should be on the density, not frequency, scale. Note that this has to go inside the aesthetic statement aes(). I’m also going to get rid of the fill by using NA so it doesn’t plot over the density line.\n\nggplot(pen, aes(x=bill_length_mm)) + geom_density(col=\"blue\") + \n  geom_histogram(aes(y=..density..), colour=\"black\", fill=NA)\n\n\n\n\n\n\n\n\n\n\n\ngghistogram(pen,\n            x = \"bill_length_mm\", \n            add_density = TRUE,\n            add.params = list(color=\"blue\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5 Boxplots\nAnother very common way to visualize the distribution of a continuous variable is using a boxplot. Boxplots are useful for quickly identifying where the bulk of your data lie. R specifically draws a “modified” boxplot where values that are considered outliers are plotted as dots.\n\nbaseggplotggpubr\n\n\n\nboxplot(pen$bill_length_mm)\n\n\n\n\n\n\n\n\nNotice that the only axis labeled is the y=axis. Like a dotplot the x axis, or “width”, of the boxplot is meaningless here. We can make the axis more readable by flipping the plot on it’s side.\n\nboxplot(pen$bill_length_mm, horizontal = TRUE, main=\"Distribution of penguin bill lengths\", xlab=\"Bill length in mm\")\n\n\n\n\n\n\n\n\nHorizontal is a bit easier to read in my opinion.\nAdding the mean\nA boxplot displays the median, so if we want to add more statistical detail and see any discrepancies between parameters we can add the mean as a point.\n\nboxplot(pen$bill_length_mm, horizontal = TRUE, main=\"Distribution of penguin bill lengths\", xlab=\"Bill length in mm\")\npoints(mean(na.omit(pen$bill_length_mm)), 1, col = \"red\", pch = 19)\n\n\n\n\n\n\n\n\n\n\nWhat about ggplot? ggplot doesn’t really like to do univariate boxplots. We can get around that by specifying that we want the box placed at a specific x value.\n\nggplot(pen, aes(x=1, y=bill_length_mm)) + geom_boxplot()\n\n\n\n\n\n\n\n\nTo flip it horizontal you may think to simply swap x and y? Good thinking. Of course it wouldn’t be that easy. So let’s just flip the whole darned plot on it’s coordinate axis.\n\nggplot(pen, aes(x=1, y=bill_length_mm)) + geom_boxplot() + coord_flip()\n\n\n\n\n\n\n\n\nAdding the mean\n\nggplot(pen, aes(x=1, y=bill_length_mm)) + geom_boxplot() + coord_flip() +\n  geom_hline(yintercept = mean(na.omit(pen$bill_length_mm)), color=\"red\", linetype=\"dashed\")\n\n\n\n\n\n\n\n\n\n\n\nggboxplot(pen, x=1, y=\"bill_length_mm\", \n          orientation = \"horizontal\",\n          main = \"Distribution of penguin bill lengths\",\n          ylab = \"Bill length in mm\")\n\n\n\n\n\n\n\n\nAdding the mean\n\nggboxplot(pen, x=1, y=\"bill_length_mm\", \n          orientation = \"horizontal\",\n          main = \"Distribution of penguin bill lengths\",\n          ylab = \"Bill length in mm\",\n          add = 'mean')\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.6 Violin plots\n\n\n\n\n\n\n\nbrief intro - usage, how they’re different from boxplots\n\n\n\n\n\nggplotggpubr\n\n\n\nggplot(pen, aes(x=1, y=bill_length_mm)) + geom_violin()\n\n\n\n\n\n\n\n\nAdding the mean\n\nggplot(pen, aes(x=1, y=bill_length_mm)) + geom_violin() +\n  geom_hline(yintercept = mean(na.omit(pen$bill_length_mm)), color=\"red\", linetype=\"dashed\")\n\n\n\n\n\n\n\n\n\n\n\nggviolin(pen, x=1, y=\"bill_length_mm\")\n\n\n\n\n\n\n\n\nAdding the mean\n\nggviolin(pen, x=1, y=\"bill_length_mm\",\n         add = 'mean')\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.7 Boxplot + violin plots\nOverlaying a boxplot and a violin plot serves a similar purpose to Histograms + Density plots.\n\nggplotggpubr\n\n\n\nggplot(pen, aes(x=1, y=bill_length_mm)) + geom_violin() + geom_boxplot()\n\n\n\n\n\n\n\n\nBetter appearance - different levels of transparency of the box and violin.\n\nggplot(pen, aes(x=1, y=bill_length_mm)) + xlab(\"\") + theme_bw() + \n              geom_violin(fill=\"blue\", alpha=.1) + \n              geom_boxplot(fill=\"blue\", alpha=.5, width=.2) + \n              theme(axis.title.x=element_blank(),\n              axis.text.x=element_blank(),\n              axis.ticks.x=element_blank())\n\n\n\n\n\n\n\n\nAdding the mean\n\nggplot(pen, aes(x=1, y=bill_length_mm)) + xlab(\"\") + theme_bw() + \n              geom_violin(fill=\"blue\", alpha=.1) + \n              geom_boxplot(fill=\"blue\", alpha=.5, width=.2) + \n              geom_hline(yintercept = mean(na.omit(pen$bill_length_mm)),\n                         color=\"red\", linetype=\"dashed\")\n\n\n\n\n\n\n\n\n\n\n\nggviolin(pen, x=1, y=\"bill_length_mm\", \n         alpha=.2, fill=\"blue\", \n         add = \"boxplot\", add.params = list(alpha=.4),\n         xlab=\"\") \n\n\n\n\n\n\n\n\nAdding the mean\n\nggviolin(pen, x=1, y=\"bill_length_mm\", \n         alpha=.2, fill=\"blue\", \n         add = c('boxplot', 'mean'),\n         add.params = list(alpha=.4),\n         xlab=\"\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.8 Normal QQ plots\nThe last useful plot that we will do on a single continuous variable is to assess the normality of the distribution. Basically how close the data follows a normal distribution.\n\nbaseggplotggpubr\n\n\n\nqqnorm(pen$body_mass_g)\nqqline(pen$body_mass_g, col=\"red\")\n\n\n\n\n\n\n\n\nThe line I make red because it is a reference line. The closer the points are to following this line, the more “normal” the shape of the distribution is. Price has some pretty strong deviation away from that line. Below I have plotted what a normal distribution looks like as an example of a “perfect” fit.\n\nz &lt;- rnorm(1000)\nqqnorm(z)\nqqline(z, col=\"blue\")\n\n\n\n\n\n\n\n\n\n\nqq (or qnorm) plots specifically plot the data against a theoretical distribution. That means in the aes() aesthetic argument we don’t specify either x or y, but instead the sample= is the variable we want to plot.\n\nggplot(pen, aes(sample=body_mass_g)) + stat_qq()\n\n\n\n\n\n\n\n\n\n\n\nggqqplot(pen, x=\"body_mass_g\")",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#categorical-v.-categorical",
    "href": "data_viz.html#categorical-v.-categorical",
    "title": "2  Visualizing Data",
    "section": "2.5 Categorical v. Categorical",
    "text": "2.5 Categorical v. Categorical\n\n2.5.1 Two-way tables\n\n\n\n\n\n\n\nintro to two way frequency and proportion tables\n\n\n\n\n\nFrequencyProportion\n\n\nCross-tabs, cross-tabulations and two-way tables (all the same thing, different names) can be created by using the table() function.\nThe frequency table is constructed using the table() function.\n\ntable(pen$island, pen$species)\n\n           \n            Adelie Chinstrap Gentoo\n  Biscoe        44         0    124\n  Dream         56        68      0\n  Torgersen     52         0      0\n\n\nThere are 44 Adelie penguins and 124 Gentoo penguins on Biscoe Island, 56 Adelie and 68 Chinstrap penguins on Dream Island, and 52 Adelie penguins on Torgersen Island.\n\n\nChoose your percentages depending on your research question. What are you wanting to compare?\nBest practices:\n\nExplanatory variable on the rows\nResponse variable on the columns\nCalculate row %’s as the % of the response for each explanatory group.\n\nHere are demonstrations of how the interpretation of the percents change depending on what the denominator is.\nCell proportions\nWrapping prop.table() around a table gives you the cell proportions.\n\nprop.table(table(pen$island, pen$species))\n\n           \n               Adelie Chinstrap    Gentoo\n  Biscoe    0.1279070 0.0000000 0.3604651\n  Dream     0.1627907 0.1976744 0.0000000\n  Torgersen 0.1511628 0.0000000 0.0000000\n\n\n12.8% of all penguins are Adelie penguins living on Biscoe Island, and 36% are Gentoo penguins living on Biscoe Island, so about 39% of all penguins in our data are living on Biscoe Island.\nRow proportions\nTo get the row proportions, you specify margin=1. The percentages now add up to 1 across the rows.\n\nround(prop.table(table(pen$island, pen$species), margin=1),3)\n\n           \n            Adelie Chinstrap Gentoo\n  Biscoe     0.262     0.000  0.738\n  Dream      0.452     0.548  0.000\n  Torgersen  1.000     0.000  0.000\n\n\n26.2% of penguins on Biscoe Island are from the Adelie species. The remaining 73.8% on the island are Gentoo penguins.\nColumn proportions\nTo get the column proportions, you specify margin=2. The percentages now add up to 1 down the columns.\n\nround(prop.table(table(pen$island, pen$species), margin=2),3)\n\n           \n            Adelie Chinstrap Gentoo\n  Biscoe     0.289     0.000  1.000\n  Dream      0.368     1.000  0.000\n  Torgersen  0.342     0.000  0.000\n\n\n0.289% of all Adelie penguins are on Biscoe Island. Chinstrap and Gentoo species are endemic to a single island, so 100% of their populations are on Dream and Torgersen Island, respectively.\n\n\n\n\n\n2.5.2 Grouped bar charts: stacked\nTo compare proportions of one categorical variable within the same level of another, we can use grouped barcharts.\n\nbaseggplot\n\n\nAs before, the object to be plotted needs to be the result of a table.\n\nis &lt;- table(pen$island, pen$species)\nbarplot(is)\n\n\n\n\n\n\n\n\n\n\nAgain plot the cut on the x axis, but then fill using the second categorical variable. This has the effect of visualizing the row percents from the table above, or the percent of species on each island.\n\nggplot(pen, aes(x=island, fill=species)) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.3 Grouped bar charts: side by side\nStacked bars can be difficult to interpret, and very difficult to compare values between groups. A side by side barchart is preferable. The beside=TRUE is what controls the placement of the bars.\n\nbaseggplot\n\n\n\nbarplot(is, main=\"quick side by side barchart using base graphics\", \n        beside=TRUE)\n\n\n\n\n\n\n\n\n\n\nAgain the default is a stacked barchart. So we just specify position=dodge to put the bars side by side.\n\nggplot(pen, aes(x=island, fill=species)) + geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nAnd look, an automatic legend. What if I wanted to better compare island population proportions within species? This is the column percentages. Just switch which variable is the x axis and which one is used to fill the colors!\n\nggplot(pen, aes(x=species, fill=island)) + geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nFor more than 2 colors I do not recommend choosing the colors yourself. I know little about color theory so I use the built-in color palettes. Here is a great cheatsheet about using color palettes.\nAnd this easy change is why we love ggplot2.\n\n\n\n\n\n2.5.4 Grouped bar charts with percentages\nNot as easy as one would hope, but the solution is to calculate the desired percentages first and then plot the summary data using either geom_bar(stat='identity') or geom_col().\n\ncalc.props &lt;- pen %&gt;% group_by(island, species) %&gt;%\n              summarise(count=n()) %&gt;%\n              mutate(pct=round(count/sum(count),3))\ncalc.props\n\n# A tibble: 5 × 4\n# Groups:   island [3]\n  island    species   count   pct\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;\n1 Biscoe    Adelie       44 0.262\n2 Biscoe    Gentoo      124 0.738\n3 Dream     Adelie       56 0.452\n4 Dream     Chinstrap    68 0.548\n5 Torgersen Adelie       52 1    \n\n\n\nggplotsjPlot\n\n\nSince we’re plotting summary data, the height of the bars is specified using y=pct.\n\nggplot(calc.props, aes(x=island, fill=species, y=pct)) +\n                  geom_col(position=\"dodge\") + theme_bw() \n\n\n\n\n\n\n\n\nNow set some options to the y axis using scale_y_continuous() to make the graph more accurate and readable. The labels=percent comes from the scales package.\n\nggplot(calc.props, aes(x=island, fill=species, y=pct)) +\n                  geom_col(position=\"dodge\") + theme_bw() +\n                  scale_y_continuous(limits=c(0,1), labels=percent)\n\n\n\n\n\n\n\n\n\n\nsjPlot does a very nice job of being able to cleanly show not only n’s but percents.\n\nplot_xtab(pen$island, pen$species, margin=\"row\", coord.flip = TRUE) \n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.5 Mosaic plots\nBut what if you want to know how two categorical variables are related and you don’t want to look at two different barplots? Mosaic plots are a way to visualize the proportions in a table. So here’s the two-way table we’ll be plotting.\n\ntable(pen$island, pen$species)\n\n           \n            Adelie Chinstrap Gentoo\n  Biscoe        44         0    124\n  Dream         56        68      0\n  Torgersen     52         0      0\n\n\nThe syntax for a mosaic plot uses model notation, which is basically y ~ x where the ~ is read as “twiddle” or “tilde”. It’s to the left of your 1 key.\n\nmosaicplot(island~species, data=pen)\n\n\n\n\n\n\n\n\nHelpful, ish. Here are two very useful options. In reverse obviousness, color applies shades of gray to one of the factor levels, and shade applies a color gradient scale to the cells in order of what is less than expected (red) to what is more than expected (blue) if these two factors were completely independent.\n\npar(mfrow=c(1,2)) # display the plots in 1 row and 2 columns\nmosaicplot(sex~species, data=pen, color=TRUE)\nmosaicplot(island~species, data=pen, shade=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nswitch out old interpretation for penguins\n\nFor example, there are fewer ‘Very Good’ cut diamonds that are color ‘G’, and fewer ‘Premium’ cut diamonds that are color ‘H’. As you can see, knowing what your data means when trying to interpret what the plots are telling you is essential.\n\n\n\nThat’s about all the ways you can plot categorical variables.\nIf you are wondering why there was no 3D barcharts demonstrated see here, here, and here for other ways you can really screw up your visualization.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#continuous-v.-continuous",
    "href": "data_viz.html#continuous-v.-continuous",
    "title": "2  Visualizing Data",
    "section": "2.6 Continuous v. Continuous",
    "text": "2.6 Continuous v. Continuous\n\n2.6.1 Scatterplot\nThe most common method of visualizing the relationship between two continuous variables is by using a scatterplot.\n\nbaseggplot\n\n\nBack to the plot() command. Here we use model notation again, so it’s \\(y~x\\).\n\nplot(flipper_length_mm~body_mass_g, data=pen)\n\n\n\n\n\n\n\n\nLooks like for the most part as penguin body mass increases so does flipper length. That makes sense.\n\n\nWith ggplot we specify both the x and y variables, and add a point.\n\nggplot(pen, aes(x=body_mass_g, y=flipper_length_mm)) + geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.6.2 Adding lines to the scatterplots\nTwo most common trend lines added to a scatterplots are the “best fit” straight line and the “lowess” smoother line.\n\nbaseggplot\n\n\nThe best fit line (in blue) gets added by using the abline() function wrapped around the linear model function lm(). Note it uses the same model notation syntax and the data= statement as the plot() function does. The lowess line is added using the lines() function, but the lowess() function itself doesn’t allow for the data= statement so we have to use $ sign notation.\n\nplot(flipper_length_mm~body_mass_g, data=pen)\nabline(lm(flipper_length_mm~body_mass_g, data=pen), col=\"blue\")\nlines(lowess(na.omit(pen$flipper_length_mm)~na.omit(pen$body_mass_g)),\n      col=\"red\")\n\n\n\n\n\n\n\n\n\n\nWith ggplot, we just add a geom_smooth() layer.\n\nggplot(pen, aes(x=body_mass_g, y=flipper_length_mm)) + geom_point() + geom_smooth() \n\n\n\n\n\n\n\n\nHere the point-wise confidence interval for this lowess line is shown in grey. If you want to turn the confidence interval off, use se=FALSE. Also notice that the smoothing geom uses a different function or window than the lowess function used in base graphics.\nHere it is again using the ggplot plotting function and adding another geom_smooth() layer for the lm (linear model) line in blue, and the lowess line (by not specifying a method) in red.\n\nggplot(pen, aes(x=body_mass_g, y=flipper_length_mm)) + geom_point() + \n  geom_smooth(se=FALSE, method=\"lm\", color=\"blue\") + \n  geom_smooth(se=FALSE, color=\"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.6.3 Line plots\nLine plots connect each dot with a straight line. This is most often done when measuring trends of the response as the value of x increases (such as a time series)\n\n\n\n\n\n\n\nswitch out example for time series\n\n\n\n\nWe saw earlier that body_mass_g and flipper_length_mm seemed possibly linear. Let see how the average flipper length changes with body mass.\n\nmm.per.g &lt;- pen %&gt;% group_by(body_mass_g) %&gt;% summarise(mean = mean(flipper_length_mm))\n\n\nbaseggplot\n\n\nFor base graphics, type=‘b’ means both points and lines, ‘l’ gives you just lines and ‘p’ gives you only points. You can find more plotting character options under ?pch.\n\nplot(mean~body_mass_g, data=mm.per.g, type='l')\n\n\n\n\n\n\n\n\n\n\nWith ggplot we specify that we want a line geometry only.\n\nggplot(mm.per.g, aes(x=body_mass_g, y=mean)) + geom_line()\n\n\n\n\n\n\n\n\n\n\n\nHow does this relationship change with penguin species? First lets get the average flipper length per combination of body mass and species\n\nmmpgs &lt;- pen %&gt;% group_by(body_mass_g, species) %&gt;% summarise(mean = mean(flipper_length_mm))\n\n\nggplotbase\n\n\nThis is where ggplot starts to excel in it’s ease of creating more complex plots. All we have to do is specify that we want the lines colored by the cut variable.\n\nggplot(mmpgs, aes(x=body_mass_g, y=mean, col=species)) + geom_line()\n\n\n\n\n\n\n\n\nAnd we get one line per species.\n\n\nThis plot can be created in base graphics, but it takes an advanced knowledge of the graphics system to do so. So I do not show it here.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#continuous-v.-categorical",
    "href": "data_viz.html#continuous-v.-categorical",
    "title": "2  Visualizing Data",
    "section": "2.7 Continuous v. Categorical",
    "text": "2.7 Continuous v. Categorical\nCreate an appropriate plot for a continuous variable, and plot it for each level of the categorical variable.\n\n2.7.1 Dotplot/strip chart\nDotplots can be very useful when plotting dots against several categories. They can also be called stripcharts.\n\nbaseggplot\n\n\n\nstripchart(body_mass_g ~ species, data=pen)\n\n\n\n\n\n\n\n\n\n\nWe can reproduce the same thing by plotting one continuous variable against one categorical variable, and adding a layer of points. I’d argue that horizontal looks better due to the axis-labels.\n\na &lt;- ggplot(pen, aes(y=body_mass_g, x=species)) + geom_point()\nb &lt;- ggplot(pen, aes(y=species, x=body_mass_g)) + geom_point()\ngrid.arrange(a, b, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.7.2 Grouped boxplots\n\nbaseggplot\n\n\nBase graphics plots grouped boxplots with also just the addition of a twiddle (tilde) ~. Another example of where model notation works.\n\nboxplot(bill_length_mm~species, data=pen)\n\n\n\n\n\n\n\n\n\n\nA simple addition, just define your x and y accordingly.\n\nggplot(pen, aes(x=species, y=bill_depth_mm, fill=species)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nDescriptive additions\n\nAdding violinsAdding jittered pointsAdding ridge plots\n\n\nViolin plots can be overlaid here as well.\n\nggplot(pen, aes(x=species, y=bill_depth_mm, fill=species)) +\n        geom_violin(alpha=.1) + \n        geom_boxplot(alpha=.5, width=.2)\n\n\n\n\n\n\n\n\n\n\n\nggplot(pen, aes(x=species, y=bill_depth_mm, fill=species)) + \n         geom_boxplot() +\n         geom_jitter()\n\n\n\n\n\n\n\n\n\n\n\npen %&gt;%\n  select(species,\n         bill_depth_mm) %&gt;%\n  na.omit() %&gt;%\n  ggplot(aes(x=species,\n             y=bill_depth_mm,\n             fill = species)) +\n  geom_boxplot(alpha=.5, width=.2) +\n  stat_summary(fun=\"mean\") +\n  stat_slab(alpha = .3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.7.3 Grouped histograms\n\nggplotbase\n\n\nBy default ggplot wants to overlay all plots on the same grid. This doesn’t look to good with histograms. Instead you can overlay density plots\n\na &lt;- ggplot(pen, aes(x=bill_depth_mm, fill=species)) + geom_histogram()\nb &lt;- ggplot(pen, aes(x=bill_depth_mm, fill=species)) + geom_density() \ngrid.arrange(a,b, ncol=2)\n\n\n\n\n\n\n\n\nThe solid fills are still difficult to read, so we can either turn down the alpha (turn up the transparency) or only color the lines and not the fill.\n\nc &lt;- ggplot(pen, aes(x=bill_depth_mm, fill=species)) + geom_density(alpha=.2)\nd &lt;- ggplot(pen, aes(x=bill_depth_mm, fill=species)) + geom_density() \ngrid.arrange(c,d, ncol=2)\n\n\n\n\n\n\n\n\n\n\nThere is no easy way to create grouped histograms in base graphics, so we will skip it.\n\n\n\n\n\n2.7.4 Ridgeline plots\nRidgeline plots have not been added to the base distribution of ggplot2 yet. For now it’s available in the ggridges package. Really good way to visualize density plots without the overlapping issue.\n\nggplot(pen, aes(x=bill_depth_mm, y=species)) + geom_density_ridges()",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#faceting-paneling",
    "href": "data_viz.html#faceting-paneling",
    "title": "2  Visualizing Data",
    "section": "2.8 Faceting / paneling",
    "text": "2.8 Faceting / paneling\nThis is a good place to introduce a term called faceting. The definition is a particular aspect or feature of something, or one side of something many-sided, especially of a cut gem. Basically instead of plotting the grouped graphics on the same plotting area, we let each group have it’s own plot, or facet.\nWe add a facet_wrap() and specify that we want to panel on the species group. Note the twiddle in front of species.\n\nggplot(pen, aes(x=bill_depth_mm, fill=species)) + geom_density() + facet_wrap(~species)\n\n\n\n\n\n\n\n\nThe grid placement can be semi-controlled by using the ncol argument in the facet_wrap() statement.\n\nggplot(pen, aes(x=bill_depth_mm, fill=species)) + \n  geom_density() + facet_wrap(~species, ncol=4)\n\n\n\n\n\n\n\n\nIt is important to compare distributions across groups on the same scale, and our eyes can compare items vertically better than horizontally. So let’s force ncol=1.\n\nggplot(pen, aes(x=bill_depth_mm, fill=species)) + \n  geom_density() + facet_wrap(~species, ncol=1)\n\n\n\n\n\n\n\n\n\n2.8.1 Paneling on two variables\nWho says we’re stuck with only faceting on one variable? A variant on facet_wrap is facet_grid. Here we can specify multiple variables to panel on.\n\nggplot(pen, aes(x=body_mass_g, fill=sex)) + geom_density() + facet_grid(sex~island)\n\n\n\n\n\n\n\n\nHow about plotting bill length against flipper length, for all combinations of species and island, with the points further separated by sex?\n\nggplot(pen, aes(x=flipper_length_mm, y=bill_length_mm, color=sex)) + geom_point() + facet_grid(island~species)",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#multiple-plots-per-window",
    "href": "data_viz.html#multiple-plots-per-window",
    "title": "2  Visualizing Data",
    "section": "2.9 Multiple plots per window",
    "text": "2.9 Multiple plots per window\n\nbaseggplotQuarto\n\n\nI use par(mfrow=c(r,c)) for base graphics, where r is the number of rows and c the number of columns.\n\npar(mfrow=c(1,3))\nplot(pen$bill_depth_mm)\nplot(pen$species)\nplot(pen$bill_length_mm ~ pen$bill_depth_mm)\n\n\n\n\n\n\n\n\nOther resources including learning about layouts. Multipanel plotting with base graphics\n\n\nUse the grid.arrange function in the gridExtra package. I’ve done it several times above. You assign the output of a ggplot object to an object (here it’s plot1 and plot2). Then you use grid.arrange() to arrange them either side by side or top and bottom.\n\na &lt;- ggplot(pen, aes(x=bill_depth_mm, fill=species)) + geom_density(alpha=.2)\nb &lt;- ggplot(pen, aes(x=bill_depth_mm, fill=species)) + geom_density() \ngrid.arrange(a,b, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nadd example or reference to https://quarto.org/docs/get-started/computations/rstudio.html#multiple-figures",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#multivariate-3-variables",
    "href": "data_viz.html#multivariate-3-variables",
    "title": "2  Visualizing Data",
    "section": "2.10 Multivariate (3+ variables)",
    "text": "2.10 Multivariate (3+ variables)\nThis is not much more complicated than taking an appropriate bivariate plot and adding a third variable through paneling, coloring, or changing a shape.\nThis is trivial to do in ggplot, not trivial in base graphics. So I won’t show those examples.\n\n2.10.1 Three continuous\nContinuous variables can also be mapped to the size of the point. Here I set the alpha on the points so we could see the overplotting (many points on a single spot). So the darker the spot the more data points on that spot.\n\nggplot(pen, aes(x=bill_length_mm, y=bill_depth_mm, size=body_mass_g)) + geom_point(alpha=.2)\n\n\n\n\n\n\n\n\n\n\n2.10.2 Scatterplot matrix\nA scatterplot matrix allows you to look at the bivariate comparison of multiple pairs of variables simultaneously. First we need to trim down the data set to only include the variables we want to plot, then we use the pairs() function.\n\nc.vars &lt;- pen[,c('flipper_length_mm', 'bill_length_mm', 'bill_depth_mm', \n                 'body_mass_g')]\npairs(c.vars)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReplace original interpretation- We can see price has a non-linear relationship with X, Y and Z and x & y have a near perfect linear relationship.\n\n\n\n\n\n\n2.10.3 Two categorical and one continuous\nThis is very similar to side by side boxplots, one violin plot per sex, within each island\n\n\n\n\n\n\n\nReplace original interpretation- This is difficult to really see due to the large number of categories each factor has. The categorical variables in the penguins dataset have less categories w less combinations\n\n\n\n\n\nggplot(pen, aes(x=island, y=bill_length_mm, fill=species)) + geom_violin()\n\n\n\n\n\n\n\n\nBest bet here would be to panel on species and change the x axis to location.\n\nggplot(pen, aes(x=species, y=bill_length_mm, fill=species)) + geom_violin() + facet_wrap(~island)\n\n\n\n\n\n\n\n\n\n\n2.10.4 Two continuous and one categorical\nAnd lastly let’s look back at how we can play with scatterplots of using a third categorical variable (using ggplot2 only). We can color the points by species,\n\nggplot(pen, aes(x=flipper_length_mm, y=bill_length_mm, color=species)) + geom_point()\n\n\n\n\n\n\n\n\nWe could add a smoothing lowess line for each species separately,\n\nggplot(pen, aes(x=flipper_length_mm, y=bill_length_mm, color=species)) + geom_point() + geom_smooth(se=FALSE)\n\n\n\n\n\n\n\n\nAnd using grid.arrange we can include both visualizations.\n\na &lt;- ggplot(pen, aes(x=bill_length_mm, y=bill_depth_mm, color=species)) + geom_point() + ggtitle(\"Colored by species\")\nd &lt;- ggplot(pen, aes(x=bill_length_mm, y=bill_depth_mm, color=species)) + geom_point() + \n      geom_smooth(se=FALSE) +ggtitle(\"Lowess line per species\")\ngrid.arrange(a, d, ncol=2, nrow=1)\n\n\n\n\n\n\n\n\nOr we just panel by species.\n\nggplot(pen, aes(x=bill_length_mm, y=bill_depth_mm)) + geom_point() + facet_wrap(~species)\n\n\n\n\n\n\n\n\nWe could even change the color by sex, and shape by species.\n\nggplot(pen, aes(x=flipper_length_mm, y=bill_length_mm, color=sex, shape=species)) + geom_point() \n\n\n\n\n\n\n\n\nThat’s harder to read. So note that just because you can change an aesthetic, doesn’t mean you should. And just because you can plot things on the same axis, doesn’t mean you have to.\nBefore you share your plot with any other eyes, always take a step back and try to explain what it is telling you. If you have to take more than a minute to get to the point then it may be too complex and simpler graphics are likely warranted.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#troubleshooting",
    "href": "data_viz.html#troubleshooting",
    "title": "2  Visualizing Data",
    "section": "2.11 Troubleshooting",
    "text": "2.11 Troubleshooting\n\n2.11.1 Problem: Missing data showing up as a category in ggplot?\nGet rid of that far right bar!\n\nggplot(NCbirths, aes(x=marital)) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution:\n\n\n\n\n\nUse dplyr to select only the variables you are going to plot, then pipe in the na.omit() at the end. It will create a temporary data frame (e.g) plot.data that you then provide to ggplot().\n\nplot.data &lt;- NCbirths %&gt;% select(marital) %&gt;% na.omit()\nggplot(plot.data, aes(x=marital)) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.11.2 Problem: Got numerical binary 0/1 data but want to plot it as categorical?\nConsider a continuous variable for the number of characters in an email num_char, and a 0/1 binary variable spam.\n\n\n\n\n\n\nSolution:\n\n\n\n\n\nCreate a second variable var_factor for plotting and keep the binary var as 0/1 for analysis.\n\nemail$spam_cat &lt;- factor(email$spam, labels=c(\"Ham\", \"Spam\"))\nggplot(email, aes(y=num_char, x=spam_cat)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.11.3 Problem: You want to change the legend title for a fill or color scale.\n\n\n\n\n\n\nSolution:\n\n\n\n\n\nAdd the name= argument to whatever layer you added that created the legend. Here I specified a fill, and it was a discrete variable. So I use the scale_fill_discrete() layer.\n\nggplot(email, aes(y=num_char, x=spam_cat, fill=spam_cat)) + geom_boxplot() + \n  scale_fill_discrete(name=\"Ya like Spam?\")\n\n\n\n\n\n\n\n\nHere, I colored the points by a discrete variable, so the layer is scale_color_discrete().\n\nggplot(email, aes(x=num_char, y=line_breaks, col=spam_cat)) + geom_point() +\n  scale_color_discrete(name=\"Ya like Spam?\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.11.4 Problem: You want to add means to boxplots.\nBoxplots are great. Even better with violin overlays. Know what makes them even better than butter? Adding a point for the mean. stat_summary is the layer you want to add. Check out this stack overflow post for more context.\n\nggplot(email, aes(x=spam_cat, y=num_char, fill=spam_cat)) +\n  geom_boxplot() +\n  stat_summary(fun.y=\"mean\", geom=\"point\", size=3, pch=17,color=\"blue\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution:\n\n\n\n\n\nI suggest playing around with size and plotting character pch to get a feel for how these work. You can also look at ?pch (and scroll down in the help file) to see the 25 default plotting characters.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#but-what-about",
    "href": "data_viz.html#but-what-about",
    "title": "2  Visualizing Data",
    "section": "2.12 But what about…",
    "text": "2.12 But what about…\n\nLegend adjustment: remove it, move it to another side, rename it\nCustom specified colors and shapes\n\nGo to the R Graphics Cookbook, 2e for these.\nOther visualizations:\n\nHeat maps\nWord clouds, or simpler\nInteractive plots - Look into plotly() and ggplotly(), start with their guide directed towards R users here or browse the Plotly R open source graphing library",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#additional-resources",
    "href": "data_viz.html#additional-resources",
    "title": "2  Visualizing Data",
    "section": "2.13 Additional Resources",
    "text": "2.13 Additional Resources\nFor any Google Search - be sure to limit searches to within the past year or so. R packages get updated very frequently, and many functions change or become obsolete.\n\nComprehensive guides\n\nR Graphics 2e: The best book about using base graphics\nR Graphics Cookbook 2e: The best book for using ggplot2\nggplot2: Elegant Graphics for Data Analysis 3e\n\nSubject reference and tutorial sites\n\nMath 130 Lesson 07 - Creating graphics - more on ggplot2 syntax\nSTHDA: Statistical tools for high-throughput data analysis.\n\nggplot2 essentials\nggplot2 qq plot (quantile - quantile graph) : Quick start guide\nOther graphics options\n\nQuick-R / Datacamp:\n\nBasic Graphs\nggplot2\nScatterplots\n\nR-bloggers\n\nWaffle charts\nScatterplot matrices\n\n\nLiterate programming tools\n\nQuarto\n\nMultiple figure alignment\n\n\nHelp lists\n\nggplot2 Google Groups\nStackoverflow questions tagged ggplot2\nChico R users group",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "select_analysis.html",
    "href": "select_analysis.html",
    "title": "3  Selecting Appropriate Analyses",
    "section": "",
    "text": "Section in progress\n\n\n\nThis section covers how to choose appropriate analyses for any number and type of measurements. Think like, flow chart.\nConsiderations:\n\nPurpose of analysis.\n\nTypes of variables in data set.\n\nData used in analysis.\n\nAssumptions needed; satisfied?\n\nChoice of analyses is often arbitrary: consider several\n\nExample:\n5 independent variables: 3 interval, 1 ordinal, 1 nominal\n1 dependent variable: interval\nAnalysis options\n\nMultiple regression: pretend independent ordinal variable is an interval variable use dummy (0 /1) variables for nominal variables\nAnalysis of variance: categorize all independent variables\nAnalysis of covariance: leave variables as is, check assumptions\nLogistic regression: Categorize dependent variable: high, low\nSurvival analysis: IF dependent variable is time to an event\n\nUnsure? Do several and compare results.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Selecting Appropriate Analyses</span>"
    ]
  },
  {
    "objectID": "foundations.html",
    "href": "foundations.html",
    "title": "4  Foundations for Inference",
    "section": "",
    "text": "Nothing here yet",
    "crumbs": [
      "Statistical Inference",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Foundations for Inference</span>"
    ]
  },
  {
    "objectID": "bivariate_analysis.html",
    "href": "bivariate_analysis.html",
    "title": "5  Bivariate Analysis",
    "section": "",
    "text": "5.1 Assumption of independent observations\nThe primary assumption of most standard statistical procedures is that observations are independent of each other. That is, the value of one observation does not change or affect another observation.\nHowever, there are many examples where measurements are made on subjects before and after a certain exposure or treatment (pre-post), or an experiment to compare two cell phone packages might use pairs of subjects that are the same age, sex and income level. One subject would be randomly assigned to the first phone package, the other in the pair would get the second phone package. This chapter only deals with non-correlated analyses, leaving that topic for a later chapter.",
    "crumbs": [
      "Statistical Inference",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate_analysis.html#choosing-appropriate-bivariate-analysis",
    "href": "bivariate_analysis.html#choosing-appropriate-bivariate-analysis",
    "title": "5  Bivariate Analysis",
    "section": "5.2 Choosing appropriate bivariate analysis",
    "text": "5.2 Choosing appropriate bivariate analysis\nChoosing which statistical analyses procedure is appropriate completely depending on the data types of the explanatory and response variable. This is a simplified table, only covering the common/standard types of bivariate analysis.\n\n\n\n\n\n\n\nfigure out how to get table here. latex doesnt work. - some options: raw markdown, knitr::kable, mermaid diagram\n\n\n\n\nFor this set of notes, the variable types are referred to using the first letter, e.g. Q for quantitative, B for binary, and C for categorical. Thus a T-test is a (Q \\(\\sim\\) B) analysis, and a correlation analysis is (Q \\(\\sim\\) Q) analysis.\n\n\n\n\n\n\n\ncounty dataset will need to be replaced or example switched - no longer included in openintro & the csv on https://www.norcalbiostat.com/data/#countyComplete is missing federal spending column",
    "crumbs": [
      "Statistical Inference",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate_analysis.html#qb-two-means-t-test",
    "href": "bivariate_analysis.html#qb-two-means-t-test",
    "title": "5  Bivariate Analysis",
    "section": "5.3 (Q~B) Two means: T-Test",
    "text": "5.3 (Q~B) Two means: T-Test\nIt is common to compare means from different samples. For instance, we might investigate the effectiveness of a certain educational intervention by looking for evidence of greater reading ability in the treatment group against a control group. That is, our research hypothesis is that reading ability of a child is associated with an educational intervention.\nThe null hypothesis states that there is no relationship, or no effect, of the educational intervention (binary explanatory variable) on the reading ability of the child (quantitative response variable). This can be written in symbols as follows:\n\\[H_{0}: \\mu_{1} = \\mu_{2}\\mbox{ or }\\qquad  H_{0}: \\mu_{1} -\\mu_{2}=0\\]\nwhere \\(\\mu_{1}\\) is the average reading score for students in the control group (no intervention) and \\(\\mu_{2}\\) be the average reading score for students in the intervention group. Notice it can be written as one mean equals the other, but also as the difference between two means equaling zero. The alternative hypothesis \\(H_{A}\\) states that there is a relationship:\n\\[H_{A}: \\mu_{1} \\neq \\mu_{2} \\qquad \\mbox{ or } \\qquad H_{A}: \\mu_{1}-\\mu_{2} \\neq 0\\]\n\n5.3.1 Assumptions\n\nThe data distribution for each group is approximately normal.\nThe scores are independent within each group.\nThe scores from the two groups are independent of each other (i.e. the two samples are independent).\n\n\n\n5.3.2 Sampling Distribution for the difference\nWe use \\(\\bar{x}_1 - \\bar{x}_2\\) as a point estimate for \\(\\mu_1 - \\mu_2\\), which has a standard error of\n\\[\nSE_{\\bar{x}_1 - \\bar{x}_2}\n   = \\sqrt{SE_{\\bar{x}_1}^2 + SE_{\\bar{x}_2}^2}\n     = \\sqrt{\\frac{\\sigma^{2}_{1}}{n_1} + \\frac{\\sigma^{2}_{2}}{n_2}}\n\\]\nSo the equations for a Confidence Interval is,\n\\[\n  \\left( \\bar{x}_{1} - \\bar{x}_{2} \\right) \\pm t_{\\frac{\\alpha}{2}, df}\n    \\sqrt{ \\frac{\\sigma^{2}_{1}}{n_{1}} + \\frac{\\sigma^{2}_{2}}{n_{2}} }\n\\]\nand Test Statistic is,\n\\[\n  t^{*} =  \\frac{\\left( \\bar{x}_{1} - \\bar{x}_{2} \\right) - d_{0}}\n       {\\left( \\sqrt{ \\frac{\\sigma^{2}_{1}}{n_{1}} + \\frac{\\sigma^{2}_{2}}{n_{2}} }\n       \\right )}\n\\]\nTypically it is unlikely that the population variances \\(\\sigma^{2}_{1}\\) and \\(\\sigma^{2}_{2}\\) are known so we will use sample variances \\(s^{2}_{1}\\) and \\(s^{2}_{2}\\) as estimates.\nWhile you may never hand calculate these equations, it is important to see the format, or structure, of the equations. Equation \\(\\ref{2sampCImean}\\) has the same format of\n\\[ \\mbox{point estimate} \\pm 2*\\mbox{standard error}\\]\nregardless what it is we’re actually trying to estimate. Thus in a pinch, you can calculate approximate confidence intervals for whatever estimate you are trying to understand, given only the estimate and standard error, even if the computer program does not give it to you easily or directly.\n\n\n5.3.3 Example: Smoking and BMI\n\n\n\n\n\n\nWe would like to know, is there convincing evidence that the average BMI differs between those who have ever smoked a cigarette in their life compared to those who have never smoked? This example uses the Addhealth dataset.\n\n\n\n1. Identify response and explanatory variables.\n\nThe quantitative response variable is BMI (variable )\nThe binary explanatory variable is whether the person has ever smoked a cigarette (variable )\n\n2. Visualize and summarize bivariate relationship.\n\nplot.bmi.smoke &lt;- addhealth %&gt;% select(eversmoke_c, BMI) %&gt;% na.omit()\n\nggplot(plot.bmi.smoke, aes(x=eversmoke_c, y=BMI, fill=eversmoke_c)) +\n      geom_boxplot(width=.3) + geom_violin(alpha=.4) +\n      labs(x=\"Smoking status\") +\n      scale_fill_viridis_d(guide=FALSE) +\n      stat_summary(fun.y=\"mean\", geom=\"point\", size=3, pch=17, \n                   position=position_dodge(width=0.75))\n\n\n\n\n\n\n\n\n\nplot.bmi.smoke %&gt;% group_by(eversmoke_c) %&gt;%\n summarise(mean=mean(BMI, na.rm=TRUE),\n             sd = sd(BMI, na.rm=TRUE),\n             IQR = IQR(BMI, na.rm=TRUE))\n\n# A tibble: 2 × 4\n  eversmoke_c  mean    sd   IQR\n  &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Non Smoker   29.7  7.76  9.98\n2 Smoker       28.8  7.32  9.02\n\n\nSmokers have an average BMI of 28.8, smaller than the average BMI of non-smokers at 29.7. Nonsmokers have more variation in their BMIs (sd 7.8 v. 7.3 and IQR 9.98 v. 9.02), but the distributions both look normal, if slightly skewed right.\n3. Write the relationship you want to examine in the form of a research question.\n\nNull Hypothesis: There is no relationship between BMI and smoking status.\nAlternate Hypothesis: There is a relationship between BMI and smoking status.\n\n4. Perform an appropriate statistical analysis.\nI. Let \\(\\mu_1\\) denote the average BMI for nonsmokers, and \\(\\mu_2\\) the average BMI for smokers.\n\n\\(\\mu_1 - \\mu_2 = 0\\) There is no difference in the average BMI between smokers and nonsmokers. \\(\\mu_1 - \\mu_2 \\neq 0\\) There is a difference in the average BMI between smokers and nonsmokers.\nWe are comparing the means between two independent samples. A Two-Sample T-Test for a difference in means will be conducted. The assumptions that the groups are independent is upheld because each individual can only be either a smoker or nonsmoker. The difference in sample means \\(\\bar{x_1} - \\bar{x_2}\\) is normally distributed – this is a valid assumption due to the large sample size and that differences typically are normally distributed. The observations are independent, and the variability is roughly equal (IQR 9.9 v. 9.0).\nWe use the t.test function, but use model notation of the format outcome \\(\\sim\\) category. Here, BMI is our continuous outcome that we’re testing across the (binary) categorical predictor eversmoke_c.\n\n\nt.test(BMI ~ eversmoke_c, data=addhealth)\n\n\n    Welch Two Sample t-test\n\ndata:  BMI by eversmoke_c\nt = 3.6937, df = 3395.3, p-value = 0.0002245\nalternative hypothesis: true difference in means between group Non Smoker and group Smoker is not equal to 0\n95 percent confidence interval:\n 0.3906204 1.2744780\nsample estimates:\nmean in group Non Smoker     mean in group Smoker \n                29.67977                 28.84722 \n\n\nWe have very strong evidence against the null hypothesis, \\(p = 0.0002\\).\n5. Write a conclusion in the context of the problem.\nOn average, nonsmokers have a significantly higher BMI by 0.83 (0.39, 1.27) compared to nonsmokers (\\(p = 0.0002\\)).\n\n\n\n\n\n\nAlways check the output against the direction you are testing. R always will calculate a difference as group 1 - group 2, and it defines the groups alphabetically. For example, for a factor variable that has groups A and B, R will automatically calculate the difference as A-B. In this example it is Nonsmoker - Smoker.",
    "crumbs": [
      "Statistical Inference",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate_analysis.html#bv-anova",
    "href": "bivariate_analysis.html#bv-anova",
    "title": "5  Bivariate Analysis",
    "section": "5.4 (Q~C) Multiple means: ANOVA",
    "text": "5.4 (Q~C) Multiple means: ANOVA\nFrequently, a researcher wants to compare the means of an outcome across three or more treatments in a single experiment. We might initially think to do pairwise comparisons (1v2, 1v3, 2v3) for a total of three comparisons. However, this strategy can be treacherous. If we have many groups and do many comparisons, it is likely that we will eventually find a difference just by chance, even if there is no difference in the populations.\nWhen we analyze a conventional two-treatment experiment, we are prepared to run a 1 in 20 risk of an apparently significant result arising purely by accident (the 5% chance of a Type I error). We regard such a risk as being fairly unlikely and feel justified in accepting with confidence any significant results we obtain.\nAnalyzing a single experiment as a series of 10 treatment pairs is a very different proposition. The chance of an apparently significant result arising purely by chance somewhere in the 10 analyses increases dramatically. Using a 5% error rate, the chance of NOT making at Type I error is .95. To not make a Type I error 10 times is \\(.95^{10} = .6\\). That means there is a 40% chance of making a Type I error!\n\n\n\nSignificant - xkcd webcomic\n\n\n\n5.4.1 Example: Visual comparison\nExamine the figure below. Compare groups I, II, and III. Can you visually determine if the differences in the group centers is due to chance or not? What about groups IV, V, and VI?\n\n\n\nSide-by-side dot plot for the outcomes for six groups.\n\n\nSo we need some method of comparing treatments for more than two groups at a time. This is done using an Analysis of Variance (ANOVA) model.\n\n\n\n\n\n\nTerminology\n\n\n\n\nResponse Variable: The response variable in the ANOVA setting is the quantitative (continuous) variable that we want to compare among the different treatments.\nFactor/Treatment: A property or characteristic (categorical variable) that allows us to distinguish the different populations from one another. An independent variable to be studied in an investigation such as temperature, type of plant, color of flower, location.\nFactor/Treatment level: Factors have different levels, such as 3 temperatures, 5 locations, 3 colors, etc.\nWithin-sample Variation: Variation within a sample from one population. Individuals who receive the same treatment will experience identical experimental conditions. The variation within each of the treatment groups must therefore be a consequence of solely random variation.\nBetween-sample Variation: Variation between samples. This is the difference between the group means. If some treatments are genuinely more effective than others, then we would expect to see relatively large differences between the treatment means and a relatively large between-treatments variation.\n\n\n\n\n\n5.4.2 Formulation of the One-way ANOVA model\nANOVA is a mathematical technique which uses a model based approach to partition the variance in an experiment into different sources of variance. This technique enables us to test if most the variation in the treatment means is due to differences between the groups rather than random chance.\nStarting with our generic conceptual understanding of statistical models:\n\nDATA = MODEL + RESIDUAL\n\nour MODEL for this situation is the group membership. Does knowing what group an observation is in tell you about the location of the data? The one-way (or one-factor) ANOVA model is\n\\[\ny_{ij} = \\mu_{i} + \\epsilon_{ij} \\qquad \\qquad\n\\epsilon_{ij} \\overset{iid}{\\sim} \\mathcal{N}(0,\\sigma^{2})\n\\]\nfor \\(i=1, \\ldots, I\\) factor levels and \\(j = 1, \\ldots, n_{i}\\) subjects within each factor level. The random error terms are independently and identically distributed (iid) normally with common variance.\nThe null and alternative hypotheses are always phrased as follows:\n\n\\(H_0\\): The mean outcome is the same across all groups. \\(\\mu_1 = \\mu_2 = \\cdots = \\mu_k\\)\n\\(H_A\\): At least one mean is different.\n\nHow do we compare means using an ANalysis Of VAriance? By comparing the portion of the variance in the outcome that is explained by the groups, to the portion that’s leftover is due to unexplained randomness. Essentially we’re comparing the ratio of MODEL to RESIDUAL.\nThe total variation of the observed data is broken down into 2 parts:\n\nTotal Variation = Between Group Variation + Within Group Variation\n\nVariation is measured using the Sum of Squares (SS): The sum of the squares within a group (SSE), the sum of squares between groups (SSG), and the total sum of squares (SST).\nSSG (Between groups): Measures the variation of the \\(I\\) group means around the overall mean. \\[\n  SSG = \\sum_{i=1}^{I}n_{i}(\\bar{y}_{i.}-\\bar{y}..)^{2} = n_{1}(\\bar{y}_{1.}-\\bar{y}..)^{2} + n_{2}(\\bar{y}_{2.}-\\bar{y}..)^{2} + n_{3}(\\bar{y}_{3.}-\\bar{y}..)^{2}\n\\]\nSSE (Within group): Measures the variation of each observation around its group mean. \\[\nSSE = \\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}(y_{ij}-\\bar{y}_{i.})^{2} = \\sum_{i=1}^{I}(n_{i}-1)Var(Y_{i})\n\\]\nSST (Total): Measures the variation of the \\(N\\) data points around the overall mean. \\[\nSST =  \\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}(y_{ij}-\\bar{y}..)^{2} = (N-1)Var(Y)\n\\]\n\n\n5.4.3 Analysis of Variance table\nThe results of an analysis of variance test are always summarized in an ANOVA table. The format of an ANOVA table is as follows:\n\n\n\n\n\n\n\n\n\n\nSource\nSS\n\\(df\\)\nMS\nF\n\n\n\n\nGroups\nSSG\n\\(I-1\\)\nMSG = \\(\\frac{SSG}{I-1}\\ \\)\n\\(\\frac{MSG}{MSE}\\)\n\n\nError\nSSE\n\\(N-I\\)\nMSE = \\(\\frac{MSG}{N-I}\\ \\)\n\n\n\nTotal\nSST\n\\(N-1\\)\n\n\n\n\n\n\n\n5.4.4 The F-distribution\nThe \\(p\\)-value of the test is the area to the right of the F statistic density curve. This is always to the right because the F-distribution is not symmetric, truncated at 0 and skewed right. This is true regardless of the \\(df\\).\n\n\n\n\n\n\n\n\n\n\n\n5.4.5 Assumptions\nGenerally we must check three conditions on the data before performing ANOVA:\n\nThe observations are independent within and across groups\nThe data within each group are nearly normal\nThe variability across the groups is about equal.\n\nWhen these three conditions are met, we may perform an ANOVA to determine whether the data provide strong evidence against the null hypothesis that all the \\(\\mu_i\\) are equal.\n\n\n5.4.6 Example: A comparison of plant species under low water conditions\n\n\n\n\n\n\nThe PLANTS1 data file gives the percent of nitrogen in four different species of plants grown in a laboratory. The researchers collected these data in parts of the country where there is very little rainfall. To examine the effect of water, they varied the amount per day from 50mm to 650mm in 100mm increments. There were 9 plants per species-by-water combination. Because the plants are to be used primarily for animal food, with some parts that can be consumed by people, a high nitrogen content is very desirable. Let’s formally test to see if the nitrogen content in the plants differ across species.\n\n\n\n1. Identify response and explanatory variables.\n\nThe quantitative response variable is % nitrogen (pctnit)\nThe categorical explanatory variable is species (species)\n\n2. Visualize and summarize bivariate relationship.\n\nplot.nitrogen.species &lt;- plants1 %&gt;% select(species, pctnit) %&gt;% na.omit()\n\nggplot(plot.nitrogen.species, aes(x=species, y = pctnit, fill=species)) +\n      geom_boxplot(width=.3) + geom_violin(alpha=.4) +\n      labs(x=\"Species\") +\n      scale_fill_viridis_d(guide=FALSE) +\n      stat_summary(fun.y=\"mean\", geom=\"point\", size=3, pch=17,\n      position=position_dodge(width=0.75))\n\n\n\n\n\n\n\n\n\nplot.nitrogen.species %&gt;% group_by(species) %&gt;%\n summarise(mean=mean(pctnit, na.rm=TRUE),\n             sd = sd(pctnit, na.rm=TRUE),\n             IQR = IQR(pctnit, na.rm=TRUE)) %&gt;% kable()\n\n\n\n\nspecies\nmean\nsd\nIQR\n\n\n\n\n1\n3.039810\n0.2506118\n0.2690\n\n\n2\n2.092841\n0.2377523\n0.2725\n\n\n3\n3.284365\n0.3218599\n0.5065\n\n\n4\n1.195587\n0.2342217\n0.3125\n\n\n\n\n\nWhile the standard deviations are relatively similar across all species, the means are different (3.04 v. 2.09 v. 3.28 v. 1.20), with species 3 having the largest mean nitrogen content and species 4 the smallest. Species 3 has the highest IQR and species 1 has the lowest (0.506 v. 0.269).\n3. Write the relationship you want to examine in the form of a research question.\n\nNull Hypothesis: There is no difference in the average nitrogen content among plant species 1 through 4.\nAlternative Hypothesis: There is a difference in the average nitrogen content among plant species 1 through 4.\n\n4. Perform an appropriate statistical analysis.\nI. Let \\(\\mu_{1}\\), \\(\\ldots\\), \\(\\mu_{4}\\) be the mean nitrogen content in plant species 1 through 4 respectively.\n\n\\(H_{0}: \\mu_{1} = \\mu_{2} = \\mu_{3} = \\mu_{4}\\)\n\\(H_{A}:\\) At least one mean is different.\nWe are comparing means from multiple groups, so an ANOVA is the appropriate procedure. We need to check for independence, approximate normality and approximately equal variances across groups.\n\nIndependence: We are assuming that each plant was sampled independently of each other, and that the species themselves are independent of each other.\nNormality: With grouped data it’s easier to look at the histograms than qqplots.\n\nggplot(plants1, aes(x=pctnit, fill=species)) + ylab(\"\") + geom_density() + \n  facet_grid(species~.) +\n  theme(legend.position=\"bottom\") +\n  scale_y_continuous(breaks=NULL) + scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nThe distributions per group tend to follow an approximate normal distribution.\nEqual variances: One way to assess if the groups have approximately equal variances is by comparing the IQR across groups.\n\nplants1 %&gt;% group_by(species) %&gt;% summarise(IQR = IQR(pctnit), SD = sd(pctnit)) %&gt;% kable()\n\n\n\n\nspecies\nIQR\nSD\n\n\n\n\n1\n0.2690\n0.2506118\n\n\n2\n0.2725\n0.2377523\n\n\n3\n0.5065\n0.3218599\n\n\n4\n0.3125\n0.2342217\n\n\n\n\n\nThe IQRs are similar so assumption of equal variances is not grossly violated. We can proceed with the ANOVA procedure.\n\nWe use the aov(response ~ predictor) function on the relationship between the nitrogen levels and tree species. We then pipe in summary() to make the output display nicely.\n\n\naov(pctnit~species, data=plants1) %&gt;% summary()\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nspecies       3 172.39   57.46   827.5 &lt;2e-16 ***\nResiduals   248  17.22    0.07                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n5. Write a conclusion in the context of the problem. The results of the ANOVA test indicate that at least one species has a different average nitrogen content than the other varieties (\\(p&lt;\\).001).\n\n\n5.4.7 Coefficient of determination \\(R^{2}\\)\nThe coefficient of determination is defined as \\(R^{2} = \\frac{SSG}{SST}\\) and can be interpreted as the % of the variation seen in the outcome that is due to subject level variation within each of the treatment groups. The strength of this measure can be thought of in a similar manner as the correlation coefficient \\(r\\): \\(&lt; .3\\) indicates a poor fit, \\(&lt; .5\\) indicates a medium fit, and \\(&gt; .7\\) indicates a good fit.\n\n172.39/(172.39+17.22)*100\n\n[1] 90.9182\n\n\nA large amount (91%) of the variation seen in nitrogen content in the plant can be explained by the species of plant.\n\n\n5.4.8 Multiple Comparisons\nSuppose that an ANOVA test reveals that there is a difference in at least one of the means. How can we determine which groups are significantly different without increasing our chance of a Type I error?\nSimple! We perform all the pairwise comparisons but using a test statistic that retains a family-wise error rate of 0.05 (or our chosen \\(\\alpha\\)). There are different methods to adjust for multiple comparisons, we will be using the Tukey HSD (honest significant difference) test. Continuing on with the analysis of nitrogen across plant species.\n\nTukeyHSD(aov(pctnit~species, data=plants1))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = pctnit ~ species, data = plants1)\n\n$species\n          diff        lwr        upr   p adj\n2-1 -0.9469683 -1.0684156 -0.8255209 0.0e+00\n3-1  0.2445556  0.1231082  0.3660029 2.4e-06\n4-1 -1.8442222 -1.9656696 -1.7227748 0.0e+00\n3-2  1.1915238  1.0700764  1.3129712 0.0e+00\n4-2 -0.8972540 -1.0187014 -0.7758066 0.0e+00\n4-3 -2.0887778 -2.2102252 -1.9673304 0.0e+00\n\n\nThe results from Tukey’s HSD for all pairwise comparisons indicate that the average nitrogen content in one species is significantly different from each of the three other species. The nice benefit of this procedure is that the difference between the means of the two groups are compared, and a 95 percent confidence interval for each difference is included. So specifically, species 2 has on average 0.94 (0.82, 1.09) lower percent nitrogen compared to species 1 (\\(p&lt;.0001\\)). Also, species 3 has on average 1.19 (1.07, 1.31) higher percent nitrogen compared to species 2 (\\(p&lt;.0001\\)).",
    "crumbs": [
      "Statistical Inference",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate_analysis.html#bv-chisq",
    "href": "bivariate_analysis.html#bv-chisq",
    "title": "5  Bivariate Analysis",
    "section": "5.5 (C~C) Multiple Proportions: \\(\\chi^{2}\\)",
    "text": "5.5 (C~C) Multiple Proportions: \\(\\chi^{2}\\)\nRecall that the point estimates for the proportion of an event occurring is \\(\\frac{x}{n}\\), where \\(x\\) is the number of times the event occurs out of \\(n\\) records. In this section we we would like to make conclusions about the difference in two population proportions: \\(p_1 - p_2\\). In other words we’re testing the hypothesis that \\(p_{1}-p_{2}=0\\).\nOur estimate for the difference in proportions based on the sample is \\(\\hat{p}_1 - \\hat{p}_2\\). No surprise there. What is slightly different is that we use a pooled proportion to check the condition of normality, and to calculate the standard error of the estimate. This pooled proportion is calculated by pooling the number of events in both groups, divided by the effective sample size for those groups.\n\\[ \\hat{p} = \\frac{x_{1} + x_{2}}{n_{1}+n_{2}} \\]\nThen the standard error of the point estimate is calculated as\n\\[ \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n_1} + \\frac{\\hat{p}(1-\\hat{p})}{n_2}} \\]\nSo the equations for the Confidence Interval for the difference in proportions is,\n\\[\n\\left( \\hat{p}_{1} - \\hat{p}_{2} \\right) \\pm t_{\\frac{\\alpha}{2}, df}\n\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n_1} + \\frac{\\hat{p}(1-\\hat{p})}{n_2}}\n\\]\nwith test statistic, \\[\nt^{*} =  \\frac{\\left( \\hat{p}_{1} - \\hat{p}_{2} \\right) - d_{0}}\n        {\\left( \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n_1} + \\frac{\\hat{p}(1-\\hat{p})}{n_2}}\n        \\right )}\n\\]\n\n5.5.1 Conditions for the sampling distribution to be normal.\nThe difference \\(\\hat{p}_1 - \\hat{p}_2\\) tends to follow a normal model when 1) each proportion separately follows a normal model, and 2) the two samples are independent of each other. #1 can be verified by checking the success-failure condition for each group.\nThat means:\n\n\\(\\hat{p}n_{1} \\geq 10\\), AND\n\\(\\hat{p}n_{2} \\geq 10\\), AND\n\\(\\hat{q}n_{1} \\geq 10\\), AND\n\\(\\hat{q}n_{1} \\geq 10\\).\n\nWhere, if I’ve forgotten to mention it yet, \\(q = 1-p\\).\nWhen sample sizes are below 10, but still not super small, say like 5, we turn to the non-parameteric version of this test called a Fisher’s Exact Test.\n\n\n5.5.2 Example: Are Mammograms effective?\n\n\n\n\n\n\nThis example comes from the OpenIntro Statistics textbook (3rd ed).\nA 30-year study was conducted with nearly 90,000 female participants. Miller AB. 2014 During a 5-year screening period, each woman was randomized to one of two groups: in the first group, women received regular mammograms to screen for breast cancer, and in the second group, women received regular non-mammogram breast cancer exams. No intervention was made during the following 25 years of the study, and we’ll consider death resulting from breast cancer over the full 30-year period. Results from the study are summarized in the following table.\n\n\n\n\n\n\n\n\n\nAlive\nDead\nSum\n\n\n\n\nControl\n44405\n505\n44910\n\n\nMammogram\n44425\n500\n44925\n\n\nSum\n88830\n1005\n89835\n\n\n\n\n\n\n\n\nThe independent/explanatory variable is treatment (additional mammograms), and the dependent/response variable is death from breast cancer. Are these measures associated?\nIf mammograms are much more effective than non-mammogram breast cancer exams, then we would expect to see additional deaths from breast cancer in the control group (there is a relationship). On the other hand, if mammograms are not as effective as regular breast cancer exams, we would expect to see no difference in breast cancer deaths in the two groups (there is no relationship).\nWhat we need to do is to figure out how many deaths would be expected, if there was no relationship between treatment death by breast cancer, and then examine the residuals - the difference between the observed (\\(O_{ij}\\)) and expected (\\(E_{ij}\\)).\nIn our DATA = MODEL + RESIDUAL framework, the DATA is the observed counts \\(O_{ij}\\), and the MODEL is the expected counts \\(E_{ij}\\).\nTo see how the expected counts are calculated, we need to define a few more symbols, so we can find our way around the cells of a table. Just like rows and columns in a matrix, rows are indexed first (as \\(i\\) and columns indexed as \\(j\\)). So the cell in the top left is \\(i=1\\) and \\(j=1\\).\n\n\n\n\n\n\n\n\n\n\\(O_\n    {\n    i\n    j}\\)\nA l ive\nD ead\nT o tal\n\n\n\n\nM a mmo\n\\(n_\n                                                    {\n                                                    1\n                                                 1}\\)\n\\(n_\n                                                                                                                                                                      {\n                                                                                                                                                                      1\n                                                                                                                                                              2}\\) | \\(n_\n                                                                                                                                                                      {\n                                                                                                                                                                      1\n                                                                                                                                                                   .}\\)\n\n\n\n\nCo n t rol\n\\(n_\n                                                                                                                                                                      {\n                                                                                                                                                                      2\n                                                                                                                                                                   1}\\)\n\\(n_\n                                                                                                                                                                                                                                                                                                                                                                                                                   {\n                                                                                                                                                                                                                                                                                                                                                                                                                   2\n                                                                                                                                                                                                                                                                                                                                                                                                           2}\\) | \\(n_\n                                                                                                                                                                                                                                                                                                                                                                                                                   {\n                                                                                                                                                                                                                                                                                                                                                                                                                   2\n                                                                                                                                                                                                                                                                                                                                                                                                                .}\\)\n\n\nT o tal\n\\(n_\n                                                    {\n                                                    .\n                                                 1}\\)\n\\(n_\n                                                                                                                                                                      {\n                                                                                                                                                                      .\n                                                                                                                                                                   2}\\)\n\\(N\\)\n\n\n\nThe expected count for each cell is calculated as the row total times the column total for that cell, divided by the overall total. Yes this will end up as a fraction.\n\\[E_{ij} = \\frac{n_{i.}n_{.j}}{N}\\]\n\n\n\n\n\n\nAlive\nDead\n\n\n\n\nControl\n44407.58\n502.4161\n\n\nMammogram\n44422.42\n502.5839\n\n\n\n\n\n\n\nThe residuals are calculated as \\[ RESIDUALS = (O_{ij} - E_{ij})\\]\n\n\n\n\n\n\nAlive\nDead\n\n\n\n\nControl\n-0.0122616\n0.1152775\n\n\nMammogram\n0.0122596\n-0.1152583\n\n\n\n\n\n\n\nExamining the residuals can tell us which combinations had counts more or less observations than expected. If mammograms were not associated with survival, there were 0.01 fewer people still alive than expected, and 0.11 more people dead. This is trivially small (2 x 2) example with very large sample sizes. There will be another example provided later.\nThe \\(\\chi^2\\) test statistic is defined as the sum of the squared residuals, divided by the expected counts, and follows a \\(\\chi^2\\) distribution with degrees of freedom (#rows -1)(#cols -1).\n\\[ \\sum_{ij}\\frac{(O_{ij}-E_{ij})^{2}}{E_{ij}} \\]\nLike every other statistical test, large values of test statistics correspond to low p-values.\nBelow is a picture of the distribution for the current example. The p-value is reported on the left (vertically), the purple shaded area denotes the rejection region if we were using a hard cutoff of 0.05. (The rejection region is the area where the test statistic had to be at for a p-value to be smaller than .05.). For this example the test statistic was 0.017, which corresponds to a p-value of 0.895. Thus, this study does not provide enough evidence to support the claim that mammograms decrease the rate of deaths by breast cancer.\n\n\n\n\n\n\n\n\n\n\n\n5.5.3 Example: Smoking and General Health\nMore often than not, we will have the full data available. That is, data at each individual record not just a summary table like in the previous example. Let’s work through an example.\n\n\n\n\n\n\nUsing the Addhealth data set, what can we say about the relationship between smoking and a person’s perceived general level of general health?\n\n\n\n1. Identify response and explanatory variables.\n\nThe binary explanatory variable is whether the person has ever smoked an entire cigarette (eversmoke_c)\nThe categorical explanatory variable is the person’s general health (genhealth) and has levels “Excellent”, “Very Good”, “Good”, “Fair”, and “Poor”.\n\n2. Visualize and summarise bivariate relationship.\n\nsjPlot::plot_xtab(grp=addhealth$eversmoke_c, x=addhealth$genhealth, \n                  show.total = FALSE, margin=\"row\", legend.title=\"\") \n\n\n\n\n\n\n\n\nThe percentage of smokers seems to increase as the general health status decreases. Almost three-quarters (73%, n=40) of those reporting poor health have smoked an entire cigarette at least once in their life compared to 59% (n=573) of those reporting excellent health.\n3. Write the relationship you want to examine in the form of a research question.\nIs the proportion of those who have ever smoked equal across all levels of general health?\n\nNull Hypothesis: The proportion of smokers in each general health category is the same.\nAlternate Hypothesis: At least one proportion is different.\n\n4. Perform an appropriate statistical analysis.\nI. Define the parameters under consideration.\n\nLet \\(p_{1}\\) be the true proportion of smokers within the ``Excellent” health category.\nLet \\(p_{2}\\) be the true proportion of smokers within the ``Very good” health category.\nLet \\(p_{3}\\) be the true proportion of smokers within ``Good” health category.\nLet \\(p_{4}\\) be the true proportion of smokers within ``Fair” health category.\nLet \\(p_{5}\\) be the true proportion of smokers within ``Poor” health category.\n\n\n\\(H_{0}: p_{1} = p_{2} = p_{3} = p_{4} = p_{5}\\)\n\\(H_{A}:\\) At least one proportion is different.\nI will conduct a \\(\\chi\\)-squared test of association. There is at least 10 observations in each combination of smoking status and general health.\nConduct the test.\n\n\nhealth.smoke.model &lt;- chisq.test(addhealth$genhealth, addhealth$eversmoke_c)\nhealth.smoke.model\n\n\n    Pearson's Chi-squared test\n\ndata:  addhealth$genhealth and addhealth$eversmoke_c\nX-squared = 30.795, df = 4, p-value = 3.371e-06\n\n\nWe have strong evidence against the null; the \\(p\\)-value is less than .0001.\n5. Write a conclusion in context of the problem. We can conclude that there is an association between ever smoking a cigarette in their life and perceived general health (\\(\\chi^2\\) = 30.8, df=4, \\(p&lt;.0001\\)).\n\n\n5.5.4 Multiple Comparisons\nJust like with ANOVA, if we find that the chi-squared test indicates that at least one proportion is different from the others, it’s our job to figure out which ones might be different! We will analyze the residuals to accomplish this. Not by hand! Never again! You’re not learning how to code for nothing.\nThe residuals are automatically stored in the model output. You can either print them out and look at the values directly:\n\nhealth.smoke.model$residuals\n\n                   addhealth$eversmoke_c\naddhealth$genhealth Non Smoker     Smoker\n          Excellent  3.4461139 -2.5168277\n          Very good  0.4810893 -0.3513578\n          Good      -2.4431255  1.7843072\n          Fair      -1.0556365  0.7709714\n          Poor      -0.9446378  0.6899048\n\n\nOr you can extract them and save them as a data frame. Then use ggplot with geom_raster to fill in your squares.\n\nplot.residuals &lt;- health.smoke.model$residuals %&gt;% data.frame()\nggplot(plot.residuals, aes(x=addhealth.genhealth, y=addhealth.eversmoke_c)) +\n       geom_raster(aes(fill=Freq)) +  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\nThe proportion of those who have never smoked and report being in Excellent health is higher than expected if these two measures were independent (high positive residual means observed is greater than expected). A lower percent of people reporting Good health never smoked, which is lower than expected if smoking and health status were independent. So these two categories are likely to be the groups that have a different proportion of lifetime smoker \\(p_{i}\\) compared to the other groups.",
    "crumbs": [
      "Statistical Inference",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate_analysis.html#bv-corr",
    "href": "bivariate_analysis.html#bv-corr",
    "title": "5  Bivariate Analysis",
    "section": "5.6 (Q~Q) Correlation",
    "text": "5.6 (Q~Q) Correlation\nThe correlation coefficient is designated by \\(r\\) for the sample correlation, and \\(\\rho\\) for the population correlation. The correlation is a measure of the strength and direction of a linear relationship between two variables.\nThe correlation ranges from +1 to -1. A correlation of +1 means that there is a perfect, positive linear relationship between the two variables. A correlation of -1 means there is a perfect, negative linear relationship between the two variables. In both cases, knowing the value of one variable, you can perfectly predict the value of the second.\n\n5.6.1 Strength of the correlation\nHere are rough estimates for interpreting the strengths of correlations based on the magnitude of \\(r\\).\n\n\\(|r| \\geq 0.7\\): Very strong relationship\n\\(0.4 \\leq |r| &lt; 0.7\\): Strong relationship\n\\(0.3 \\leq |r| &lt; 0.4\\): Moderate relationship\n\\(0.2 \\leq |r| &lt; 0.3:\\) Weak relationship\n\\(|r| &lt; 0.2:\\) Negligible or no relationship\n\n\n\n5.6.2 Example: Federal spending per capita and poverty rate\n\n\n\n\n\n\n\nAdd intro text to example once resolved/replaced\n\n\n\n\n\n#ggplot(county, aes(x=poverty, y=fed_spend00)) +\n#  geom_point() + ylab(\"federal spending per capita\") +\n#  xlab(\"poverty rate\")\n#cor(county$poverty, county$fed_spend00, use=\"complete.obs\")\n\n\nThere is a negligible, positive, linear relationship between poverty rate and per capita federal spending (\\(r = 0.03\\)).\nLet \\(\\rho\\) denote the true correlation between poverty rate and federal spending per capita.\nOur null hypothesis is that there is no correlation between poverty rate and federal spending (\\(\\rho = 0\\)), and the alternative hypothesis is that they are correlated (\\(\\rho \\neq 0\\)).\nWe can use the cor.test() function to analyze the evidence in favor of this alternative hypothesis.\n\n\n#cor.test(county$poverty, county$fed_spend00)\n\nWe conclude from this that there was a non-statistically significant, negligible correlation between poverty and federal spending (\\(r = 0.03 (-0.0003, .069), p = 0.05\\)).",
    "crumbs": [
      "Statistical Inference",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "reg_intro.html",
    "href": "reg_intro.html",
    "title": "6  Introduction to Regression",
    "section": "",
    "text": "6.1 Opening Remarks\nThe PMA6 textbook (Chapter 7) goes into great detail on this topic, since regression is typically the basis for all advanced models.\nThe book also distinguishes between a “fixed-x” case, where the values of the explanatory variable \\(x\\) only take on pre-specified values, and a “variable-x” case, where the values of \\(x\\) are observations from a population distribution of X’s.\nThis latter case is what we will be concerning ourselves with.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to Regression</span>"
    ]
  },
  {
    "objectID": "sl_reg.html",
    "href": "sl_reg.html",
    "title": "7  Simple Linear Regression",
    "section": "",
    "text": "7.1 Example\nOne of the major early indicators of reduced respiratory function is FEV1 or forced expiratory volume in the first second (amount of air exhaled in 1 second). Since it is known that taller males tend to have higher FEV1, we wish to determine the relationship between height and FEV1. We can use regression analysis for both a descriptive and predictive purpose.\nggplot(fev, aes(y=FFEV1, x=FHEIGHT)) + geom_point() + \n      xlab(\"Height\") + ylab(\"FEV1\") + \n      ggtitle(\"Scatterplot and Regression line of FEV1 Versus Height for Males.\") + \n      geom_smooth(method=\"lm\", se=FALSE, col=\"blue\")\nIn this graph, height is given on the horizontal axis since it is the independent or predictor variable and FEV1 is given on the vertical axis since it is the dependent or outcome variable.\nInterpretation: There does appear to be a tendency for taller men to have higher FEV1. The regression line is also added to the graph. The line is tilted upwards, indicating that we expect larger values of FEV1 with larger values of height.\nSpecifically the equation of the regression line is \\[\nY = -4.087 + 0.118 X\n\\]\nThe quantity 0.118 in front of \\(X\\) is greater than zero, indicating that as we increase \\(X, Y\\) will increase. For example, we would expect a father who is 70 inches tall to have an FEV1 value of\n\\[\\mbox{FEV1} = -4.087 + (0.118) (70) = 4.173\\]\nIf the height was 66 inches then we would expect an FEV1 value of only 3.70.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "sl_reg.html#sec-slr-fev",
    "href": "sl_reg.html#sec-slr-fev",
    "title": "7  Simple Linear Regression",
    "section": "",
    "text": "Lung function data were obtained from an epidemiological study of households living in four areas with different amounts and types of air pollution. The data set used in this book is a subset of the total data. In this chapter we use only the data taken on the fathers, all of whom are nonsmokers (see PMA6 Appendix A for more details).\n\n\n\n\n\nDescriptive: Describing the relationship between FEV1 and height\nPredictive: Use the equation to determine expected or normal FEV1 for a given height\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaution on out of range predictions\n\n\n\nTo take an extreme example, suppose a father was 2 feet tall. Then the equation would predict a negative value of FEV1 (\\(-1.255\\)).\nA safe policy is to restrict the use of the equation to the range of the \\(X\\) observed in the sample.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "sl_reg.html#sec-mathematical-model",
    "href": "sl_reg.html#sec-mathematical-model",
    "title": "7  Simple Linear Regression",
    "section": "7.2 Mathematical Model",
    "text": "7.2 Mathematical Model\nThe mathematical model that we use for regression has three features.\n\n\\(Y\\) values are normally distributed at any given \\(X\\)\nThe mean of \\(Y\\) values at any given \\(X\\) follows a straight line \\(Y = \\beta_{0} + \\beta_{1} X\\).\nThe variance of \\(Y\\) values at any \\(X\\) is \\(\\sigma^2\\) (same for all X). This is known as homoscedasticity, or homogeneity of variance.\n\nMathematically this is written as:\n\\[\nY|X \\sim N(\\mu_{Y|X}, \\sigma^{2}) \\\\\n\\mu_{Y|X} = \\beta_{0} + \\beta_{1} X \\\\\nVar(Y|X) = \\sigma^{2}\n\\]\nand can be visualized as:\n\n\n\nFigure 6.2",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "moderation_stratification.html",
    "href": "moderation_stratification.html",
    "title": "8  Moderation and Stratification",
    "section": "",
    "text": "8.1 Moderation\nModeration occurs when the relationship between two variables depends on a third variable.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Moderation and Stratification</span>"
    ]
  },
  {
    "objectID": "moderation_stratification.html#moderation",
    "href": "moderation_stratification.html#moderation",
    "title": "8  Moderation and Stratification",
    "section": "",
    "text": "The third variable is referred to as the moderating variable or simply the moderator.\nThe moderator affects the direction and/or strength of the relationship between the explanatory (\\(x\\)) and response (\\(y\\)) variable.\n\nThis tends to be an important\n\nWhen testing a potential moderator, we are asking the question whether there is an association between two constructs, but separately for different subgroups within the sample.\n\nThis is also called a stratified model, or a subgroup analysis.\n\n\n\n8.1.1 Motivating Example - Admissions at UC Berkeley\nSometimes moderating variables can result in what’s known as Simpson’s Paradox. This has had legal consequences in the past at UC Berkeley.\nBelow are the admissions figures for Fall 1973 at UC Berkeley.\n\nTable of admissions rates at UC Berkeley in 1973\n\n\n\nApplicants\nAdmitted\n\n\n\n\nTotal\n12,763\n41%\n\n\nMen\n8,442\n44%\n\n\nWomen\n4,321\n35%\n\n\n\nIs there evidence of gender bias in college admissions? Do you think a difference of 35% vs 44% is too large to be by chance?\nDepartment specific data\n\nThe table of admissions rates for the 6 largest departments show a different story.\n\n\n\n\n\n\n\n\n\n\n\n\nAll\n\nMen\n\nWomen\n\n\n\nDepartment\nApplicants\nAdmitted\nApplicants\nAdmitted\nApplicants\nAdmitted\n\n\nA\n933\n64%\n825\n62%\n108\n82%\n\n\nB\n585\n63%\n560\n63%\n25\n68%\n\n\nC\n918\n35%\n325\n37%\n593\n34%\n\n\nD\n792\n34%\n417\n33%\n375\n35%\n\n\nE\n584\n25%\n191\n28%\n393\n24%\n\n\nF\n714\n6%\n373\n6%\n341\n7%\n\n\nTotal\n4526\n39%\n2691\n45%\n1835\n30%\n\n\n\nAfter adjusting for features such as size and competitiveness of the department, the pooled data showed a “small but statistically significant bias in favor of women”.\n\n\n8.1.2 Motivating Example: Association of flower parts\nLet’s explore the relationship between the length of the sepal in an iris flower, and the length (cm) of its petal.\n\noverall &lt;- ggplot(iris, aes(x=Sepal.Length, y=Petal.Length)) + \n                geom_point() + geom_smooth(se=FALSE) + \n                theme_bw()\n\nby_spec &lt;- ggplot(iris, aes(x=Sepal.Length, y=Petal.Length, col=Species)) + \n                  geom_point() + geom_smooth(se=FALSE) + \n                  theme_bw() + theme(legend.position=\"top\")\n\ngridExtra::grid.arrange(overall, by_spec , ncol=2)\n\n\n\n\n\n\n\n\nThe points are clearly clustered by species, the slope of the lowess line between virginica and versicolor appear similar in strength, whereas the slope of the line for setosa is closer to zero. This would imply that petal length for Iris setosa may not be affected by the length of the sepal.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Moderation and Stratification</span>"
    ]
  },
  {
    "objectID": "moderation_stratification.html#stratification",
    "href": "moderation_stratification.html#stratification",
    "title": "8  Moderation and Stratification",
    "section": "8.2 Stratification",
    "text": "8.2 Stratification\nStratified models fit the regression equations (or any other bivariate analysis) for each subgroup of the population.\nThe mathematical model describing the relationship between Petal length (\\(Y\\)), and Sepal length (\\(X\\)) for each of the species separately would be written as follows:\n\\[ Y_{is} \\sim \\beta_{0s} + \\beta_{1s}*x_{i} + \\epsilon_{is} \\qquad \\epsilon_{is} \\sim \\mathcal{N}(0,\\sigma^{2}_{s})\\] \\[ Y_{iv} \\sim \\beta_{0v} + \\beta_{1v}*x_{i} + \\epsilon_{iv} \\qquad \\epsilon_{iv} \\sim \\mathcal{N}(0,\\sigma^{2}_{v}) \\] \\[ Y_{ir} \\sim \\beta_{0r} + \\beta_{1r}*x_{i} + \\epsilon_{ir} \\qquad \\epsilon_{ir} \\sim \\mathcal{N}(0,\\sigma^{2}_{r}) \\]\nwhere \\(s, v, r\\) indicates species setosa, versicolor and virginica respectively.\nIn each model, the intercept, slope, and variance of the residuals can all be different. This is the unique and powerful feature of stratified models. The downside is that each model is only fit on the amount of data in that particular subset. Furthermore, each model has 3 parameters that need to be estimated: \\(\\beta_{0}, \\beta_{1}\\), and \\(\\sigma^{2}\\), for a total of 9 for the three models. The more parameters that need to be estimated, the more data we need.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Moderation and Stratification</span>"
    ]
  },
  {
    "objectID": "moderation_stratification.html#identifying-a-moderator",
    "href": "moderation_stratification.html#identifying-a-moderator",
    "title": "8  Moderation and Stratification",
    "section": "8.3 Identifying a moderator",
    "text": "8.3 Identifying a moderator\nHere are 3 scenarios demonstrating how a third variable can modify the relationship between the original two variables.\n\nSignificant –&gt; Non-Significant\n\nSignificant relationship at bivariate level\nWe expect the effect to exist in the entire population\nWithin at least one level of the third variable the strength of the relationship changes\nP-value is no longer significant within at least one subgroup\n\nNon-Significant –&gt; Significant\n\nNon-significant relationship at bivariate level\nWe do not expect the effect to exist in the entire population\nWithin at least one level of the third variable the relationship becomes significant\nP-value is now significant within at least one subgroup\n\nChange in Direction of Association\n\nSignificant relationship at bivariate level\nWe expect the effect to exist in the entire population\nWithin at least one level of the third variable the direction of the relationship changes\nMeans change order, positive to negative correlation etc.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Moderation and Stratification</span>"
    ]
  },
  {
    "objectID": "moderation_stratification.html#what-to-look-for-in-each-type-of-analysis",
    "href": "moderation_stratification.html#what-to-look-for-in-each-type-of-analysis",
    "title": "8  Moderation and Stratification",
    "section": "8.4 What to look for in each type of analysis",
    "text": "8.4 What to look for in each type of analysis\n\nANOVA - look at the \\(p\\)-value, \\(r\\)-squared, means, and the graph of the ANOVA and compare to those values in the Moderation (i.e., each level of third variable) output to determine if third variable is moderator or not.\nChi-Square - look at the \\(p\\)-value, the percents for the columns in the crosstab table, and the graph for the Chi-Square and compare to those values in the Moderation (i.e., each level of third variable) output to determine if third variable is a moderator or not.\nCorrelation and Linear Regression - look at the correlation coefficient (\\(r\\)), \\(p\\)-value, regression coefficients, \\(r\\)-squared, and the scatterplot. Compare to those values in the Moderation (i.e., each level of third variable) output to determine if third variable is a moderator or not.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Moderation and Stratification</span>"
    ]
  },
  {
    "objectID": "moderation_stratification.html#ex-correlation",
    "href": "moderation_stratification.html#ex-correlation",
    "title": "8  Moderation and Stratification",
    "section": "8.5 Ex: Correlation",
    "text": "8.5 Ex: Correlation\nCan we predict penguin body mass from the flipper length?\n\nggscatter(pen, x=\"flipper_length_mm\", y = \"body_mass_g\", add = \"reg.line\", \n          color = \"island\", ellipse = TRUE)\n\n\n\n\n\n\n\n\nProbably, but the relationship between flipper length and body mass changes depending on what island they are found on.\nOverall\n\ncor(pen$flipper_length_mm, pen$body_mass_g, use=\"pairwise.complete.obs\")\n\n[1] 0.8712018\n\n\nStratified by species\n\nby(pen, pen$species, function(x){\n  cor(x$flipper_length_mm, x$body_mass_g, use=\"pairwise.complete.obs\")\n})\n\npen$species: Adelie\n[1] 0.4682017\n------------------------------------------------------------ \npen$species: Chinstrap\n[1] 0.6415594\n------------------------------------------------------------ \npen$species: Gentoo\n[1] 0.7026665\n\n\nThere is a strong, positive, linear relationship (r=.87) between the flipper length and body mass of penguins when ignoring the species. This association is attenuated however within each species. Gentoo and Chinstrap still have strong correlations between flipper length and body mass, \\(r\\)=.70 and .64 respectively. However Adelie species penguins only have a moderate correlation with \\(r=.45\\).\nSo does Species moderate the relationship between flipper length and body mass? Visually we see a difference, but it is likely not statistically significant. More on how to determine that in Section 10.2.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Moderation and Stratification</span>"
    ]
  },
  {
    "objectID": "moderation_stratification.html#ex-regression",
    "href": "moderation_stratification.html#ex-regression",
    "title": "8  Moderation and Stratification",
    "section": "8.6 Ex: Regression",
    "text": "8.6 Ex: Regression\nLet’s explore the relationship between the length of the sepal in an iris flower, and the length (cm) of its petal.\n\noverall &lt;- ggplot(iris, aes(x=Sepal.Length, y=Petal.Length)) + \n                geom_point() + geom_smooth(se=FALSE) + \n                theme_bw()\n\nby_spec &lt;- ggplot(iris, aes(x=Sepal.Length, y=Petal.Length, col=Species)) + \n                  geom_point() + geom_smooth(se=FALSE) + \n                  theme_bw() + theme(legend.position=\"top\")\n\ngridExtra::grid.arrange(overall, by_spec , ncol=2)\n\n\n\n\n\n\n\n\nThe points are clearly clustered by species, the slope of the lowess line between virginica and versicolor appear similar in strength, whereas the slope of the line for setosa is closer to zero. This would imply that petal length for Setosa may not be affected by the length of the sepal.\nHow does the species change the regression equation?\nOverall\n\nlm(iris$Petal.Length ~ iris$Sepal.Length) |&gt; summary() |&gt; broom::tidy()\n\n# A tibble: 2 × 5\n  term              estimate std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)          -7.10    0.507      -14.0 6.13e-29\n2 iris$Sepal.Length     1.86    0.0859      21.6 1.04e-47\n\n\nStratified by species\n\nby(iris, iris$Species, function(x) {\n  lm(Petal.Length ~ Sepal.Length, data = x) |&gt; summary() |&gt; broom::tidy()\n  })\n\niris$Species: setosa\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)     0.803    0.344       2.34  0.0238\n2 Sepal.Length    0.132    0.0685      1.92  0.0607\n------------------------------------------------------------ \niris$Species: versicolor\n# A tibble: 2 × 5\n  term         estimate std.error statistic  p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     0.185    0.514      0.360 7.20e- 1\n2 Sepal.Length    0.686    0.0863     7.95  2.59e-10\n------------------------------------------------------------ \niris$Species: virginica\n# A tibble: 2 × 5\n  term         estimate std.error statistic  p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     0.610    0.417       1.46 1.50e- 1\n2 Sepal.Length    0.750    0.0630     11.9  6.30e-16\n\n\n\nOverall: -7.1 + 1.86x, significant positive slope p = 1.04x10-47\nSetosa: 0.08 + 0.13x, non-significant slope, p=.06\nVersicolor: 0.19 + 0.69x, significant positive slope p=2.6x10-10\nVirginica: 0.61 + 0.75x, significant positive slope p= 6.3x10-16\n\nSo we can say that iris species moderates the relationship between sepal and petal length.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Moderation and Stratification</span>"
    ]
  },
  {
    "objectID": "moderation_stratification.html#ex-anova",
    "href": "moderation_stratification.html#ex-anova",
    "title": "8  Moderation and Stratification",
    "section": "8.7 Ex: ANOVA",
    "text": "8.7 Ex: ANOVA\nIs the relationship between flipper length and species the same for each sex of penguin?\n\nggplot(pen, aes(x=flipper_length_mm, y=species, fill=species)) + \n      stat_slab(alpha=.5, justification = 0) + \n      geom_boxplot(width = .2,  outlier.shape = NA) + \n      geom_jitter(alpha = 0.5, height = 0.05) +\n      stat_summary(fun=\"mean\", geom=\"point\", col=\"red\", size=4, pch=17) + \n      theme_bw() + \n      labs(x=\"Flipper Length (mm)\", y = \"Species\", title = \"Overall\") + \n      theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\npen %&gt;% select(flipper_length_mm, species, sex) %&gt;% na.omit() %&gt;%\nggplot(aes(x=flipper_length_mm, y=species, fill=species)) + \n      stat_slab(alpha=.5, justification = 0) + \n      geom_boxplot(width = .2,  outlier.shape = NA) + \n      geom_jitter(alpha = 0.5, height = 0.05) +\n      stat_summary(fun=\"mean\", geom=\"point\", col=\"red\", size=4, pch=17) + \n      theme_bw() + \n      labs(x=\"Flipper Length (mm)\", y = \"Species\", title = \"Overall\") + \n      theme(legend.position = \"none\") + \n  facet_wrap(~sex)\n\n\n\n\n\n\n\n\nThe pattern of distributions of flipper length by species seems the same for both sexes of penguin. Sex is likely not a moderator. Let’s check the ANOVA anyhow.\nOverall\n\naov(pen$flipper_length_mm ~ pen$species) |&gt; summary()\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \npen$species   2  52473   26237   594.8 &lt;2e-16 ***\nResiduals   339  14953      44                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\nBy Sex\n\nby(pen, pen$sex, function(x) {\n  aov(x$flipper_length_mm ~ x$species) |&gt; summary()\n  })\n\n             Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nx$species     2 21415.6   10708  411.79 &lt; 2.2e-16 ***\nResiduals   162  4212.6      26                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n------------------------------------------------------------ \n             Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nx$species     2 29098.4 14549.2  384.37 &lt; 2.2e-16 ***\nResiduals   165  6245.6    37.9                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSex is not a modifier, the relationship between species and flipper length is the same within male and female penguins.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Moderation and Stratification</span>"
    ]
  },
  {
    "objectID": "moderation_stratification.html#ex-4-chi-squared",
    "href": "moderation_stratification.html#ex-4-chi-squared",
    "title": "8  Moderation and Stratification",
    "section": "8.8 Ex: 4 Chi-Squared",
    "text": "8.8 Ex: 4 Chi-Squared\nIdentify response, explanatory, and moderating variables\n\nCategorical response variable = Ever smoked (variable eversmoke_c)\nCategorical explanatory variable = General Health (variable genhealth)\nCategorical Potential Moderator = Gender (variable female5_c)\n\nVisualize the relationship between smoking and general health across the entire sample.\n\nplot_xtab(addhealth$genhealth, addhealth$eversmoke_c, \n          show.total = FALSE, margin = \"row\") + \n  ggtitle(\"Overall\")\n\n\n\n\n\n\n\n\n\nfem &lt;- addhealth %&gt;% filter(female_c == \"Female\")\nmal &lt;- addhealth %&gt;% filter(female_c == \"Male\")\n\nfem.plot &lt;- plot_xtab(fem$genhealth, fem$eversmoke_c, \n          show.total = FALSE, margin = \"row\") + \n  ggtitle(\"Females only\")\nmal.plot &lt;- plot_xtab(mal$genhealth, mal$eversmoke_c, \n          show.total = FALSE, margin = \"row\") + \n  ggtitle(\"Males only\")\n\ngridExtra::grid.arrange(fem.plot, mal.plot)\n\n\n\n\n\n\n\n\nA general pattern is seen where the proportion of smokers increases as the level of general health decreases. This pattern is similar within males and females, but it is noteworthy that a higher proportion of non smokers are female.\n\n\n\n\n\n\nInvestigate\n\n\n\nDoes being female change the relationship between smoking and general health? Is the distribution of smoking status (proportion of those who have ever smoked) equal across all levels of general health, for both males and females?\n\n\nFit both the original, and stratified models.\nOriginal\n\nchisq.test(addhealth$eversmoke_c, addhealth$genhealth)\n\n\n    Pearson's Chi-squared test\n\ndata:  addhealth$eversmoke_c and addhealth$genhealth\nX-squared = 30.795, df = 4, p-value = 3.371e-06\n\n\nStratified\n\nby(addhealth, addhealth$female_c, function(x) chisq.test(x$eversmoke_c, x$genhealth))\n\naddhealth$female_c: Male\n\n    Pearson's Chi-squared test\n\ndata:  x$eversmoke_c and x$genhealth\nX-squared = 19.455, df = 4, p-value = 0.0006395\n\n------------------------------------------------------------ \naddhealth$female_c: Female\n\n    Pearson's Chi-squared test\n\ndata:  x$eversmoke_c and x$genhealth\nX-squared = 19.998, df = 4, p-value = 0.0004998\n\n\nDetermine if the Third Variable is a moderator or not.\nThe relationship between smoking status and general health is significant in both the main effects and the stratified model. The distribution of smoking status across general health categories does not differ between females and males. Gender is not a moderator for this analysis.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Moderation and Stratification</span>"
    ]
  },
  {
    "objectID": "mlr.html",
    "href": "mlr.html",
    "title": "9  Multiple Linear Regression",
    "section": "",
    "text": "9.1 Mathematical Model\nThe mathematical model for multiple linear regression equates the value of the continuous outcome \\(y_{i}\\) to a linear combination of multiple predictors \\(x_{1} \\ldots x_{p}\\) each with their own slope coefficient \\(\\beta_{1} \\ldots \\beta_{p}\\).\n\\[ y_{i} = \\beta_{0} + \\beta_{1}x_{1i} + \\ldots + \\beta_{p}x_{pi} + \\epsilon_{i}\\]\nwhere \\(i\\) indexes the observations \\(i = 1 \\ldots n\\), and \\(j\\) indexes the number of parameters \\(j=1 \\ldots p\\). This linear combination is often written using summation notation: \\(\\sum_{i=1}^{p}X_{ij}\\beta_{j}\\).\nThe assumptions on the residuals \\(\\epsilon_{i}\\) still hold:\nIn matrix notation the linear combination of \\(X\\)’s and \\(\\beta\\)’s is written as \\(\\mathbf{x}_{i}^{'}\\mathbf{\\beta}\\), (the inner product between the vectors \\(\\mathbf{x}_{i}\\) and \\(\\mathbf{\\beta}\\)). Then the model is written as:\n\\[ \\textbf{y} = \\textbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon} ,\\]\nand we say the regression model relates \\(y\\) to a function of \\(\\textbf{X}\\) and \\(\\mathbf{\\beta}\\), where \\(\\textbf{X}\\) is a \\(n \\times p\\) matrix of \\(p\\) covariates on \\(n\\) observations and \\(\\mathbf{\\beta}\\) is a length \\(p\\) vector of regression coefficients.\nNote: Knowledge of Matricies or Linear Algebra is not required to conduct or understand multiple regression, but it is foundational and essential for Statistics and Data Science majors to understand the theory behind linear models.\nLearners in other domains should attempt to understand matricies at a high level, as some of the places models can fail is due to problems doing math on matricies.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "mlr.html#mathematical-model",
    "href": "mlr.html#mathematical-model",
    "title": "9  Multiple Linear Regression",
    "section": "",
    "text": "They have mean zero\n\nThey are homoscedastic, that is all have the same finite variance: \\(Var(\\epsilon_{i})=\\sigma^{2}&lt;\\infty\\)\n\nDistinct error terms are uncorrelated (Independent): \\(\\text{Cov}(\\epsilon_{i},\\epsilon_{j})=0,\\forall i\\neq j.\\)",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "mlr.html#parameter-estimation",
    "href": "mlr.html#parameter-estimation",
    "title": "9  Multiple Linear Regression",
    "section": "9.2 Parameter Estimation",
    "text": "9.2 Parameter Estimation\nRecall the goal of regression analysis is to minimize the unexplained/residual error. That is, to minimize the difference between the value of the dependent variable predicted by the model and the true value of the dependent variable.\n\\[ \\hat{y_{i}} - y_{i}, \\]\nwhere the predicted values \\(\\hat{y}_{i}\\) are calculated as\n\\[\\hat{y}_{i}  = \\sum_{i=1}^{p}X_{ij}\\beta_{j}\\]\nThe sum of the squared residual errors (the distance between the observed point \\(y_{i}\\) and the fitted value) now has the following form:\n\\[ \\sum_{i=1}^{n} |y_{i} - \\sum_{i=1}^{p}X_{ij}\\beta_{j}|^{2}\\]\nOr in matrix notation\n\\[ || \\mathbf{Y} - \\mathbf{X}\\mathbf{\\beta} ||^{2} \\]\nSolving this least squares problem for multiple regression requires knowledge of multivariable calculus and linear algebra, and so is left to a course in mathematical statistics.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "mlr.html#fitting-the-model",
    "href": "mlr.html#fitting-the-model",
    "title": "9  Multiple Linear Regression",
    "section": "9.3 Fitting the model",
    "text": "9.3 Fitting the model\nThe analysis in example Section 7.1 concluded that FEV1 in fathers significantly increases by 0.12 (95% CI:0.09, 0.15) liters per additional inch in height (p&lt;.0001). Looking at the multiple \\(R^{2}\\) (correlation of determination), this simple model explains 25% of the variance seen in the outcome \\(y\\).\nHowever, FEV tends to decrease with age for adults, so we should be able to predict it better if we use both height and age as independent variables in a multiple regression equation.\n\n\n\n\n\n\nThink about it\n\n\n\nWhat direction do you expect the slope coefficient for age to be? For height?\n\n\nFitting a regression model in R with more than 1 predictor is done by adding each variable to the right hand side of the model notation connected with a +.\n\nlm(FFEV1 ~ FAGE + FHEIGHT, data=fev)\n\n\nCall:\nlm(formula = FFEV1 ~ FAGE + FHEIGHT, data = fev)\n\nCoefficients:\n(Intercept)         FAGE      FHEIGHT  \n   -2.76075     -0.02664      0.11440",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "mlr.html#interpreting-coefficients",
    "href": "mlr.html#interpreting-coefficients",
    "title": "9  Multiple Linear Regression",
    "section": "9.4 Interpreting Coefficients",
    "text": "9.4 Interpreting Coefficients\nSimilar to simple linear regression, each \\(\\beta_{j}\\) coefficient is considered a slope. That is, the amount \\(Y\\) will change for every 1 unit increase in \\(X_{j}\\). In a multiple variable regression model, \\(b_{j}\\) is the estimated change in \\(Y\\) after controlling for other predictors in the model.\n\n9.4.1 Continuous predictors\n\nmlr.dad.model &lt;- lm(FFEV1 ~ FAGE + FHEIGHT, data=fev)\nsummary(mlr.dad.model)\n\n\nCall:\nlm(formula = FFEV1 ~ FAGE + FHEIGHT, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.34708 -0.34142  0.00917  0.37174  1.41853 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.760747   1.137746  -2.427   0.0165 *  \nFAGE        -0.026639   0.006369  -4.183 4.93e-05 ***\nFHEIGHT      0.114397   0.015789   7.245 2.25e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5348 on 147 degrees of freedom\nMultiple R-squared:  0.3337,    Adjusted R-squared:  0.3247 \nF-statistic: 36.81 on 2 and 147 DF,  p-value: 1.094e-13\n\nconfint(mlr.dad.model)\n\n                  2.5 %      97.5 %\n(Intercept) -5.00919751 -0.51229620\nFAGE        -0.03922545 -0.01405323\nFHEIGHT      0.08319434  0.14559974\n\n\n\nHolding height constant, a father who is one year older is expected to have a FEV value 0.03 (0.01, 0.04) liters less than another man (p&lt;.0001).\nHolding age constant, a father who is 1cm taller than another man is expected to have a FEV value of 0.11 (.08, 0.15) liter greater than the other man (p&lt;.0001).\n\nFor the model that includes age, the coefficient for height is now 0.11, which is interpreted as the rate of change of FEV1 as a function of height after adjusting for age. This is also called the partial regression coefficient of FEV1 on height after adjusting for age.\n\n\n9.4.2 Binary predictors\nBinary predictors (categorical variables with only 2 levels) get converted to a numeric binary indicator variable which only has the values 0 and 1. Whichever level gets assigned to be 0 is called the reference group or level. The regression estimate \\(b\\) then is the effect of being in group (\\(x=1\\)) compared to being in the reference (\\(x=0\\)) group.\nDoes gender also play a roll in FEV? Let’s look at how gender may impact or change the relationship between FEV and either height or age.\n\nNote, the fev data set is in wide form right now, with different columns for mothers and fathers. First I need to reshape the data into long format, so gender is it’s own variable.\n\n\n# a pivot_longer() probably would have worked here as well\nfev_long &lt;- data.frame(gender = c(fev$FSEX, fev$MSEX), \n                   fev1 = c(fev$FFEV1, fev$MFEV1), \n                   ht = c(fev$FHEIGHT, fev$MHEIGHT), \n                   age = c(fev$FAGE, fev$MAGE), \n                   area = c(fev$AREA, fev$AREA))\nfev_long$gender &lt;- factor(fev_long$gender, labels=c(\"M\", \"F\"))\nfev_long$area   &lt;- factor(fev_long$area, labels=c(\"Burbank\", \"Lancaster\", \"Long Beach\", \"Glendora\"))\n\nSo the model being fit looks like:\n\\[ y_{i} = \\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i} +\\beta_{3}x_{3i} + \\epsilon_{i}\\]\nwhere\n\n\\(x_{1}\\): Age\n\\(x_{2}\\): height\n\\(x_{3}\\): 0 if Male, 1 if Female\n\n\nlm(fev1 ~ age + ht + gender, data=fev_long)\n\n\nCall:\nlm(formula = fev1 ~ age + ht + gender, data = fev_long)\n\nCoefficients:\n(Intercept)          age           ht      genderF  \n   -2.24051     -0.02354      0.10509     -0.63775  \n\n\nIn this model gender is a binary categorical variable, with reference group “Male”. This is detected because the variable that shows up in the regression model output is genderF. So the estimate shown is for males, compared to females.\nNote that I DID NOT have to convert the categorical variable gender to a binary numeric variable before fitting it into the model. R (and any other software program) will do this for you already.\nThe regression equation for the model with gender is\n\\[ y = -2.24 - 0.02 age + 0.11 height - 0.64genderF \\]\n\n\\(b_{0}:\\) For a male who is 0 years old and 0 cm tall, their FEV is -2.24L.\n\\(b_{1}:\\) For every additional year older an individual is, their FEV1 decreases by 0.02L.\n\\(b_{2}:\\) For every additional cm taller an individual is, their FEV1 increases by 0.16L.\n\\(b_{3}:\\) Females have 0.64L lower FEV compared to males.\n\nNote: The interpretation of categorical variables still falls under the template language of “for every one unit increase in \\(X_{p}\\), \\(Y\\) changes by \\(b_{p}\\)”. Here, \\(X_{3}=0\\) for males, and 1 for females. So a 1 “unit” change is females compared to males.\n\n\n9.4.3 Categorical Predictors\nLet’s continue to model the FEV for individuals living in Southern California, but now we also consider the effect of city they live in. For those unfamiliar with the region, these cities represent very different environmental profiles.\n\ntable(fev_long$area)\n\n\n   Burbank  Lancaster Long Beach   Glendora \n        48         98         38        116 \n\n\nLet’s fit a model with area, notice again I do not do anything to the variable area itself aside from add it into the model.\n\nlm(fev1 ~ age + ht + gender + area, data=fev_long) |&gt; summary()\n\n\nCall:\nlm(formula = fev1 ~ age + ht + gender + area, data = fev_long)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.32809 -0.29573  0.00578  0.31588  1.37041 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -2.250564   0.752414  -2.991  0.00302 ** \nage            -0.022801   0.004151  -5.493 8.59e-08 ***\nht              0.103866   0.010555   9.841  &lt; 2e-16 ***\ngenderF        -0.642168   0.078400  -8.191 8.10e-15 ***\nareaLancaster   0.031549   0.084980   0.371  0.71072    \nareaLong Beach  0.061963   0.104057   0.595  0.55199    \nareaGlendora    0.121589   0.082097   1.481  0.13967    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4777 on 293 degrees of freedom\nMultiple R-squared:  0.6529,    Adjusted R-squared:  0.6458 \nF-statistic: 91.86 on 6 and 293 DF,  p-value: &lt; 2.2e-16\n\n\nExamine the coefficient names, areaLancaster, areaLong Beach and areaGlendora. Again R automatically take a categorical variable and turn it into a series of binary indicator variables where a 1 indicates if a person is from that area. Notice how someone from Burbank has 0’s for all of the three indicator variables, someone from Lancaster only has a 1 in the areaLancaster variable and 0 otherwise. And etc. for each other area.\n\n\n\n\n\n\nareaLancaster\nareaLong.Beach\nareaGlendora\narea\n\n\n\n\n1\n0\n0\n0\nBurbank\n\n\n51\n1\n0\n0\nLancaster\n\n\n75\n0\n1\n0\nLong Beach\n\n\n101\n0\n0\n1\nGlendora\n\n\n\n\n\n\nMost commonly known as “Dummy coding”. Not an informative term to use.\nBetter used term: Indicator variable\nMath notation: I(gender == “Female”).\nA.k.a “reference coding” or “one hot encoding”\nFor a nominal X with K categories, define K indicator variables.\n\nChoose a reference (referent) category:\nLeave it out\nUse remaining K-1 in the regression.\nOften, the largest category is chosen as the reference category.\n\n\nInterpreting the regression coefficients are going to be compared to the reference group. In this case, it is the Burbank area. Why Burbank? Because that is what R sees as the first level. If you want something different, you need to change the factor ordering.\n\nlevels(fev_long$area)\n\n[1] \"Burbank\"    \"Lancaster\"  \"Long Beach\" \"Glendora\"  \n\n\nThe mathematical model is now written as follows,\n\\[ Y_{i} = \\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i} +\\beta_{3}x_{3i} + \\beta_{4}x_{4i} + \\beta_{5}x_{5i} +\\beta_{6}x_{6i}\\epsilon_{i}\\]\nwhere\n\n\\(x_{1}\\): Age\n\\(x_{2}\\): height\n\\(x_{3}\\): 0 if Male, 1 if Female\n\\(x_{4}\\): 1 if living in Lancaster, 0 otherwise\n\\(x_{5}\\): 1 if living in Long Beach, 0 otherwise\n\\(x_{6}\\): 1 if living in Glendora, 0 otherwise\n\nFor someone living in Burbank, \\(x_{4}=x_{5}=x_{6} =0\\) so the model then is\n\\[Y_{i} = \\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i} +\\beta_{3}x_{3i} + \\epsilon_{i}\\]\nFor someone living in Lancaster, \\(x_{4}=1, x_{5}=0, x_{6} =0\\) so the model then is\n\\[\nY_{i} = \\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i} +\\beta_{3}x_{3i} + \\beta_{4}(1) \\\\\nY_{i} \\sim (\\beta_{0} + \\beta_{4}) + \\beta_{1}x_{i} + \\beta_{2}x_{2i} +\\beta_{3}x_{3i} \\epsilon_{i}\n\\]\nFor someone living in Long Beach, \\(x_{4}=0, x_{5}=1, x_{6} =0\\) so the model then is\n\\[\nY_{i} = \\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i} +\\beta_{3}x_{3i} + \\beta_{5}(1) \\\\\nY_{i} \\sim (\\beta_{0} + \\beta_{5}) + \\beta_{1}x_{i} + \\beta_{2}x_{2i} +\\beta_{3}x_{3i} \\epsilon_{i}\n\\]\nand the model for someone living in Glendora \\(x_{4}=0, x_{5}=0, x_{6} =1\\) is\n\\[\nY_{i} = \\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i} +\\beta_{3}x_{3i} + \\beta_{6}(1) \\\\\nY_{i} \\sim (\\beta_{0} + \\beta_{6}) + \\beta_{1}x_{i} + \\beta_{2}x_{2i} +\\beta_{3}x_{3i} \\epsilon_{i}\n\\]\nIn summary, each area gets it’s own intercept, but still has a common slope for all other variables.\n\\[y_{i.Burbank} = -2.25 - 0.023(age) + 0.10(ht) -0.64(female)\\] \\[y_{i.Lancaster} = -2.22 - 0.023(age) + 0.10(ht) -0.64(female)\\] \\[y_{i.Long.Beach} = -2.19 - 0.023(age) + 0.10(ht) -0.64(female)\\] \\[y_{i.Glendora} = -2.13 - 0.023(age) + 0.10(ht) -0.64(female)\\]\nLet’s look interpret the regression coefficients and their 95% confidence intervals from the main effects model again.\n\nlm(fev1 ~ age + ht + gender + area, data=fev_long) |&gt; tbl_regression()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\nage\n-0.02\n-0.03, -0.01\n&lt;0.001\n\n\nht\n0.10\n0.08, 0.12\n&lt;0.001\n\n\ngender\n\n\n\n\n\n\n\n\n    M\n—\n—\n\n\n\n\n    F\n-0.64\n-0.80, -0.49\n&lt;0.001\n\n\narea\n\n\n\n\n\n\n\n\n    Burbank\n—\n—\n\n\n\n\n    Lancaster\n0.03\n-0.14, 0.20\n0.7\n\n\n    Long Beach\n0.06\n-0.14, 0.27\n0.6\n\n\n    Glendora\n0.12\n-0.04, 0.28\n0.14\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\\(b_{4}\\): After controlling for age, height and gender, those that live in Lancaster have 0.03 (-0.14, 0.20) higher FEV1 compared to someone living in Burbank (p=0.7).\n\\(b_{5}\\): After controlling for age, height and gender, those that live in Long Beach have 0.06 (-0.14, 0.27) higher FEV1 compared to someone living in Burbank (p=0.6).\n\\(b_{6}\\): After controlling for age, height and gender, those that live in Glendora have 0.12 (-0.04, 0.28) higher FEV1 compared to someone living in Burbank (p=0.14).\n\nBeta coefficients for categorical variables are always interpreted as the difference between that particular level and the reference group.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "mlr.html#presenting-results",
    "href": "mlr.html#presenting-results",
    "title": "9  Multiple Linear Regression",
    "section": "9.5 Presenting results",
    "text": "9.5 Presenting results\nThe direct software output always tells you more information than what you are wanting to share with an audience. Here are some ways to “prettify” your regression output.\n\nbroom + knitrgtsummarydotwhisker\n\n\n\ntidy(mlr.dad.model) |&gt; kable(digits=3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-2.761\n1.138\n-2.427\n0.016\n\n\nFAGE\n-0.027\n0.006\n-4.183\n0.000\n\n\nFHEIGHT\n0.114\n0.016\n7.245\n0.000\n\n\n\n\n\n\n\n\ntbl_regression(mlr.dad.model)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\nFAGE\n-0.03\n-0.04, -0.01\n&lt;0.001\n\n\nFHEIGHT\n0.11\n0.08, 0.15\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nConsult the vignette for additional ways to modify the output to show measures such as AIC, \\(R^{2}\\) and the number of observations being used to fit the model.\n\n\nWith the function dwplot in the dotwhisker package we can create a forest plot.\n\ndwplot(mlr.dad.model)\n\n\n\n\n\n\n\n\nFurther improvement on dwplot - extract the point estimate & CI into a data table, then add it as a geom_text layer.\n\ntext &lt;- data.frame(                               # create a data frame\n  estimate = coef(mlr.dad.model),                 # by extracting the coefficients,\n  CI.low = confint(mlr.dad.model)[,1],            # with their lower\n  CI.high = confint(mlr.dad.model)[,2]) %&gt;%       # and upper confidence interval values\n  round(2)                                        # round digits\n\n# create the string for the label\ntext$label &lt;- paste0(text$estimate, \"(\", text$CI.low, \", \" , text$CI.high, \")\")\n\ntext                                              # view the results to check for correctness\n\n            estimate CI.low CI.high               label\n(Intercept)    -2.76  -5.01   -0.51 -2.76(-5.01, -0.51)\nFAGE           -0.03  -0.04   -0.01 -0.03(-0.04, -0.01)\nFHEIGHT         0.11   0.08    0.15    0.11(0.08, 0.15)\n\ntext &lt;- text[-1, ]                                # drop the intercept row\n\n# ---- create plot ------\nmlr.dad.model %&gt;%                                  # start with a model\n  tidy() %&gt;%                                       # tidy up the output\n  relabel_predictors(\"(Intercept)\" = \"Intercept\",  # convert to sensible names\n                     FAGE = \"Age\", \n                     FHEIGHT = \"Height\") %&gt;% \n  filter(term != \"Intercept\") %&gt;%                  # drop the intercept \n  dwplot() +                                       # create the ggplot \n  geom_text(aes(x=text$estimate, y = term,         # add the estimates and CI's\n                label = text$label), \n            nudge_y = .1) +                        # move it up a smidge\n  geom_vline(xintercept = 0, col = \"grey\",         # add a reference line at 0\n             lty = \"dashed\", linewidth=1.2) +      # make it dashed and a little larger\n  scale_x_continuous(limits = c(-.15, .15))        # expand the x axis limits for readability",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "mlr.html#confounding",
    "href": "mlr.html#confounding",
    "title": "9  Multiple Linear Regression",
    "section": "9.6 Confounding",
    "text": "9.6 Confounding\nOne primary purpose of a multivariable model is to assess the relationship between a particular explanatory variable \\(x\\) and your response variable \\(y\\), after controlling for other factors.\n\n\n\nAll the ways covariates can affect response variables\n\n\nCredit: A blog about statistical musings\n\n\n\n\n\n\nLearn more\n\n\n\nEasy to read short article from a Gastroenterology journal on how to control confounding effects by statistical analysis.\n\n\nOther factors (characteristics/variables) could also be explaining part of the variability seen in \\(y\\).\n\n\n\n\n\n\nConfounders\n\n\n\nIf the relationship between \\(x_{1}\\) and \\(y\\) is bivariately significant, but then no longer significant once \\(x_{2}\\) has been added to the model, then \\(x_{2}\\) is said to explain, or confound, the relationship between \\(x_{1}\\) and \\(y\\).\n\n\nSteps to determine if a variable \\(x_{2}\\) is a confounder.\n\nFit a regression model on \\(y \\sim x_{1}\\).\nIf \\(x_{1}\\) is not significantly associated with \\(y\\), STOP. Re-read the “IF” part of the definition of a confounder.\nFit a regression model on \\(y \\sim x_{1} + x_{2}\\).\nLook at the p-value for \\(x_{1}\\). One of two things will have happened.\n\nIf \\(x_{1}\\) is still significant, then \\(x_{2}\\) does NOT confound (or explain) the relationship between \\(y\\) and \\(x_{1}\\).\nIf \\(x_{1}\\) is NO LONGER significantly associated with \\(y\\), then \\(x_{2}\\) IS a confounder.\n\n\nThis means that the third variable is explaining the relationship between the explanatory variable and the response variable.\nNote that this is a two way relationship. The order of \\(x_{1}\\) and \\(x_{2}\\) is invariant. If you were to add \\(x_{2}\\) to the model before \\(x_{1}\\) you may see the same thing occur. That is - both variables are explaining the same portion of the variance in \\(y\\).",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "mlr.html#what-to-watch-out-for",
    "href": "mlr.html#what-to-watch-out-for",
    "title": "9  Multiple Linear Regression",
    "section": "9.7 What to watch out for",
    "text": "9.7 What to watch out for\n\nRepresentative sample\nRange of prediction should match observed range of X in sample\nUse of nominal or ordinal, rather than interval or ratio data\nErrors-in-variables\nCorrelation does not imply causation\nViolation of assumptions\nInfluential points\nAppropriate model\nMulticollinearity",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "model_building.html",
    "href": "model_building.html",
    "title": "10  Model Building",
    "section": "",
    "text": "10.1 Interactions (PMA6 8.8)\nIn this main effects model, Species only changes the intercept. The effect of species is not multiplied by Sepal length. Reviewing the scatterplot below, do you think this is a reasonable model to fit the observed relationship?\nggplot(iris, aes(x=Sepal.Length, y=Petal.Length, color = Species)) + \n  geom_point() + geom_smooth(method=\"lm\", se=FALSE)\nIf we care about how species changes the relationship between petal and sepal length, we can fit a model with an interaction between sepal length (\\(x_{1}\\)) and species. For this first example let \\(x_{2}\\) be an indicator for when species == setosa. Note that both main effects of sepal length, and setosa species are also included in the model. Interactions are mathematically represented as a multiplication between the two variables that are interacting.\n\\[ Y_{i} \\sim \\beta_{0} + \\beta_{1}x_{i} + \\beta_{2}x_{2i} + \\beta_{3}x_{1i}x_{2i}\\]\nIf we evaluate this model for both levels of \\(x_{2}\\), the resulting models are the same as the stratified models.\nWhen \\(x_{2} = 0\\), the record is on an iris not from the setosa species.\n\\[ Y_{i} \\sim \\beta_{0} + \\beta_{1}x_{i} + \\beta_{2}(0) + \\beta_{3}x_{1i}(0)\\] which simplifies to \\[ Y_{i} \\sim \\beta_{0} + \\beta_{1}x_{i}\\]\nWhen \\(x_{2} = 1\\), the record is on an iris of the setosa species.\n\\[ Y_{i} \\sim \\beta_{0} + \\beta_{1}x_{i} + \\beta_{2}(1) + \\beta_{3}x_{1i}(1)\\] which simplifies to \\[ Y_{i} \\sim (\\beta_{0} + \\beta_{2}) + (\\beta_{1} + \\beta_{3})x_{i}\\]\nEach subgroup model has a different intercept and slope, but we had to estimate 4 parameters in the interaction model, and 6 for the fully stratified model.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Building</span>"
    ]
  },
  {
    "objectID": "model_building.html#interactions-pma6-8.8",
    "href": "model_building.html#interactions-pma6-8.8",
    "title": "10  Model Building",
    "section": "",
    "text": "10.1.1 Fitting interaction models & interpreting coefficients\nInteractions are fit in R by simply multiplying * the two variables together in the model statement.\n\niris$setosa &lt;- ifelse(iris$Species == \"setosa\", 1, 0)\nlm(Petal.Length ~ Sepal.Length + setosa + Sepal.Length*setosa, data=iris) |&gt; tbl_regression()\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\nSepal.Length\n1.0\n0.91, 1.1\n&lt;0.001\n\n\nsetosa\n2.4\n0.61, 4.1\n0.008\n\n\nSepal.Length * setosa\n-0.90\n-1.2, -0.56\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nThe coefficient \\(b_{3}\\) for the interaction term is significant, confirming that species changes the relationship between sepal length and petal length. Thus, species is a moderator (see Chapter 8).\nInterpreting Coefficients\n\nIf \\(x_{2}=0\\), then the effect of \\(x_{1}\\) on \\(Y\\) simplifies to: \\(\\beta_{1}\\)\n\n\\(b_{1}\\) The effect of sepal length on petal length for non-setosa species of iris (setosa=0)\nFor non-setosa species, the petal length increases 1.03cm for every additional cm of sepal length.\n\nIf \\(x_{2}=1\\), then the effect of \\(x_{1}\\) on \\(Y\\) model simplifies to: \\(\\beta_{1} + \\beta_{3}\\)\n\nFor setosa species, the petal length increases by 1.03-0.9=0.13 cm for every additional cm of sepal length.\n\n\n\n\n\nThe main effects (\\(b_{1}\\), \\(b_{2}\\)) cannot be interpreted by themselves when there is an interaction in the model.\n\n\n\n\n10.1.2 Categorical Interaction variables\nLet’s up the game now and look at the full interaction model with a categorical version of species. Recall \\(x_{1}\\) is Sepal Length, \\(x_{2}\\) is the indicator for versicolor, and \\(x_{3}\\) the indicator for virginica . Refer to Section 9.4.3 for information on how to interpret categorical predictors as main effects.\n\\[ Y_{i} \\sim \\beta_{0} + \\beta_{1}x_{i} + \\beta_{2}x_{2i} + \\beta_{3}x_{3i} + \\beta_{4}x_{1i}x_{2i} + \\beta_{5}x_{1i}x_{3i}+\\epsilon_{i}\\]\n\nsummary(lm(Petal.Length ~ Sepal.Length + Species + Sepal.Length*Species, data=iris))\n\n\nCall:\nlm(formula = Petal.Length ~ Sepal.Length + Species + Sepal.Length * \n    Species, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.68611 -0.13442 -0.00856  0.15966  0.79607 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      0.8031     0.5310   1.512    0.133    \nSepal.Length                     0.1316     0.1058   1.244    0.216    \nSpeciesversicolor               -0.6179     0.6837  -0.904    0.368    \nSpeciesvirginica                -0.1926     0.6578  -0.293    0.770    \nSepal.Length:Speciesversicolor   0.5548     0.1281   4.330 2.78e-05 ***\nSepal.Length:Speciesvirginica    0.6184     0.1210   5.111 1.00e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2611 on 144 degrees of freedom\nMultiple R-squared:  0.9789,    Adjusted R-squared:  0.9781 \nF-statistic:  1333 on 5 and 144 DF,  p-value: &lt; 2.2e-16\n\n\nThe slope of the relationship between sepal length and petal length is calculated as follows, for each species:\n\nsetosa \\((x_{2}=0, x_{3}=0): b_{1}=0.13\\)\nversicolor \\((x_{2}=1, x_{3}=0): b_{1} + b_{2} + b_{4} = 0.13+0.55 = 0.68\\)\nvirginica \\((x_{2}=0, x_{3}=1): b_{1} + b_{3} + b_{5} = 0.13+0.62 = 0.75\\)\n\nCompare this to the estimates gained from the stratified model:\n\nby(iris, iris$Species, function(x){\n  lm(Petal.Length ~ Sepal.Length, data=x) %&gt;% coef()\n})\n\niris$Species: setosa\n (Intercept) Sepal.Length \n   0.8030518    0.1316317 \n------------------------------------------------------------ \niris$Species: versicolor\n (Intercept) Sepal.Length \n   0.1851155    0.6864698 \n------------------------------------------------------------ \niris$Species: virginica\n (Intercept) Sepal.Length \n   0.6104680    0.7500808 \n\n\nThey’re the same! Proof that an interaction is equivalent to stratification.\n\n\n10.1.3 Example 2\nWhat if we now wanted to include other predictors in the model? How does sepal length relate to petal length after controlling for petal width? We add the variable for petal width into the model:\n\nsummary(lm(Petal.Length ~ Sepal.Length + setosa + Sepal.Length*setosa + Petal.Width, data=iris))\n\n\nCall:\nlm(formula = Petal.Length ~ Sepal.Length + setosa + Sepal.Length * \n    setosa + Petal.Width, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.83519 -0.18278 -0.01812  0.17004  1.06968 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         -0.86850    0.27028  -3.213  0.00162 ** \nSepal.Length         0.66181    0.05179  12.779  &lt; 2e-16 ***\nsetosa               1.83713    0.62355   2.946  0.00375 ** \nPetal.Width          0.97269    0.07970  12.204  &lt; 2e-16 ***\nSepal.Length:setosa -0.61106    0.12213  -5.003 1.61e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2769 on 145 degrees of freedom\nMultiple R-squared:  0.9761,    Adjusted R-squared:  0.9754 \nF-statistic:  1478 on 4 and 145 DF,  p-value: &lt; 2.2e-16\n\n\nSo far, petal width, and the combination of species and sepal length are both significantly associated with petal length.\nNote of caution: Stratification implies that the stratifying variable interacts with all other variables. So if we were to go back to the stratified model where we fit the model of petal length on sepal length AND petal width, stratified by species, we would be implying that species interacts with both sepal length and petal width.\nE.g. the following stratified model\n\n\\(Y = A + B + C + D + C*D\\), when D=1\n\\(Y = A + B + C + D + C*D\\), when D=0\n\nis the same as the following interaction model:\n\n\\(Y = A + B + C + D + A*D + B*D + C*D\\)\n\n\n\n10.1.4 Example 3\nLet’s explore the relationship between income, employment status and depression. This example follows a logistic regression example from section Section 11.4.4.\nHere I create the binary indicators of lowincome (annual income &lt;$10k/year) and underemployed (part time or unemployed).\n\ndepress_clean$lowincome &lt;- ifelse(depress_clean$income &lt; 10, 1, 0)\ntable(depress_clean$lowincome, depress_clean$income, useNA=\"always\")\n\n      \n        2  4  5  6  7  8  9 11 12 13 15 16 18 19 20 23 24 25 26 27 28 31 32 35\n  0     0  0  0  0  0  0  0 17  2 18 24  1  1 25  3 25  2  1  1  1 19  1  1 24\n  1     7  8 10 12 18 14 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  &lt;NA&gt;  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n      \n       36 37 42 45 55 65 &lt;NA&gt;\n  0     1  1  1 15  9 10    0\n  1     0  0  0  0  0  0    0\n  &lt;NA&gt;  0  0  0  0  0  0    0\n\ndepress_clean$underemployed &lt;- ifelse(depress_clean$employ %in% c(\"PT\", \"Unemp\"), 1, 0 )\ntable(depress_clean$underemployed, depress_clean$employ, useNA=\"always\")\n\n      \n         1   2   3   4   5   6   7 &lt;NA&gt;\n  0    167  42  14  38  27   2   4    0\n  &lt;NA&gt;   0   0   0   0   0   0   0    0\n\n\nThe Main Effects model assumes that the effect of income on depression is independent of employment status, and the effect of employment status on depression is independent of income.\n\nme_model &lt;- glm(cases ~ lowincome + underemployed, data=depress_clean, family=\"binomial\")\nsummary(me_model)\n\n\nCall:\nglm(formula = cases ~ lowincome + underemployed, family = \"binomial\", \n    data = depress_clean)\n\nCoefficients: (1 not defined because of singularities)\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -1.6393     0.1902  -8.618   &lt;2e-16 ***\nlowincome       0.1684     0.3294   0.511    0.609    \nunderemployed       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 268.12  on 293  degrees of freedom\nResidual deviance: 267.87  on 292  degrees of freedom\nAIC: 271.87\n\nNumber of Fisher Scoring iterations: 4\n\n\nTo formally test whether an interaction term is necessary, we add the interaction term into the model and assess whether the coefficient for the interaction term is significantly different from zero.\n\nme_intx_model &lt;- glm(cases ~ lowincome + underemployed + lowincome*underemployed, data=depress_clean, family=\"binomial\") \nsummary(me_intx_model)\n\n\nCall:\nglm(formula = cases ~ lowincome + underemployed + lowincome * \n    underemployed, family = \"binomial\", data = depress_clean)\n\nCoefficients: (2 not defined because of singularities)\n                        Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              -1.6393     0.1902  -8.618   &lt;2e-16 ***\nlowincome                 0.1684     0.3294   0.511    0.609    \nunderemployed                 NA         NA      NA       NA    \nlowincome:underemployed       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 268.12  on 293  degrees of freedom\nResidual deviance: 267.87  on 292  degrees of freedom\nAIC: 271.87\n\nNumber of Fisher Scoring iterations: 4",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Building</span>"
    ]
  },
  {
    "objectID": "model_building.html#sec-general-F",
    "href": "model_building.html#sec-general-F",
    "title": "10  Model Building",
    "section": "10.2 Simultaneous test of multiple variables (PMA6 9.5)",
    "text": "10.2 Simultaneous test of multiple variables (PMA6 9.5)\nThe General-F test is used for simultaneous tests of \\(Q\\) variables in a model. This is used primarily in two situations:\n\nTesting if a categorical variable (with more than 2 levels) as a whole improves model fit.\nTesting whether or not the regression model is helpful in predicting values of Y at all.\n\nConsider a model with \\(P\\) variables and you want to test if \\(Q\\) additional variables are useful.\n\n\\(H_{0}: Q\\) additional variables are useless, i.e., their \\(\\beta\\)’s all = 0\n\n\\(H_{A}: Q\\) additional variables are useful to explain/predict \\(Y\\)\n\nWe can leverage the ANOVA framework to compare the residual sum of squares between the model including the \\(Q\\) variables, and the one without.\n\\[\nF = \\frac{({\\mbox{RSS}}_P-{\\mbox{RSS}_{P+Q})}/Q}{{\\mbox\n{RSS}}_{P+Q}{/}(N-P-Q-1)}\n\\]\nThe numerator quantifies improvement in the model from adding the additional \\(Q\\) variables. This ratio has a \\(F\\) distribution with \\(Q\\) and \\(N-P-Q-1\\) degrees of freedom.\n\n\n\n\n\n\nExample\n\n\n\nConsider the following model, where \\(X_{1}\\) and \\(X_{2}\\) are continuous predictors and \\(X_{3}, X_{4}, X_{5}\\) are binary indicators from a 4 level categorical variable.\n\n\n\\[\nY = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + \\beta_{4}x_{4} + \\beta_{5}X_{5}+\\epsilon_{i}\n\\]\nIf you wanted to test (1) whether or not the categorical variable as a whole improves model fit, then \\(\\mathbf{R} =\n\\begin{bmatrix}\n0 , 0 ,1,1,1\n\\end{bmatrix}\\)\nIf we want to test (2) that the regression plane is useful to predict \\(Y\\), then we are testing \\(\\beta_{1}=\\beta_{2}=...\\beta_{5}=0\\), then \\(\\mathbf{R} =\n\\begin{bmatrix}\n1 , 1 ,1,1,1\n\\end{bmatrix}\\).\n\n10.2.1 Example: Modeling depression score\nConsider a model to predict depression using age, employment status and whether or not the person was chronically ill in the past year as covariates. This example uses the cleaned depression data set.\n\nemploy.depression.model &lt;- lm(cesd ~ age + chronill + employ, data=depress_clean)\nsummary(employ.depression.model)\n\n\nCall:\nlm(formula = cesd ~ age + chronill + employ, data = depress_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.907  -5.601  -2.065   3.142  32.753 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 11.14724    1.33736   8.335 3.14e-15 ***\nage         -0.14439    0.03043  -4.745 3.28e-06 ***\nchronill     2.27884    1.01165   2.253    0.025 *  \nemploy       1.42030    0.34798   4.082 5.79e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.429 on 290 degrees of freedom\nMultiple R-squared:  0.09677,   Adjusted R-squared:  0.08742 \nF-statistic: 10.36 on 3 and 290 DF,  p-value: 1.703e-06\n\n\nThe results of this model show that age and chronic illness are statistically associated with CESD (each p&lt;.006). However employment status shows mixed results. Some employment statuses are significantly different from the reference group, some are not. So overall, is employment status associated with depression?\n(1) Testing if a categorical variable as a whole improves model fit\nSince employment is a categorical variable, all the coefficient estimates shown are the effect of being in that income category has on depression compared to being employed full time. For example, the coefficient for PT employment is greater than zero, so they have a higher CESD score compared to someone who is fully employed.\nTo test that employment status affects CESD we need to do a global test that all \\(\\beta\\)’s related to employment status are 0.\n\\(H_{0}: \\beta_{3} = \\beta_{4} = \\beta_{5} = \\beta_{6} = \\beta_{7} = \\beta_{8} = 0\\)\n\\(H_{A}\\): At least one \\(\\beta_{j}\\) is not 0.\nANOVA to the rescue! Since ANOVA partitions the variance in our outcome \\(Y\\) into amounts due to each variable, we get an ANOVA table that has one row per term:\n\naov(employ.depression.model) %&gt;% summary()\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nage           1    615   614.6   8.651  0.00353 ** \nchronill      1    409   409.2   5.759  0.01703 *  \nemploy        1   1184  1183.6  16.659 5.79e-05 ***\nResiduals   290  20605    71.1                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe last row for employ is what we are interested in here.\nFirst confirm that the degrees of freedom are correct. It should equal the # of categories in the variable you are testing, minus 1.\n\nEmployment has 7 levels, so \\(df=6\\).\nOr equivalently, the degrees of freedom are the number of \\(beta\\)’s you are testing to be 0.\n\n\nThe p-value of this Wald test is significant, thus not \\(beta\\)’s are equal to zero, which implies employment status significantly predicts CESD score.\n\n\n\nNote the p-values for the individual coefficients age and chronill are not the same as in the regression model. ANOVA models are order dependent as they describe a “reduction” in variance in the outcome due to that variable. A deeper explanation of this is not included in these notes at this time.\n\n\n(2) Testing that the regression plane is useful to predict \\(Y\\)\nThis information is provided to us directly in the last line of the summary output from a linear model.\n\nsummary(employ.depression.model)\n\n\nCall:\nlm(formula = cesd ~ age + chronill + employ, data = depress_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.907  -5.601  -2.065   3.142  32.753 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 11.14724    1.33736   8.335 3.14e-15 ***\nage         -0.14439    0.03043  -4.745 3.28e-06 ***\nchronill     2.27884    1.01165   2.253    0.025 *  \nemploy       1.42030    0.34798   4.082 5.79e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.429 on 290 degrees of freedom\nMultiple R-squared:  0.09677,   Adjusted R-squared:  0.08742 \nF-statistic: 10.36 on 3 and 290 DF,  p-value: 1.703e-06\n\n\n\n\n10.2.2 Testing for a moderation effect in a multiple regression model.\nModeration is introduced in Chapter 8, and helps to set the motivation for stratified models. Later, in Section 10.1.2, we show that an interaction term in a regression model is equivalent to stratification.\nWell what if you have other predictors in the model, not just the ones that you have an interaction on? We can use the Wald test to assess if a measure is a significant moderator without stratifying.\nContinuing with the depression example, we saw that employment affects CESD depression score. What if we think that the effect (slope) of age on CESD may be different depending on their employment? That is, is the effect of age on depression different for those that are employed versus retired?\n\nemp.dep.intx &lt;- lm(cesd ~ age + chronill + employ + age*employ, data=depress_clean)\nsummary(emp.dep.intx)\n\n\nCall:\nlm(formula = cesd ~ age + chronill + employ + age * employ, data = depress_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.207  -5.506  -2.057   3.125  33.450 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  8.21730    2.50270   3.283  0.00115 **\nage         -0.07501    0.05861  -1.280  0.20170   \nchronill     2.29855    1.01016   2.275  0.02361 * \nemploy       2.67061    0.96780   2.759  0.00616 **\nage:employ  -0.02664    0.01924  -1.384  0.16737   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.416 on 289 degrees of freedom\nMultiple R-squared:  0.1027,    Adjusted R-squared:  0.0903 \nF-statistic: 8.271 on 4 and 289 DF,  p-value: 2.501e-06\n\n\nLet’s revisit our list of beta coefficients:\n\n\\(\\beta_{1}\\): Age\n\\(\\beta_{2}\\): Chronic illness\n\\(\\beta_{3} \\ldots \\beta_{7}\\): Effects of different levels of employment (Houseperson to Unemployed)\n\\(\\beta_{8} \\ldots \\beta_{12}\\): Multiplicative effect that levels of employment have on the slope of age.\n\nTo see if the interaction term age*employ is significant, we run an F test via aov() and interpret the p-value for the interaction term age:employ. Here the p-value is very large, so there is no reason to believe that employment moderates the relationship between age and CESD score. This is a two way relationship. There is also no reason to believe that age moderates the relationship between employment and CESD score.\n\naov(emp.dep.intx) |&gt; summary()\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nage           1    615   614.6   8.678  0.00348 ** \nchronill      1    409   409.2   5.778  0.01686 *  \nemploy        1   1184  1183.6  16.712 5.64e-05 ***\nage:employ    1    136   135.7   1.916  0.16737    \nResiduals   289  20469    70.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis last table is also known as a “Two Factor” or “Two way” ANOVA with an interaction term. This is quite often used in scientific experiments where two treatments (and their combination) is being investigated.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Building</span>"
    ]
  },
  {
    "objectID": "model_building.html#multicollinearity-pma6-8.9",
    "href": "model_building.html#multicollinearity-pma6-8.9",
    "title": "10  Model Building",
    "section": "10.3 Multicollinearity (PMA6 8.9)",
    "text": "10.3 Multicollinearity (PMA6 8.9)\n\nOccurs when some of the X variables are highly intercorrelated.\nComputed estimates of regression coefficients are unstable and have large standard errors.\n\nFor example, the squared standard error of the \\(i\\)th slope coefficient (\\([SE(\\beta_{i})]^2\\)) can be written as:\n\\[\n[SE(\\beta_{i})]^2 = \\frac{S^{2}}{(N-1)(S_{i}^{2})}*\\frac{1}{1 - (R_{i})^2}\n\\]\nwhere \\(S^{2}\\) is the residual mean square, \\(S_{i}\\) the standard deviation of \\(X_{i}\\), and \\(R_{i}\\) the multiple correlation between \\(X_{i}\\) and all other \\(X\\)’s.\nWhen \\(R_{i}\\) is close to 1 (very large), \\(1 - (R_{i})^2\\) becomes close to 0, which makes \\(\\frac{1}{1 - (R_{i})^2}\\) very large.\nThis fraction is called the variance inflation factor and is available in most model diagnostics.\n\nbig.pen.model &lt;- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, data=pen) \nperformance::check_collinearity(big.pen.model) |&gt; plot()\n\n\n\n\n\n\n\n\n\nSolution: use variable selection to delete some X variables.\nAlternatively, use dimension reduction techniques such as Principal Components (Chapter 14).",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Building</span>"
    ]
  },
  {
    "objectID": "model_building.html#variable-selection-process",
    "href": "model_building.html#variable-selection-process",
    "title": "10  Model Building",
    "section": "10.4 Variable Selection Process",
    "text": "10.4 Variable Selection Process\n\n\n\n\n\n\nCorresponding text\n\n\n\nPMA6 Ch 9\n\n\nVariable selection methods such as the ones described in this section, are most often used when performing an Exploratory analysis, where many independent variables have been measured, but a final model to explain the variability of a dependent variable has not yet been determined.\nWhen building a model, we want to choose a set of independent variables that both will yield a good prediction using as few variables as possible (parsimony). We also need to consider controlling for moderators and confounders. In many situations where regression is used, the investigator has strong justification for including certain variables in the model.\n\nprevious studies\naccepted theory\n\nThe investigator may have prior justification for using certain variables but may be open to suggestions for the remaining variables.\nThe set of independent variables can be broken down into logical subsets\n\nFactors of primary interest. (such as an exposure or treatment)\nPotential confounders. These are measures that could be associated with both the response, and explanatory variables, and which could explain the relationship between the primary factor of interest and the outcome. These are typically a set of demographics such as age, gender, ethnicity, and tend to be factors found to be important in prior studies.\nEffect Modifiers (Moderators). A set of variables that other studies have shown to change or affect the relationship between the explanatory and response variables.\nPrecision variables (covariates). Variables associated with the dependent variable, but not the primary factor of interest.\n\nHow variables are chosen for inclusion into a model is heavily driven by the purpose of the model:\n\ndescriptive\npredictive\n\n\n10.4.1 Automated selection procedures (PMA6 9.6)\n\n\n\n\n\n\nExample\n\n\n\nThis example uses the penguins data to model the body mass\n\n\n\n\n\n\n\n\nThe model fitting must apply the models to the same dataset. This may be a problem if there are missing values. We suggest you remove the missing values first. (From the R help file)\n\n\n\n\npen.nomiss &lt;- pen %&gt;% na.omit()\n\nForward selection: Variables are added one at a time until optimal model reached.\n\nChoose the variable with the highest absolute correlation \\(\\mid r \\mid\\) with the outcome.\nChoose the next variable that maximizes the model adjusted \\(R^{2}\\).\nRepeat until adding additional variables does not improve the model fit significantly.\n\nBackward elimination: Variables are removed one at a time until optimal model reached\n\nPut all variables into the model.\nRemove the least useful variable in the model. This can be done by choosing the variable with the largest \\(p\\)-value.\nRepeat until removing additional variables reduces the model fit significantly.\n\nStepwise selection: Combination of forward and backward.\n\nStart with no variables (just \\(\\bar{Y}\\))\nAdd the variable that results in the greatest improvement in model fit.\nAdd another variable that results in the greatest improvement in model fit after controlling for the first.\nCheck to see if removing any variable currently in the model improves the fit.\nAdd another variable…\nCheck to remove variables…\nRepeat until no variables can be added or removed.\n\nMost programs have the option to force variables to be included in the model. This is important in cases where there is a primary factor of interest such as a treatment effect.\nDoing stepwise selection in R\nFirst you need to specify your null model - just the outcome, no covariates, and the full model - the outcome against ALL of your covariates.\n\nnull.model &lt;- lm(body_mass_g ~ 1, data=pen.nomiss)\nfull.model &lt;- lm(body_mass_g ~ ., data=pen.nomiss)\n\n\nForward selectionBackward selectionStepwise\n\n\n\nstep(null.model, \n     scope=list(lower=null.model, upper=full.model),\n     direction='forward', trace=1) |&gt; summary()\n\nStart:  AIC=4457.28\nbody_mass_g ~ 1\n\n                    Df Sum of Sq       RSS    AIC\n+ flipper_length_mm  1 164047703  51211963 3981.1\n+ species            2 145190219  70069447 4087.5\n+ island             2  83740680 131518986 4297.2\n+ bill_length_mm     1  74792533 140467133 4317.1\n+ bill_depth_mm      1  47959592 167300074 4375.3\n+ sex                1  38878897 176380769 4392.9\n&lt;none&gt;                           215259666 4457.3\n+ year               1    102884 215156782 4459.1\n\nStep:  AIC=3981.13\nbody_mass_g ~ flipper_length_mm\n\n                 Df Sum of Sq      RSS    AIC\n+ sex             1   9416589 41795374 3915.5\n+ species         2   5368818 45843144 3948.3\n+ island          2   3437527 47774435 3962.0\n+ year            1   2666295 48545668 3965.3\n+ bill_depth_mm   1    338887 50873075 3980.9\n&lt;none&gt;                        51211963 3981.1\n+ bill_length_mm  1    140000 51071963 3982.2\n\nStep:  AIC=3915.47\nbody_mass_g ~ flipper_length_mm + sex\n\n                 Df Sum of Sq      RSS    AIC\n+ species         2  13141806 28653568 3793.8\n+ island          2   6037165 35758209 3867.5\n+ bill_depth_mm   1   3667377 38127997 3886.9\n+ year            1   2276715 39518658 3898.8\n&lt;none&gt;                        41795374 3915.5\n+ bill_length_mm  1    144990 41650383 3916.3\n\nStep:  AIC=3793.76\nbody_mass_g ~ flipper_length_mm + sex + species\n\n                 Df Sum of Sq      RSS    AIC\n+ bill_depth_mm   1   1196096 27457472 3781.6\n+ bill_length_mm  1    780776 27872792 3786.6\n+ year            1    474080 28179488 3790.2\n&lt;none&gt;                        28653568 3793.8\n+ island          2     61695 28591873 3797.0\n\nStep:  AIC=3781.56\nbody_mass_g ~ flipper_length_mm + sex + species + bill_depth_mm\n\n                 Df Sum of Sq      RSS    AIC\n+ bill_length_mm  1    541825 26915647 3776.9\n+ year            1    272828 27184644 3780.2\n&lt;none&gt;                        27457472 3781.6\n+ island          2     59488 27397984 3784.8\n\nStep:  AIC=3776.93\nbody_mass_g ~ flipper_length_mm + sex + species + bill_depth_mm + \n    bill_length_mm\n\n         Df Sum of Sq      RSS    AIC\n+ year    1    319160 26596486 3775.0\n&lt;none&gt;                26915647 3776.9\n+ island  2     56214 26859432 3780.2\n\nStep:  AIC=3774.95\nbody_mass_g ~ flipper_length_mm + sex + species + bill_depth_mm + \n    bill_length_mm + year\n\n         Df Sum of Sq      RSS  AIC\n&lt;none&gt;                26596486 3775\n+ island  2     79468 26517018 3778\n\n\n\nCall:\nlm(formula = body_mass_g ~ flipper_length_mm + sex + species + \n    bill_depth_mm + bill_length_mm + year, data = pen.nomiss)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-809.15 -179.43   -3.42  183.60  866.03 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       80838.770  41677.817   1.940 0.053292 .  \nflipper_length_mm    18.064      3.088   5.849 1.20e-08 ***\nsexmale             382.168     47.797   7.996 2.28e-14 ***\nspeciesChinstrap   -274.496     81.558  -3.366 0.000855 ***\nspeciesGentoo       929.275    136.036   6.831 4.16e-11 ***\nbill_depth_mm        60.749     19.926   3.049 0.002487 ** \nbill_length_mm       18.997      7.086   2.681 0.007718 ** \nyear                -41.139     20.832  -1.975 0.049131 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 286.1 on 325 degrees of freedom\nMultiple R-squared:  0.8764,    Adjusted R-squared:  0.8738 \nF-statistic: 329.3 on 7 and 325 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nstep(full.model, direction='backward', trace=1) |&gt; summary()\n\nStart:  AIC=3777.96\nbody_mass_g ~ species + island + bill_length_mm + bill_depth_mm + \n    flipper_length_mm + sex + year\n\n                    Df Sum of Sq      RSS    AIC\n- island             2     79468 26596486 3775.0\n&lt;none&gt;                           26517018 3778.0\n- year               1    342414 26859432 3780.2\n- bill_length_mm     1    583730 27100748 3783.2\n- bill_depth_mm      1    758473 27275491 3785.3\n- flipper_length_mm  1   2872068 29389086 3810.2\n- sex                1   5101785 31618803 3834.6\n- species            2   6470784 32987802 3846.7\n\nStep:  AIC=3774.95\nbody_mass_g ~ species + bill_length_mm + bill_depth_mm + flipper_length_mm + \n    sex + year\n\n                    Df Sum of Sq      RSS    AIC\n&lt;none&gt;                           26596486 3775.0\n- year               1    319160 26915647 3776.9\n- bill_length_mm     1    588158 27184644 3780.2\n- bill_depth_mm      1    760657 27357143 3782.3\n- flipper_length_mm  1   2800047 29396533 3806.3\n- sex                1   5231718 31828204 3832.8\n- species            2   9693667 36290153 3874.4\n\n\n\nCall:\nlm(formula = body_mass_g ~ species + bill_length_mm + bill_depth_mm + \n    flipper_length_mm + sex + year, data = pen.nomiss)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-809.15 -179.43   -3.42  183.60  866.03 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       80838.770  41677.817   1.940 0.053292 .  \nspeciesChinstrap   -274.496     81.558  -3.366 0.000855 ***\nspeciesGentoo       929.275    136.036   6.831 4.16e-11 ***\nbill_length_mm       18.997      7.086   2.681 0.007718 ** \nbill_depth_mm        60.749     19.926   3.049 0.002487 ** \nflipper_length_mm    18.064      3.088   5.849 1.20e-08 ***\nsexmale             382.168     47.797   7.996 2.28e-14 ***\nyear                -41.139     20.832  -1.975 0.049131 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 286.1 on 325 degrees of freedom\nMultiple R-squared:  0.8764,    Adjusted R-squared:  0.8738 \nF-statistic: 329.3 on 7 and 325 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nstep(null.model, \n     scope=list(lower=null.model, upper=full.model),\n     direction='both', trace=1) |&gt; summary()\n\nStart:  AIC=4457.28\nbody_mass_g ~ 1\n\n                    Df Sum of Sq       RSS    AIC\n+ flipper_length_mm  1 164047703  51211963 3981.1\n+ species            2 145190219  70069447 4087.5\n+ island             2  83740680 131518986 4297.2\n+ bill_length_mm     1  74792533 140467133 4317.1\n+ bill_depth_mm      1  47959592 167300074 4375.3\n+ sex                1  38878897 176380769 4392.9\n&lt;none&gt;                           215259666 4457.3\n+ year               1    102884 215156782 4459.1\n\nStep:  AIC=3981.13\nbody_mass_g ~ flipper_length_mm\n\n                    Df Sum of Sq       RSS    AIC\n+ sex                1   9416589  41795374 3915.5\n+ species            2   5368818  45843144 3948.3\n+ island             2   3437527  47774435 3962.0\n+ year               1   2666295  48545668 3965.3\n+ bill_depth_mm      1    338887  50873075 3980.9\n&lt;none&gt;                            51211963 3981.1\n+ bill_length_mm     1    140000  51071963 3982.2\n- flipper_length_mm  1 164047703 215259666 4457.3\n\nStep:  AIC=3915.47\nbody_mass_g ~ flipper_length_mm + sex\n\n                    Df Sum of Sq       RSS    AIC\n+ species            2  13141806  28653568 3793.8\n+ island             2   6037165  35758209 3867.5\n+ bill_depth_mm      1   3667377  38127997 3886.9\n+ year               1   2276715  39518658 3898.8\n&lt;none&gt;                            41795374 3915.5\n+ bill_length_mm     1    144990  41650383 3916.3\n- sex                1   9416589  51211963 3981.1\n- flipper_length_mm  1 134585395 176380769 4392.9\n\nStep:  AIC=3793.76\nbody_mass_g ~ flipper_length_mm + sex + species\n\n                    Df Sum of Sq      RSS    AIC\n+ bill_depth_mm      1   1196096 27457472 3781.6\n+ bill_length_mm     1    780776 27872792 3786.6\n+ year               1    474080 28179488 3790.2\n&lt;none&gt;                           28653568 3793.8\n+ island             2     61695 28591873 3797.0\n- flipper_length_mm  1   4325617 32979185 3838.6\n- species            2  13141806 41795374 3915.5\n- sex                1  17189576 45843144 3948.3\n\nStep:  AIC=3781.56\nbody_mass_g ~ flipper_length_mm + sex + species + bill_depth_mm\n\n                    Df Sum of Sq      RSS    AIC\n+ bill_length_mm     1    541825 26915647 3776.9\n+ year               1    272828 27184644 3780.2\n&lt;none&gt;                           27457472 3781.6\n+ island             2     59488 27397984 3784.8\n- bill_depth_mm      1   1196096 28653568 3793.8\n- flipper_length_mm  1   3145834 30603306 3815.7\n- sex                1   7932472 35389944 3864.1\n- species            2  10670525 38127997 3886.9\n\nStep:  AIC=3776.93\nbody_mass_g ~ flipper_length_mm + sex + species + bill_depth_mm + \n    bill_length_mm\n\n                    Df Sum of Sq      RSS    AIC\n+ year               1    319160 26596486 3775.0\n&lt;none&gt;                           26915647 3776.9\n+ island             2     56214 26859432 3780.2\n- bill_length_mm     1    541825 27457472 3781.6\n- bill_depth_mm      1    957145 27872792 3786.6\n- flipper_length_mm  1   2481143 29396790 3804.3\n- sex                1   5482024 32397671 3836.7\n- species            2  11183644 38099291 3888.6\n\nStep:  AIC=3774.95\nbody_mass_g ~ flipper_length_mm + sex + species + bill_depth_mm + \n    bill_length_mm + year\n\n                    Df Sum of Sq      RSS    AIC\n&lt;none&gt;                           26596486 3775.0\n- year               1    319160 26915647 3776.9\n+ island             2     79468 26517018 3778.0\n- bill_length_mm     1    588158 27184644 3780.2\n- bill_depth_mm      1    760657 27357143 3782.3\n- flipper_length_mm  1   2800047 29396533 3806.3\n- sex                1   5231718 31828204 3832.8\n- species            2   9693667 36290153 3874.4\n\n\n\nCall:\nlm(formula = body_mass_g ~ flipper_length_mm + sex + species + \n    bill_depth_mm + bill_length_mm + year, data = pen.nomiss)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-809.15 -179.43   -3.42  183.60  866.03 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       80838.770  41677.817   1.940 0.053292 .  \nflipper_length_mm    18.064      3.088   5.849 1.20e-08 ***\nsexmale             382.168     47.797   7.996 2.28e-14 ***\nspeciesChinstrap   -274.496     81.558  -3.366 0.000855 ***\nspeciesGentoo       929.275    136.036   6.831 4.16e-11 ***\nbill_depth_mm        60.749     19.926   3.049 0.002487 ** \nbill_length_mm       18.997      7.086   2.681 0.007718 ** \nyear                -41.139     20.832  -1.975 0.049131 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 286.1 on 325 degrees of freedom\nMultiple R-squared:  0.8764,    Adjusted R-squared:  0.8738 \nF-statistic: 329.3 on 7 and 325 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\n\n\n\nWarnings\n\n\n\n\nStopping criteria and algorithm can be different for different software programs.\nCan reject perfectly plausible models from later consideration\nHides relationships between variables (X3 is added and now X1 is no longer significant. X1 vs X3 should be looked at)\n\n\n\n\n\n\n\n\n\nOther references\n\n\n\nStats 191 at Stanford. This one uses cross-validation on the stepwise procedures, and demonstrates the dangers of trusting models that come out of blind use of variable selection methods.\n\n\nBest Subsets\n\nSelect one X with highest simple \\(r\\) with Y\nSelect two X’s with highest multiple \\(r\\) with Y\nSelect three X’s with highest multiple \\(r\\) with Y etc.\nCompute adjusted R2, AIC or BIC each time.\nCompare and choose among the “best subsets” of various sizes.\n\n\noc.ht &lt;- regsubsets(body_mass_g ~ ., data=pen.nomiss)\npar(mfrow=c(1,3)) # set plotting window to be 1 row and 3 columns\nplot(oc.ht, scale='adjr2');plot(oc.ht, scale='bic');plot(oc.ht, scale='Cp')\n\n\n\n\n\n\n\n\n\nThe black squares are when the variable is in the model, the white is when it’s not\nThe vertical axis are chosen fit metrics such as adjusted R2, BIC and Mallows Cp. The higher the better\n\nIn this example variables that show up as improving model fit include species, sex, flipper_length_mm, bill_length, and possibly year. For sure island is out.\n\n\n\n\n\n\nNotable problems\n\n\n\n\nIf categorical variables are not treated as a group - that is, they are not “all in” or “all out”.\nIf at least one level is frequently chosen as improving model fit, add the entire categorical variable to the model.\n\n\n\n\n\n\n\n\n\nOther references\n\n\n\nSTHDA resource on best subsets regression.\n\n\n\n\n10.4.2 LASSO Regression (PMA6 9.7)\nLeast Absolute Shrinkage and Selection Operator.\nThe goal of LASSO is to minimize\n\\[\nRSS + \\lambda \\sum_{j}\\mid \\beta_{j} \\ \\mid\n\\]\nwhere \\(\\lambda\\) is a model complexity penalty parameter.\n\n“Shrinks” the coefficients, setting some to exactly 0.\n\nThus essentially choosing a simpler model\n\nBalances model accuracy with interpretation.\n\nThe lasso fits many regression models and selects those variables that show the strongest association with the response variable using the data at hand. This is also described as a method of selective inference (Taylor and Tibshirani, 2015) and is an example of exploratory research, where the data may influence what type and how many analyses are performed.\n\n\n\n\n\n\nExample\n\n\n\nThis section uses functions glmnet package, and the Chemical data set from PMA6. Also it uses the model.matrix function from the stats package (automatically loaded). This function takes a set of input predictors and turns them into the variables that are used directly in the model. For example, categorical variables will be converted into multiple binary indicators. This typically happens in the background.\n\n\nThe glmnet function works best when the outcome y and predictors x are not contained within a data frame. The alpha argument is the tuning parameter, where a value of 1 specifies the lasso.\n\nchem &lt;- read.table(\"data/Chemical.txt\", header = TRUE)\ny &lt;- chem$PE\nx &lt;- model.matrix(PE~., chem)[,-1] # the -1 drops the intercept\nchem.lasso &lt;- glmnet(x, y, alpha = 1)\n\nWe can visualize the effect of the coefficient shrinkage using the following plot.\n\nplot(chem.lasso, xvar = \"lambda\")\nmtext(side=3, \"Number of Variables\", line=2)\n\n\n\n\n\n\n\n\n\nEach line represents the value of a coefficient as \\(ln(\\lambda)\\) changes.\nThe red line on the bottom and the purple on the top must be important, since they are the last two to be shrunk to 0 and they are relatively stable.\n\nExamining the coefficients of the chem.lasso model object gives us a very large matrix (7x61), listing the coefficients for each value of \\(\\lambda\\) that was tried. A sample of columns are shown below:\n\ncoef(chem.lasso)[,1:8]\n\n7 x 8 sparse Matrix of class \"dgCMatrix\"\n                  s0         s1         s2        s3       s4         s5\n(Intercept) 9.366667  9.5835968  9.7812554  9.961355 10.12545 10.0399324\nROR5        .         .          .          .         .        .        \nDE          .        -0.5206322 -0.9950129 -1.427251 -1.82109 -2.0903355\nSALESGR5    .         .          .          .         .        .        \nEPS5        .         .          .          .         .        .        \nNPM1        .         .          .          .         .        0.0157436\nPAYOUTR1    .         .          .          .         .        0.2427377\n                     s6          s7\n(Intercept)  9.59940208  9.19800729\nROR5         .           .         \nDE          -2.21050375 -2.31999666\nSALESGR5     .           .         \nEPS5         .           .         \nNPM1         0.04642112  0.07437333\nPAYOUTR1     0.98609790  1.66341998\n\ncoef(chem.lasso)[,56:60]\n\n7 x 5 sparse Matrix of class \"dgCMatrix\"\n                    s55         s56         s57         s58         s59\n(Intercept)  1.36957827  1.35834023  1.34802448  1.34099610  1.33052382\nROR5         0.03767492  0.03797214  0.03825501  0.03840313  0.03870172\nDE          -2.58475249 -2.58199893 -2.57937377 -2.57863116 -2.57530747\nSALESGR5     0.19961031  0.19990639  0.20017553  0.20039468  0.20064382\nEPS5        -0.03468051 -0.03483069 -0.03497088 -0.03507850 -0.03520342\nNPM1         0.34740236  0.34760738  0.34778861  0.34795977  0.34812027\nPAYOUTR1     9.78594052  9.79286717  9.79910767  9.80408094  9.81009965\n\n\nComparing the plot to the coefficient model output above, we see that the variables that show up being shrunk last are DE and PAYOUTR1.\nUsing Cross-validation to find minimum lambda\nCross-validation is a resampling method that uses different portions of the data to test and train a model on different iterations (Wikipedia).\nBy applying a cross-validation technique, we can identify the specific value for \\(\\lambda\\) that results in the lowest cross-validated Mean Squared Error (MSE) (\\(\\lambda_{min}\\)). To ensure reproducibility of these results we set a seed for the random number generator prior to analysis.\n\nset.seed(123) # Setting a seed to ensure I get the same results each time I knit\ncv.lasso &lt;- cv.glmnet(x, y, alpha = 1) # note change in function\n\n# Fit the final model using the min lambda\nmodel &lt;- glmnet(x, y, alpha = 1, lambda = cv.lasso$lambda.min)\n\nThe resulting table of shrunk regression coefficients then is;\n\ncoef(model)\n\n7 x 1 sparse Matrix of class \"dgCMatrix\"\n                      s0\n(Intercept)  2.645693621\nROR5         0.004833458\nDE          -2.882636490\nSALESGR5     0.165581782\nEPS5        -0.017771193\nNPM1         0.323497141\nPAYOUTR1     8.986481946\n\n\nIn this case we would keep variables: DE, SALESGR5, NPM1 and PAYOUTR1. Estimates for ROR5 and EPS56 are very small, and so can be reasonably excluded.\n\nThe lasso procedure normalizes the data prior to fitting a model, so the coefficient values that are returned cannot be interpreted directly in context of the problem.\n\nThis does allow us the ability to make “judgement” calls on what is a ‘small’ estimate since it’s no longer dependent on the units of the data.\n\nAppropriate inference after model selection is currently under research. No unifying theory exists yet.\nFor now, use lasso to choose variables, then fit a model with only those selected variables in the final model.\nVariables chosen in this manner are important, yet biased estimates.\n\n\nlm(PE ~ DE + SALESGR5 + NPM1 + PAYOUTR1, data = chem) |&gt; tbl_regression()\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\nDE\n-3.2\n-6.9, 0.58\n0.094\n\n\nSALESGR5\n0.19\n-0.02, 0.41\n0.077\n\n\nNPM1\n0.35\n0.12, 0.59\n0.005\n\n\nPAYOUTR1\n11\n4.7, 17\n0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n10.4.3 Ridge Regression (PMA6 10.6)\nOften compared to LASSO, Ridge regression also minimizes the RSS, but the penalty function is different: \\[\nRSS + \\lambda \\sum_{j} \\beta_{j}^2\n\\]\nRidge regression only shrinks the magnitude of the coefficients, not set them exactly to zero.\n\n\n\nThis means Ridge regression is not a method of variable selection.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Building</span>"
    ]
  },
  {
    "objectID": "model_building.html#model-fit-criteria",
    "href": "model_building.html#model-fit-criteria",
    "title": "10  Model Building",
    "section": "10.5 Comparing between models (PMA6 9.4)",
    "text": "10.5 Comparing between models (PMA6 9.4)\nThe goal: Find the subset of independent variables that optimizes (either minimize or maximize) a certain criteria. In other words, the goal is to find the optimal model.\n\n\n\n\n\n\nHow do we measure “optimal”?\n\n\n\nFirst we need to look at two quantities:\n\n10.5.1 RSS: Residual Sum of Squares\nRecall the method of least squares introduced in Chapter 9 minimizes the residual sum of squares around the regression plane. This value is central to all following model comparison. How “far away” are the model estimates from the observed?\n\\[\n\\sum(Y - \\bar{Y})^{2}(1-R^{2})  \n\\]\n\n\n10.5.2 General F Test\n\nSee also Section 10.2\n\nTwo nested models are similar if the p-value for the General F-test is non-significant at a .15 level. Nested: The list of variables in one model is a subset of the list of variables from a bigger model. Similar to all other ANOVA models, you are essentially comparing the difference in RSS between nested models.\n\n# Full model\nfull.employ.model &lt;- lm(cesd ~ age + chronill + employ, data=depress_clean)\n# Reduced model\nreduced.employ.model &lt;- lm(cesd ~ age, data=depress_clean)\nanova(reduced.employ.model, full.employ.model)\n\nAnalysis of Variance Table\n\nModel 1: cesd ~ age\nModel 2: cesd ~ age + chronill + employ\n  Res.Df   RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    292 22197                                  \n2    290 20605  2    1592.8 11.209 2.046e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nThis uses anova(), not aov().\n\n\n\n\n\n\n\n\n\nOther references\n\n\n\nPenn State resource on the general linear F-test.\n\n\n\n\n10.5.3 Likelihood function\nWhat is the likelihood that we observed the data \\(x\\), given parameter values \\(\\theta\\). \\[\n\\mathcal{L}(\\theta \\mid x)=p_{\\theta }(x)=P_{\\theta }(X=x)\n\\]\n\nFor strictly convenient mathematical matters, we tend to work with the log-likelihood (LL).\n\nGreat because \\(log\\) is a monotonic increasing function, maximizing the LL = maximizing the likelihood function.\n\nWe can compare between models using functions based off the LL.\n\nThere are several measures we can use to compare between competing models.\n\n\n10.5.4 Multiple \\(R^{2}\\)\nIf the model explains a large amount of variation in the outcome that’s good right? So we could consider using \\(R^{2}\\) as a selection criteria and trying to find the model that maximizes this value.\n\nProblem: The multiple \\(R^{2}\\) always increases as predictors are added to the model.\n\nEx. 1: N = 100, P = 1, E(\\(R^{2}\\)) = 0.01\nEx. 2: N = 21, P = 10, E(\\(R^{2}\\)) = 0.5\n\nProblem: \\(R^{2} = 1-\\frac{Model SS}{Total SS}\\) is biased: If population \\(R^{2}\\) is really zero, then E(\\(R^{2}\\)) = P/(N-1).\n\nReference PMA6 Figure 9.1\n\n\n10.5.5 Adjusted \\(R^{2}\\)\nTo alleviate bias use Mean squares instead of SS.\n\\(R^{2} = 1-\\frac{Model MS}{Total MS}\\)\nequivalently,\n\\(R^{2}_{adj} = R^{2} - \\frac{p(1-R^{2})}{n-p-1}\\)\nNow Adjusted \\(R^{2}\\) is approximately unbiased and won’t inflate as \\(p\\) increases.\n\n\n10.5.6 Mallows \\(C_{p}\\)\n\\[\n    C_{p} = (N-P-1)\\left(\\frac{RMSE}{\\hat{\\sigma}^{2}} -1 \\right) + (P+1)\n\\]\nwhere \\(RMSE = \\frac{RSS}{N-P-1}\\).\n\nSmaller is better\nWhen all variables are chosen, \\(P+1\\) is at it’s maximum but the other part of \\(C_{p}\\) is zero since \\(RMSE\\)==\\(\\hat{\\sigma}^{2}\\)\n\n\n\n10.5.7 Akaike Information Criterion (AIC)\n\nA penalty is applied to the deviance that increases as the number of parameters \\(p\\) increase.\nTries to find a parsimonious model that is closer to the “truth”.\n\nUses an information function, e.g., the likelihood function \\((LL)\\).\n\n\\[ AIC = -2LL + 2p\\]\n\nSmaller is better\nCan also be written as a function of the residual sum of squares (RSS) (in book)\nEstimates the information in one model relative to other models\n\nSo if all models suck, your AIC will just tell you which one sucks less.\n\nBuilt in AIC() function in R\nRule of thumb: Model 1 and Model 2 are considered to have significantly different fit if the difference in AIC values is greater than 2.\n\n\\[\\mid AIC_{1} - AIC_{2}\\mid &gt; 2\\]\n\n\n10.5.8 Bayesian Information Criterion (BIC)\n\nSimilar to AIC.\nBuilt in BIC() function in R\nTries to find a parsimonious model that is more likely to be the “truth”. The smaller BIC, the better.\n\n\\[ BIC = -2LL + ln(N)*(P+1)\\]\n\n\n10.5.9 AIC vs BIC\n\nBoth are “penalized likelihood” functions\nEach = -2log likelihood + penalty\nAIC: penalty = 2, BIC: penalty = ln(N)\nFor any N &gt; 7, ln(N) &gt; 2\nThus, BIC penalizes larger models more heavily.\nThey often agree.\n\nWhen they disagree, AIC chooses a larger model than BIC.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Building</span>"
    ]
  },
  {
    "objectID": "model_building.html#model-diagnostics",
    "href": "model_building.html#model-diagnostics",
    "title": "10  Model Building",
    "section": "10.6 Model Diagnostics",
    "text": "10.6 Model Diagnostics\nRecall from Section 7.2 the assumptions for linear regression model are;\n\nLinearity The relationship between \\(x_j\\) and \\(y\\) is linear, for all \\(j\\).\nNormality, Homogeneity of variance The residuals are identically distributed \\(\\epsilon_{i} \\sim N(0, \\sigma^{2})\\)\nUncorrelated/Independent Distinct error terms are uncorrelated: \\(\\text{Cov}(\\epsilon_{i},\\epsilon_{j})=0,\\forall i\\neq j.\\)\n\nThere are a few ways to visually assess these assumptions. We’ll look at this using a penguin model of body mass as an example.\n\npen.bmg.model &lt;- lm(body_mass_g ~ bill_length_mm + flipper_length_mm, data=pen)\n\n\n10.6.1 Linearity\nCreate a scatterplot with lowess AND linear regression line. See how close the lowess trend line is to the best fit line. Do this for all variables.\n\nbill.plot  &lt;- ggplot(pen, aes(y=body_mass_g, x=bill_length_mm)) + \n  geom_point() +   theme_bw() + \n  geom_smooth(col = \"red\") + \n  geom_smooth(method = \"lm\" , col = \"blue\")\n\nflipper.plot  &lt;- ggplot(pen, aes(y=body_mass_g, x=flipper_length_mm)) + \n  geom_point() +   theme_bw() + \n  geom_smooth(col = \"red\") + \n  geom_smooth(method = \"lm\" , col = \"blue\")\n\ngridExtra::grid.arrange(bill.plot, flipper.plot, ncol=2)\n\n\n\n\n\n\n\n\nBoth variables appear to have a mostly linear relationship with body mass. For penguins with bill length over 50mm the slope may decrease, but the data is sparse in the tails.\n\n\n10.6.2 Normality of residuals.\nThere are two common ways to assess normality.\n\nA histogram or density plot with a normal distribution curve overlaid.\nA qqplot. This is also known as a ‘normal probability plot’. It is used to compare the theoretical quantiles of the data if it were to come from a normal distribution to the observed quantiles. PMA6 Figure 5.4 has more examples and an explanation.\n\n\ngridExtra::grid.arrange(\n  plot(check_normality(pen.bmg.model)), \n  plot(check_normality(pen.bmg.model), type = \"qq\"),\n  ncol=2\n)\n\n\n\n\n\n\n\n\nIn both cases you want to assess how close the dots/distribution is to the reference curve/line.\n\n\n10.6.3 Homogeneity of variance\nThe variability of the residuals should be constant, and independent of the value of the fitted value \\(\\hat{y}\\).\n\nplot(check_heteroskedasticity(pen.bmg.model))\n\n\n\n\n\n\n\n\nThis assumption is often the hardest to be fully upheld. Here we see a slightly downward trend. However, this is not a massive violation of assumptions.\n\n\n10.6.4 Posterior Predictions\nNot really an assumption, but we can also assess the fit of a model by how well it does to predict the outcome. Using a Bayesian sampling method, the distribution of the predictions from the model should resemble the observed distribution.\n\nplot(check_posterior_predictions(pen.bmg.model))\n\n\n\n\n\n\n\n\nThis looks like a good fit.\n\n\n10.6.5 All at once\n\ncheck_model(pen.bmg.model)\n\n\n\n\n\n\n\n\nRefer to PMA6 8.8 to learn about leverage.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Building</span>"
    ]
  },
  {
    "objectID": "model_building.html#general-advice-pma6-9.9",
    "href": "model_building.html#general-advice-pma6-9.9",
    "title": "10  Model Building",
    "section": "10.7 General Advice (PMA6 9.9)",
    "text": "10.7 General Advice (PMA6 9.9)\n\nModel selection is not a hard science.\nSome criteria have “rules of thumb” that can guide your exploration (such as difference in AIC &lt; 2)\nUse common sense: A sub-optimal subset may make more sense than optimal one\np-values: When you compare two criteria, often the difference has a known distribution.\n\nWald F Test, the difference in RSS between the two models has a F distribution.\n\nAll criterion should be used as guides.\nPerform multiple methods of variable selection, find the commonalities.\nLet science and the purpose of your model be your ultimate guide\n\nIf the purpose of the model is for explanation/interpretation, error on the side of parsimony (smaller model) than being overly complex.\nIf the purpose is prediction, then as long as you’re not overfitting the model (as checked using cross-validation techniques), use as much information as possible.\n\nAutomated versions of variable selection processes should not be used blindly.\n“… perhaps the most serious source of error lies in letting statistical procedures make decisions for you.”…“Don’t be too quick to turn on the computer. Bypassing the brain to compute by reflex is a sure recipe for disaster.” Good and Hardin, Common Errors in Statistics (and How to Avoid Them), p. 3, p. 152",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Building</span>"
    ]
  },
  {
    "objectID": "model_building.html#what-to-watch-out-for-pma6-9.10",
    "href": "model_building.html#what-to-watch-out-for-pma6-9.10",
    "title": "10  Model Building",
    "section": "10.8 What to watch out for (PMA6 9.10)",
    "text": "10.8 What to watch out for (PMA6 9.10)\n\nMulticollinearity\nMissing Data\nUse previous research as a guide\nVariables not included can bias the results\nSignificance levels are only a guide\nPerform model diagnostics after selection to check model fit.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Building</span>"
    ]
  },
  {
    "objectID": "glm.html",
    "href": "glm.html",
    "title": "11  Generalized Linear Models",
    "section": "",
    "text": "11.1 Fitting GLMs\nAll regression models aim to model the expected value of the response variable \\(Y\\) given the observed data \\(X\\), through some link function \\(C\\)\n\\[E(Y|X) = C(X)\\]\nDepending on the data type of \\(Y\\), this link function takes different forms. Examples include:\nR\nThe general syntax is similar to lm(), with the additional required family= argument. See ?family for a list of options. Example for Logistic regression would be:\nglm(y ~ x1 + x2 + x3, data=DATA, family=\"binomial\")\nSPSS\nFile menu: Regression –&gt; Binary Logistic.\nSyntax:\nIBM - reference\nStata\nlogistic Y x1 x2\nStata - reference",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "glm.html#fitting-glms",
    "href": "glm.html#fitting-glms",
    "title": "11  Generalized Linear Models",
    "section": "",
    "text": "Linear regression: C = Identity function (no change)\nLogistic regression: C = logit function\nPoisson regression: C = log function\n\n\n\n\n\n\n\nlogistic regression Y with x1 x2 x3\n   /categorical = x2",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "glm.html#sec-log-linear",
    "href": "glm.html#sec-log-linear",
    "title": "11  Generalized Linear Models",
    "section": "11.2 Log-linear models",
    "text": "11.2 Log-linear models\nA log-linear model is when the log of the response variable is modeled using a linear combination of predictors.\n\\[ln(Y) \\sim XB +\\epsilon\\]\nRecall that in statistics, when we refer to the log, we mean the natural log ln.\nThis type of model is often use to model count data using the Poisson distribution (Section 11.5.1).\nWhy are we transforming the outcome? Typically to achieve normality when the response variable is highly skewed.\nInterpreting results\nSince we transformed our outcome before performing the regression, we have to back-transform the coefficient before interpretation. Similar to logistic regression, we need to exponentiate the regression coefficient before interpreting.\nWhen using log transformed outcomes, the effect on Y becomes multiplicative instead of additive.\n\nAdditive For every 1 unit increase in X, y increases by b1\nMultiplicative For every 1 unit increase in X, y is multiplied by \\(e^{b1}\\)\n\nExample: Let \\(b_{1} = 0.2\\).\n\nAdditive For every 1 unit increase in X, y increases by 0.2 units.\nMultiplicative For every 1 unit increase in X, y changes by \\(e^{0.2} = 1.22\\) = 22%\n\nThus we interpret the coefficient as a percentage change in \\(Y\\) for a unit increase in \\(x_{j}\\).\n\n\\(b_{j}&lt;0\\) : Positive slope, positive association. The expected value of \\(Y\\) for when \\(x=0\\) is \\(1 - e^{b_{j}}\\) percent lower than when \\(x=1\\)\n\\(b_{j} \\geq 0\\) : Negative slope, negative association. The expected value of \\(Y\\) for when \\(x=0\\) is \\(e^{b_{j}}\\) percent higher than when \\(x=1\\)\n\n\n\n\n\n\n\nLearn more\n\n\n\nThis UCLA resource is my “go-to” reference on how to interpret the results when your response, predictor, or both variables are log transformed.\n\n\n\n11.2.1 Example\nWe are going to analyze personal income from the AddHealth data set. First I need to clean up, and log transform the variable for personal earnings H4EC2 by following the steps below in order.\n\nRemove values above 999995 (structural missing).\nCreate a new variable called income, that sets all values of personal income to be NA if below the federal poverty line.\n\nFirst set income= H4EC2\nThen set income to missing, if H4EC2 &lt; 10210 (the federal poverty limit from 2008)\n\nThen create a new variable: logincome that is the natural log (ln) of income. e.g. addhealth$logincome = log(addhealth$income)\n\nWhy are we transforming income? To achieve normality.\n\npar(mfrow=c(2,2))\nhist(addhealth$income, probability = TRUE); lines(density(addhealth$income, na.rm=TRUE), col=\"red\")\nhist(addhealth$logincome, probability = TRUE); lines(density(addhealth$logincome, na.rm=TRUE), col=\"blue\")\nqqnorm(addhealth$income); qqline(addhealth$income, col=\"red\")\nqqnorm(addhealth$logincome); qqline(addhealth$logincome, col=\"blue\")\n\n\n\n\n\n\n\n\nIdentify variables\n\nQuantitative outcome that has been log transformed: Income (variable logincome)\nBinary predictor: Ever smoked a cigarette (variable eversmoke_c)\nBinary confounder: Gender (variable female_c)\n\nThe mathematical multivariable model looks like:\n\\[ln(Y) \\sim \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}\\]\nFit a linear regression model\n\nln.mod.2 &lt;- lm(logincome~wakeup + female_c, data=addhealth)\nsummary(ln.mod.2) %&gt;% pander()\n\n\n\n\n\n\n\n\n\n\n\n \nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n10.65\n0.026\n409.8\n0\n\n\nwakeup\n-0.01491\n0.003218\n-4.633\n3.73e-06\n\n\nfemale_cFemale\n-0.1927\n0.017\n-11.34\n2.564e-29\n\n\n\n\nFitting linear model: logincome ~ wakeup + female_c\n\n\n\n\n\n\n\n\nObservations\nResidual Std. Error\n\\(R^2\\)\nAdjusted \\(R^2\\)\n\n\n\n\n3813\n0.5233\n0.03611\n0.0356\n\n\n\n\n1-exp(confint(ln.mod.2)[-1,])\n\n                    2.5 %      97.5 %\nwakeup         0.02099299 0.008561652\nfemale_cFemale 0.20231394 0.147326777\n\n\nInterpret the results\n\nFor every hour later one wakes up in the morning, one can expect to earn 1-exp(-0.015) = 1.4% less income than someone who wakes up one hour earlier. This is after controlling for gender.\nFemales have on average 1-exp(-0.19) = 17% percent lower income than males, after controlling for the wake up time.\n\nBoth gender and time one wakes up are significantly associated with the amount of personal earnings one makes. Waking up later in the morning is associated with 1.4% (95% CI 0.8%-2%, p&lt;.0001) percent lower income than someone who wakes up one hour earlier. Females have 17% (95% CI 15%-20%, p&lt;.0001) percent lower income than males.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "glm.html#binary-outcome-data",
    "href": "glm.html#binary-outcome-data",
    "title": "11  Generalized Linear Models",
    "section": "11.3 Binary outcome data",
    "text": "11.3 Binary outcome data\nConsider an outcome variable \\(Y\\) with two levels: Y = 1 if event, = 0 if no event.\nLet \\(p_{i} = P(y_{i}=1)\\).\nTwo goals:\n\nAssess the impact selected covariates have on the probability of an outcome occurring.\nPredict the probability of an event occurring given a certain covariate pattern. This is covered in Chapter 12\n\nBinary data can be modeled using a Logistic Model or a Probit Model.\nThe logistic model relates the probability of an event based on a linear combination of X’s.\n\\[\nlog\\left(\n\\frac{p_{i}}{1-p_{i}}\n\\right) = \\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i} + \\ldots + \\beta_{p}x_{pi}\n\\]\nSince the odds are defined as the probability an event occurs divided by the probability it does not occur: \\((p/(1-p))\\), the function \\(log\\left(\\frac{p_{i}}{1-p_{i}}\\right)\\) is also known as the log odds, or more commonly called the logit. This is the link function for the logistic regression model.\nThis in essence takes a binary outcome 0/1 variable, turns it into a continuous probability (which only has a range from 0 to 1) Then the logit(p) has a continuous distribution ranging from \\(-\\infty\\) to \\(\\infty\\), which is the same form as a Multiple Linear Regression (continuous outcome modeled on a set of covariates)\nThe probit function uses the inverse CDF for the normal distribution as the link function. The effect of the transformation is very similar. For social science interpretation of the coefficients, we tend to choose the logit transformation and conduct a Logistic Regression. For classification purposes, often researchers will test out both transformations to see which one gives the best predictions.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "glm.html#sec-logreg",
    "href": "glm.html#sec-logreg",
    "title": "11  Generalized Linear Models",
    "section": "11.4 Logistic Regression",
    "text": "11.4 Logistic Regression\nSince the link between \\(X\\) and \\(Y\\) is no longer linear, a one unit increase in \\(X_{p}\\) is no longer associated with a \\(b_{p}\\) increase in \\(Y\\). The regression coefficients \\(b_{p}\\) from a logistic regression must be exponentiated before interpretation.\n\\[OR = e^{b}\\]\nThe Odds Ratio (OR) provides a directly understandable statistic for the relationship between \\(y\\) and a specific \\(x\\) given all other \\(x\\)’s in the model are fixed. A later example in Section 11.4.4 provides a numeric example of how Odds Ratios are calculated.\nIn testing for a relationship between \\(x\\) and \\(y\\), our hypothesis is that \\(\\beta_{p}=0\\). Since \\(e^{0}=1\\), the reference value for the Odds Ratio that signifies no relationship, is 1, not 0.\n\n11.4.1 Interpreting Odds Ratios\nConsider a binary outcome with values YES, coded as 1, and NO, coded as 0.\n\nOR = 1 = equal chance of response variable being YES given any explanatory variable value. You are not able to predict participants’ responses by knowing their explanatory variable value. This would be a non significant model when looking at the p-value for the explanatory variable in the parameter estimate table.\nOR &gt; 1 = as the explanatory variable value increases, the presence of a YES response is more likely. We can say that when a participant’s response to the explanatory variable is YES (1), they are more likely to have a response that is a YES (1).\nOR &lt;1 = as the explanatory variable value increases, the presence of a YES response is less likely. We can say that when a participant’s response to the explanatory variable is YES (1) they are less likely to have a response that is a YES (1).\n\nFor a continuous variable X with slope coefficient \\(\\beta\\), the quantity \\(e^{b}\\) is interpreted as the ratio of the odds for a person with value (X+1) relative to the odds for a person with value X.\n\n\n11.4.2 Confidence Intervals\nConfidence intervals are a range for the population’s predicted odds ratio based on the sample data. We are 95% confident that any given population’s odds ratio would range between those two values.\nThe OR is not a linear function of the \\(x's\\), but \\(\\beta\\) is. This means that a CI for the OR is created by calculating a CI for \\(\\beta\\), and then exponentiating the endpoints. A 95% CI for the OR is calculated as:\n\\[e^{\\hat{\\beta} \\pm 1.96 SE_{\\beta}}  \\tag{11.1}\\]\nThis math holds for any \\(k\\) unit change in x. The linearity of the confidence interval only applies at the untransformed level of the \\(\\beta\\)’s. NOT the odds ratio.\n\n\n11.4.3 Example: The effect of gender on Depression\nThis uses a cleaned version of the depression data set from PMAS6.\n\nBinary outcome variable: Symptoms of Depression (cases)\nBinary predictor variable: Gender (sex) as an indicator of being female\n\nThe outcome \\(y\\) is a 0/1 Bernoulli random variable. The sum of a vector of Bernoulli’s (\\(\\sum_{i=1}^{n}y_{i}\\)) has a Binomial distribution. When we specify that family = \"binomial\" the glm() function auto-assigns “logit” link function.\n\ndep_sex_model &lt;- glm(cases ~ sex, data=depress_clean, family=\"binomial\")\nsummary(dep_sex_model)\n\n\nCall:\nglm(formula = cases ~ sex, family = \"binomial\", data = depress_clean)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -3.3511     0.6867  -4.880 1.06e-06 ***\nsex           1.0386     0.3767   2.757  0.00583 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 268.12  on 293  degrees of freedom\nResidual deviance: 259.40  on 292  degrees of freedom\nAIC: 263.4\n\nNumber of Fisher Scoring iterations: 5\n\n\nWe exponentiate the coefficients to back transform the \\(\\beta\\) estimates into Odds Ratios\n\nexp(coef(dep_sex_model))\n\n(Intercept)         sex \n 0.03504558  2.82517483 \n\nexp(confint(dep_sex_model))\n\n                  2.5 %    97.5 %\n(Intercept) 0.008071827 0.1225716\nsex         1.399110558 6.2142384\n\n\nFemales have 2.8 (1.4, 6.2) times the odds of showing signs of depression compared to males.\n\n\n11.4.4 Multiple Logistic Regression\nLet’s continue with the depression model, but now also include age and income as potential predictors of symptoms of depression.\n\nmvmodel &lt;- glm(cases ~ age + income + sex, data=depress_clean, family=\"binomial\")\nsummary(mvmodel)\n\n\nCall:\nglm(formula = cases ~ age + income + sex, family = \"binomial\", \n    data = depress_clean)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept) -1.60590    0.84654  -1.897  0.05782 . \nage         -0.02096    0.00904  -2.318  0.02043 * \nincome      -0.03656    0.01409  -2.595  0.00946 **\nsex          0.92945    0.38582   2.409  0.01600 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 268.12  on 293  degrees of freedom\nResidual deviance: 247.54  on 290  degrees of freedom\nAIC: 255.54\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nThe sign of the \\(\\beta\\) coefficients can be interpreted in the same manner as with linear regression as having a positive or negative relationship.\n\nThe odds of being depressed are less if the respondent has a higher income and is older, and higher if the respondent is female.\n\n\nThe odds of a female being depressed are 2.53 times greater than the odds for Males after adjusting for the effects of age and income (p=.016).\n\nExample calculation for \\(OR = e^{\\beta}\\)\nThe full model is: \\[log(odds) = -0.676 - 0.02096*age - .03656*income + 0.92945*gender\\]\nWe want to calculate the Odds Ratio of depression for women compared to men. \\[ OR = \\frac{Odds (Y=1|F)}{Odds (Y=1|M)} \\]\nWrite out the equations for men and women separately. \\[ = \\frac{e^{-0.676 - 0.02096*age - .03656*income + 0.92945(1)}}\n          {e^{-0.676 - 0.02096*age - .03656*income + 0.92945(0)}}\\]\nApplying rules of exponents to simplify. \\[ = \\frac{e^{-0.676}e^{- 0.02096*age}e^{- .03656*income}e^{0.92945(1)}}\n          {e^{-0.676}e^{- 0.02096*age}e^{- .03656*income}e^{0.92945(0)}}\\]\n\\[ = \\frac{e^{0.92945(1)}}\n          {e^{0.92945(0)}}\\]\n\\[ = e^{0.92945} \\]\n\nexp(.92945)\n\n[1] 2.533116\n\nexp(coef(mvmodel)[4])\n\n     sex \n2.533112 \n\n\n\n\n11.4.5 Effect of a k unit change\n\nSometimes a 1 unit change in a continuous variable is not meaningful.\n\\(exp(kb)\\) is the incremental odds ratio corresponding to an increase of \\(k\\) units in the variable X, assuming that the values of all other X variables remain unchanged.\n\n\ntbl_regression(mvmodel, exponentiate=TRUE)\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\n\nage\n0.98\n0.96, 1.00\n0.020\n\n\nincome\n0.96\n0.94, 0.99\n0.009\n\n\nsex\n2.53\n1.23, 5.66\n0.016\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nThe Adjusted odds ratio (AOR) for increase of 1 year of age is 0.98 (95%CI .96, 1.0)\nHow about a 10 year increase in age? \\(e^{10*\\beta_{age}} = e^{-.21} = .81\\)\n\nIn generalized linear models, the assumptions on \\(\\beta\\) having a normal distribution.\nRefer back to Equation 11.1, the linearity of the relationship is on the \\(\\beta\\) level, not the odds ratio. Do all transformations on the \\(\\beta\\)’s, then the last step is the non-linear transformation of exponentiation.\nSo the mathematical order of operations is important! First use coef to extract the coefficients out of the model object (here named mvmodel), then pull the 2nd item out coef(mvmodel)[2], then multiply it by 10, then lastly exponentiate this value.\n\nexp(10*coef(mvmodel)[2])\n\n      age \n0.8109285 \n\n\nDo the same to calculate the confidence interval for a 10 year time span.\n\nround(exp(10*confint(mvmodel)[2,]),3)\n\n 2.5 % 97.5 % \n 0.676  0.965 \n\n\nControlling for gender and income, an individual has 0.81 (95% CI 0.68, 0.97) times the odds of being depressed compared to someone who is 10 years younger than them.\n\n\n11.4.6 Example: Predictors of smoking status\nConsider a logistic model on smoking status (0= never smoked, 1=has smoked) using gender, income, and blood pressure class (bp_class) as predictors.\n\\[\nlogit(Y) = \\beta_{0} + \\beta_{1}\\mbox{(female)} + \\beta_{2}\\mbox{(income)} + \\beta_{3}\\mbox{(Pre-HTN)}\n+ \\beta_{4}\\mbox{(HTN-I)} + \\beta_{5}\\mbox{(HTN-II)}\n\\]\n\nbp.mod &lt;- glm(smoke ~ female_c + income + bp_class, data=addhealth, family='binomial')\ntbl_regression(bp.mod, exponentiate=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\n\nfemale_c\n\n\n\n\n\n\n\n\n    Male\n—\n—\n\n\n\n\n    Female\n0.54\n0.46, 0.63\n&lt;0.001\n\n\nincome\n1.00\n1.00, 1.00\n0.005\n\n\nbp_class\n\n\n\n\n\n\n\n\n    Normal\n—\n—\n\n\n\n\n    Pre-HTN\n1.08\n0.92, 1.26\n0.4\n\n\n    HTN-I\n0.98\n0.79, 1.21\n0.8\n\n\n    HTN-II\n1.03\n0.71, 1.50\n0.9\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nIt is unlikely that blood pressure is associated with smoking status, all groups are not statistically significantly different from the reference group (all p-values are large). Let’s test that hypothesis formally using a Wald Test.\n\nsurvey::regTermTest(bp.mod, \"bp_class\")\n\nWald test for bp_class\n in glm(formula = smoke ~ female_c + income + bp_class, family = \"binomial\", \n    data = addhealth)\nF =  0.428004  on  3  and  3723  df: p= 0.73294 \n\n\nThe Wald Test has a large p-value of 0.73, thus blood pressure classification is not associated with smoking status.\n\nThis means blood pressure classification should not be included in a model to explain smoking status.\n\n\n\n11.4.7 Model Fit\n\n\n\n\n\n\nSee PMA6 12.8\n\n\n\nPseudo \\(R^{2}\\)\nRecall in linear regression, the coefficient of determination \\(R^{2}\\) could be used as a measure of model fit, as it represents the proportion of variance in the outcome explained by the model. This statistic can’t be calculated for Logistic regression, but several versions of a Pseudo \\(R^{2}\\) have been proposed, and are printed as part of the output for many statistical packages such as Stata.\nGoodness of Fit\nAnother way to assess model fit for the entire model is to perform a goodness-of-fit test. The one developed by Hosmer and Lemeshow (1980) is the most commonly used GoF test. In this approach,\n\nthe predicted probability of belonging to the event group (y=1) is calculated for every observation.\nthese probabilities are sorted in ascending order, then divided into \\(j\\) equal sized subgroups, typically deciles to create 10 ‘bins’.\nFor each ‘bin’, or range of probabilities, count the observed number of individuals with the event (y=1) (\\(O_{j}\\)).\nFor each ‘bin’, calculate the expected number of events by adding the predicted probabilities in that bin. (\\(E_{j}\\))\n\nThe goodness of fit statistic is then calculated as follows:\n\\[ GoF \\chi^{2} = \\sum_{j} \\frac{(O_{j}-E_{j})^2}{E_{j}} \\]\nwhich approximately follows a \\(\\chi_{J-2}^{2}\\) distribution under relatively large sample sizes.\n\nA large GoF statistic (or small p-value) indicate that the fit may NOT be good\n\nR package: MKmisc, function HLgof.test.\nMkmisc::HLgof.test(fit=fitted(model), obs=model$y)\nAccurate predictions\nSince the logistic regression is all about modeling the probability of an event occurring, we can use that model to create predicted probabilities. The next chapter discusses how to use a logistic regression model for prediction, and what measures of fit are used to assess how “accurate” the model is.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "glm.html#poisson-reg",
    "href": "glm.html#poisson-reg",
    "title": "11  Generalized Linear Models",
    "section": "11.5 Count outcome data",
    "text": "11.5 Count outcome data\nLets consider modeling the distribution of the number of of occurrences of a rare event in a specified period of time - e.g. Number of thunderstorms in a year\n\nIf we assume:\n\nRate (\\(\\mu\\)) is fixed over time\nSuccessive occurrences independent of each other\n\n\nThen we can use the Poisson distribution.\n\\[\nP(Y=y) = e^{-\\mu}\\frac{\\mu^{y}}{y!}\n\\]\n\nThe Poisson distribution has a distinct feature where the mean of the distribution \\(\\mu\\), is also the variance.\n\n\n\n\nPlot of Histogram of a Poisson Distribution with a Mean of 5 and a Normal Curve\n\n\n\n11.5.1 Poisson Regression\n\n\n\n\n\n\nThis section is still under development\n\n\n\nJust another GLM - we use a \\(ln\\) as the link function. This lets us model the log rates using a linear combination of covariates.\n\\[\n  ln(\\mu) = \\mathbf{X}\\beta\n\\]\nThen the expected rate of events per unit of time is:\n\\[\n  \\mu = e^{\\mathbf{X}\\beta}\n\\]\nThis model assumes that the time of “exposure” for each record is identical.\n\nNumber of cigarettes per month\nNumber of epileptic seizures per week\nNumber of people with lung cancer in four cities\n\nIf this is not the case (often), then this model needs to include an offset.\n\ne.g. observing each patient for epileptic seizures for a different number of days\naccounting for different sizes or structures of populations of interest (e.g. different cities with lung cancer)\n\nWhat actually gets fit in glm is the model of expected counts, rather than rates, with an offset for the time period \\(T\\).\n\nIf all time periods are the same, then T is constant, and a linear combination of the intercept, thus dropped from the model.\n\n\\[\n  ln(\\lambda) = \\mathbf{X}\\beta + ln(T)\n\\]\nWhile this offset will be added to the regression model as if it were another variable, it’s not quite the same because the regression coefficient for the \\(ln(T)\\) term is fixed at 1.\nThe generic formula for fitting a poisson model using glm is:\nglm(y ~ x1 + x2 + offset(log(T)), family='poisson')\nor alternatively as an argument\nglm(y ~ x1 + x2, offset = log(T),  family='poisson')\nThe interpretation of the \\(\\beta\\) regression coefficients are differences in the log rate (or the log rate-ratio). So, just like with a logistic regression often we back-transform the coefficients by exponentiating before interpreting. So \\(e^{\\beta}\\) is now the rate-ratio.\n\nThe intercept term is not a ratio, but a baseline rate when all covariates are 0\nFor other covariates, the coefficient is the relative change per unit change in the covariate.\n\none year older\nmales vs females\n\n\nAlso, similar to logistic regression, since the outcome was transformed, the standard errors are not useful or interpretable as is. To calculate confidence intervals for the rate ratios,\n\ncalculate the CI for \\(\\beta\\)\nexponentiate each end point.\n\n\n\n11.5.2 Example: Modeling counts from the Add Health Wave IV dataset.\nLet’s model the number of siblings someone has, based off their age at Wave 1 (2008).\nVisualize\n\nggplot(addhealth, aes(x=nsib)) + geom_histogram() + \n  xlab(\"Number of siblings\") + ylab(\"Count\")\n\n\n\n\n\n\n\n\n\nnsib.model &lt;- glm(nsib ~ agew1 + female, data=addhealth, family=\"poisson\")\ntbl_regression(nsib.model, exponentiate = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nIRR1\n95% CI1\np-value\n\n\n\n\nagew1\n1.05\n1.03, 1.06\n&lt;0.001\n\n\nfemale\n1.10\n1.06, 1.14\n&lt;0.001\n\n\n\n1 IRR = Incidence Rate Ratio, CI = Confidence Interval",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "glm.html#sec-multinomial-reg",
    "href": "glm.html#sec-multinomial-reg",
    "title": "11  Generalized Linear Models",
    "section": "11.6 Categorical outcome data",
    "text": "11.6 Categorical outcome data\n\n\n\n\n\n\nThis section is still under development\n\n\n\nIf you want to keep the response variable as a categorical variable with more than two levels, the following regression model types are available:\n\nOrdinal Logistic Regression\nMultinomial Regression",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "classification.html",
    "href": "classification.html",
    "title": "12  Classification of Binary outcomes",
    "section": "",
    "text": "12.1 Predicted Probabilities\nFor all of these, we need to calculate \\(p_{i} = P(y_{i}=1)\\), the probability of the event. Back solving the logistic model for \\(p_{i} = e^{\\beta X} / (1+e^{\\beta X})\\) gives us the probability of an event.\n\\[\np_{i} = \\frac{e^{\\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i} + \\ldots + \\beta_{p}x_{pi}}}\n{1 + e^{\\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i} + \\ldots + \\beta_{p}x_{pi}}}\n\\]\nConsider the main effects model of depression on age, income and sex from Section 11.4.4\nEstimate\nStd. Error\nz value\nPr(&gt;|z|)\n\n\n\n\n(Intercept)\n-0.6765\n0.5788\n-1.169\n0.2425\n\n\nage\n-0.02096\n0.00904\n-2.318\n0.02043\n\n\nincome\n-0.03656\n0.01409\n-2.595\n0.009457\n\n\nsexFemale\n0.9294\n0.3858\n2.409\n0.016\n\n\n\n(Dispersion parameter for binomial family taken to be 1 )\n\n\n\n\n\n\n\nNull deviance:\n268.1 on 293 degrees of freedom\n\n\nResidual deviance:\n247.5 on 290 degrees of freedom\nThe predicted probability of depression is calculated as: \\[\nP(depressed) = \\frac{e^{-0.676 - 0.02096*age - .03656*income + 0.92945*sex}}\n{1 + e^{-0.676 - 0.02096*age - .03656*income + 0.92945*sex}}\n\\]\nNotice this formulation requires you to specify a covariate profile. In other words, what value X take on for each record. Often when you are only concerned with comparing the effect of a single measures, you set all other measures equal to their means.\nLet’s compare the probability of being depressed for males and females separately, while holding age and income constant at the average value calculated across all individuals (regardless of sex).\ndepress_clean %&gt;% summarize(age=mean(age), income=mean(income))\n\n       age   income\n1 44.41497 20.57483\nPlug the coefficient estimates and the values of the variables into the equation and calculate. \\[\nP(depressed|Female) = \\frac{e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(1)}}\n{1 + e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(1)}}\n\\]\nXB.f &lt;- -0.676 - 0.02096*(44.4) - .03656*(20.6) + 0.92945\nexp(XB.f) / (1+exp(XB.f))\n\n[1] 0.1930504\n\\[\nP(depressed|Male) = \\frac{e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(0)}}\n{1 + e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(0)}}\n\\]\nXB.m &lt;- -0.676 - 0.02096*(44.4) - .03656*(20.6)\nexp(XB.m) / (1+exp(XB.m))\n\n[1] 0.08629312\nThe probability for a 44.4 year old female who makes $20.6k annual income has a 0.19 probability of being depressed. The probability of depression for a male of equal age and income is 0.086.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Classification of Binary outcomes</span>"
    ]
  },
  {
    "objectID": "classification.html#predicted-probabilities",
    "href": "classification.html#predicted-probabilities",
    "title": "12  Classification of Binary outcomes",
    "section": "",
    "text": "Sometimes Odds Ratios can be difficult to interpret or understand.\nSometimes you just want to report the probability of the event occurring.\nOr sometimes you want to predict whether or not a new individual is going to have the event.",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Classification of Binary outcomes</span>"
    ]
  },
  {
    "objectID": "classification.html#distribution-of-predicted-probabilities",
    "href": "classification.html#distribution-of-predicted-probabilities",
    "title": "12  Classification of Binary outcomes",
    "section": "12.2 Distribution of Predicted probabilities",
    "text": "12.2 Distribution of Predicted probabilities\nWe know that not everyone in the data set is 44.4 years old and makes $20.6k annually (thankfully). So what if you want to get the model predicted probability of the event for all individuals in the data set? There’s no way I’m doing that calculation for every person in the data set.\nWe can use the predict() command to generate a vector of predictions \\(\\hat{p}_{i}\\) for each row used in the model.\n\nphat.depr &lt;- predict(dep_sex_model, type='response') # create prediction vector\nsummary(phat.depr)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.01271 0.08352 0.16303 0.17007 0.23145 0.45082 \n\nhist(phat.depr) # base R histogram\nabline(v = mean(phat.depr), col = \"blue\", lwd = 2) # add mean\n\n\n\n\n\n\n\n\nThe average predicted probability of showing symptoms of depression is 0.17.\n\n12.2.1 Plotting predictions against covariates\nAnother important feature to look at is to see how well the model discriminates between the two groups in terms of predicted probabilities. Let’s look at a plot:\n\n\n\nAny row with missing data on any variable used in the model will be dropped, and so NOT get a predicted value. So the tactic is to use the data stored in the model object.\n\n\n\nmodel.pred.data &lt;- cbind(dep_sex_model$data, phat.depr)\ntail(names(model.pred.data))\n\n[1] \"treat\"     \"beddays\"   \"acuteill\"  \"chronill\"  \"sleep\"     \"phat.depr\"\n\n\nNow that the predictions have been added back onto the data used in the model using cbind, we have covariates to use to plot the predictions against.\n\nggpubr::ggdensity(model.pred.data, x=\"phat.depr\", add=\"mean\", rug = TRUE, \n          color = \"sex\", fill = \"sex\", palette = c(\"#00AFBB\", \"#E7B800\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThink about it\n\n\n\n\nWhat do you notice in this plot?\nWhat can you infer?",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Classification of Binary outcomes</span>"
    ]
  },
  {
    "objectID": "classification.html#predicted-class-outcome",
    "href": "classification.html#predicted-class-outcome",
    "title": "12  Classification of Binary outcomes",
    "section": "12.3 Predicted Class (outcome)",
    "text": "12.3 Predicted Class (outcome)\nTo classify individual \\(i\\) as being depressed or not, we draw a binary value (\\(x_{i} = 0\\) or \\(1\\)), with probability \\(p_{i}\\) by using the rbinom function, with a size=1.\n\nset.seed(12345) #reminder: change the combo on my luggage\nplot.mpp &lt;- data.frame(pred.prob = phat.depr, \n                       pred.class = rbinom(n = length(phat.depr), \n                                           size = 1, \n                                           p = phat.depr),\n                       truth = dep_sex_model$y)\nhead(plot.mpp)\n\n   pred.prob pred.class truth\n1 0.21108906          0     0\n2 0.08014012          0     0\n3 0.15266203          0     0\n4 0.24527840          1     0\n5 0.15208679          0     0\n6 0.17056409          0     0\n\n\nApplying class labels and creating a cross table of predicted vs truth:\n\nplot.mpp &lt;- plot.mpp %&gt;% \n            mutate(pred.class = factor(pred.class, labels=c(\"Not Depressed\", \n                                                            \"Depressed\")), \n                    truth = factor(truth, labels=c(\"Not Depressed\", \n                                                   \"Depressed\")))\n\ntable(plot.mpp$pred.class, plot.mpp$truth)\n\n               \n                Not Depressed Depressed\n  Not Depressed           195        35\n  Depressed                49        15\n\n\nThe model correctly identified 195 individuals as not depressed and 15 as depressed. The model got it wrong 49 + 35 times.\nThe accuracy of the model is calculated as the fraction of times the model prediction matches the observed category:\n\n(195+15)/(195+35+49+15)\n\n[1] 0.7142857\n\n\nThis model has a 71.4% accuracy.\n\n\n\n\n\n\nThink about it\n\n\n\nIs this good? What if death were the event?",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Classification of Binary outcomes</span>"
    ]
  },
  {
    "objectID": "classification.html#confusion-matrix",
    "href": "classification.html#confusion-matrix",
    "title": "12  Classification of Binary outcomes",
    "section": "12.4 Confusion Matrix",
    "text": "12.4 Confusion Matrix\nA confusion Matrix is the 2x2 table that compares the predicted classes to the true classes.\n\ntable(plot.mpp$pred.class, plot.mpp$truth)\n\n               \n                Not Depressed Depressed\n  Not Depressed           195        35\n  Depressed                49        15\n\n\nThis table was generated by drawing a random Bernoulli variable with probability \\(p_{i}\\). This assumes that probabilities can range from [0,1], but if you look at the plots above, the predicted probabilities max out around 0.5.\nOften we adjust the cutoff value to improve accuracy. This is where we have to put our gut feeling of what probability constitutes “high risk”. For some models, this could be as low as 30%. It’s whatever the probability is that optimally separates the classes. This is an important tuning parameter because since the models we build are only based on data we measured, often there are other unmeasured confounding factors that affect the predicted probability. So our predictions don’t span the full range from [0,1].\n\n\n\n\n\n\nThink about it\n\n\n\nUsing the above plots, where should we put the cutoff value? At what probability should we classify a record as “depressed”?\n\n\nThere are many different types of criteria that can be used to find the optimal cutoff value. But first we need to understand the expanded borders of a [Confusion Matrix]. Using the confusionMatrix function inside the caret package performs all these calculations for us.\n\n\n\n\n\n\nWarning\n\n\n\nYou must specify what the ‘event’ is. This is also another place where the factor ordering of binary variables can cause headache. Another reason to control your factors!\n\n\n\nconfusionMatrix(plot.mpp$pred.class, plot.mpp$truth, positive=\"Depressed\")\n\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      Not Depressed Depressed\n  Not Depressed           195        35\n  Depressed                49        15\n                                         \n               Accuracy : 0.7143         \n                 95% CI : (0.659, 0.7652)\n    No Information Rate : 0.8299         \n    P-Value [Acc &gt; NIR] : 1.0000         \n                                         \n                  Kappa : 0.0892         \n                                         \n Mcnemar's Test P-Value : 0.1561         \n                                         \n            Sensitivity : 0.30000        \n            Specificity : 0.79918        \n         Pos Pred Value : 0.23438        \n         Neg Pred Value : 0.84783        \n             Prevalence : 0.17007        \n         Detection Rate : 0.05102        \n   Detection Prevalence : 0.21769        \n      Balanced Accuracy : 0.54959        \n                                         \n       'Positive' Class : Depressed      \n                                         \n\n\n\n195 people were correctly predicted to not be depressed (True Negative)\n49 people were incorrectly predicted to be depressed (False Positive)\n10 people were incorrectly predicted to not be depressed (False Negative)\n15 people were correctly predicted to be depressed (True Positive)",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Classification of Binary outcomes</span>"
    ]
  },
  {
    "objectID": "classification.html#vocabulary-terms",
    "href": "classification.html#vocabulary-terms",
    "title": "12  Classification of Binary outcomes",
    "section": "12.5 Vocabulary terms",
    "text": "12.5 Vocabulary terms\nAlso other names for the same term, and formulas.\n\nTrue positive (\\(n_{11}\\))\nTrue negative (\\(n_{22}\\))\nFalse positive, Type I error (\\(n_{12}\\))\nFalse negative, Type II error (\\(n_{21}\\))\nTrue positive rate (TPR), Recall, Sensitivity, probability of detection, power. P(predicted positive | total positive) \\(\\frac{\\# True Positive}{\\#Condition Positive}\\)\nTrue negative rate (TNR), Specificity, selectivity. P(predicted negative | total negative) \\(\\frac{\\# True Negative}{\\# Condition Negative}\\)\nFalse positive rate (FPR), fall-out, probability of false alarm. \\(\\frac{\\# False Positive}{\\# Condition Negative}\\)\nFalse negative rate (FNR), miss rate. \\(\\frac{\\# False Negative}{\\# Condition Positive}\\)\nPrevalence. \\(\\frac{\\# Condition Positive}{\\# Total Population}\\)\nAccuracy. \\(\\frac{\\# True Positive + \\# True Negative}{\\# Total Population}\\)\nBalanced Accuracy: \\([(n_{11}/n_{.1}) + (n_{22}/n_{.2})]/2\\) - Adjusts for class size imbalances\nPositive Predictive Value (PPV), Precision. P(true positive | predicted positive) \\(\\frac{\\# True Positive}{\\# Predicted Condition Positive}\\)\nFalse discovery rate (FDR). \\(\\frac{\\# False Positive}{\\# Predicted Condition Positive}\\)\nFalse omission rate (FOR). \\(\\frac{\\# False Negative}{\\# Predicted Condition Negative}\\)\nNegative predictive value (NPV). \\(\\frac{\\# True Negative}{\\# Predicted Condition Negative}\\)\nF1 score. The harmonic mean of precision and recall. This ranges from 0 (bad) to 1 (good): \\(\\frac{2 * (Precision * Recall)}{Precision + Recall}\\)",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Classification of Binary outcomes</span>"
    ]
  },
  {
    "objectID": "classification.html#roc-curves",
    "href": "classification.html#roc-curves",
    "title": "12  Classification of Binary outcomes",
    "section": "12.6 ROC Curves",
    "text": "12.6 ROC Curves\n\nROC curves show the balance between sensitivity and specificity.\nWe’ll use the [ROCR] package. It only takes 3 commands:\n\ncalculate prediction() using the model\ncalculate the model performance() on both true positive rate and true negative rate for a whole range of cutoff values.\nplot the curve.\n\nThe colorize option colors the curve according to the probability cutoff point.\n\n\n\n\npr &lt;- prediction(phat.depr, dep_sex_model$y)\nperf &lt;- performance(pr, measure=\"tpr\", x.measure=\"fpr\")\nplot(perf, colorize=TRUE, lwd=3, print.cutoffs.at=c(seq(0,1,by=0.1)))\nabline(a=0, b=1, lty=2)\n\n\n\n\n\n\n\n\nWe can also use the performance() function to evaluate the \\(f1\\) measure\n\nperf.f1 &lt;- performance(pr,measure=\"f\")\nperf.acc &lt;- performance(pr,measure=\"acc\")\n\npar(mfrow=c(1,2))\nplot(perf.f1)\nplot(perf.acc)\n\n\n\n\n\n\n\n\nWe can dig into the perf.f1 object to get the maximum \\(f1\\) value (y.value), then find the row where that value occurs, and link it to the corresponding cutoff value of x.\n\n(max.f1 &lt;- max(perf.f1@y.values[[1]], na.rm=TRUE))\n\n[1] 0.3937008\n\n(row.with.max &lt;- which(perf.f1@y.values[[1]]==max.f1))\n\n[1] 68\n\n(cutoff.value &lt;- perf.f1@x.values[[1]][row.with.max])\n\n      257 \n0.2282816 \n\n\nA cutoff value of 0.228 provides the most optimal \\(f1\\) score.\nROC curves:\n\nCan also be used for model comparison: Drawing ROC Curves in R with ROCR Package (Archive)\nThe Area under the Curve (auc) also gives you a measure of overall model accuracy.\n\n\nauc &lt;- performance(pr, measure='auc')\nauc@y.values\n\n[[1]]\n[1] 0.695041",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Classification of Binary outcomes</span>"
    ]
  },
  {
    "objectID": "classification.html#model-performance",
    "href": "classification.html#model-performance",
    "title": "12  Classification of Binary outcomes",
    "section": "12.7 Model Performance",
    "text": "12.7 Model Performance\n\nSay we decide that a value of 0.22828 is our optimal cutoff value to predict depression using this model. (note here is a GOOD place to use all the decimals.)\nWe can use this probability to classify each row into groups.\n\nThe assigned class values must match the data type and levels of the true value.\nIt also has to be in the same order, so the 0 group needs to come first.\nI want this matrix to show up like the one in Wikipedia, so I’m leveraging the forcats package to reverse my factor level ordering.\n\nWe can calculate a confusion matrix using the similarly named function from the caret package.\n\n\nplot.mpp$pred.class2 &lt;- ifelse(plot.mpp$pred.prob &lt;0.22828, 0,1) \nplot.mpp$pred.class2 &lt;- factor(plot.mpp$pred.class2, labels=c(\"Not Depressed\", \"Depressed\")) %&gt;%   \n                        forcats::fct_rev()\n\nconfusionMatrix(plot.mpp$pred.class2, forcats::fct_rev(plot.mpp$truth), positive=\"Depressed\")\n\nConfusion Matrix and Statistics\n\n               Reference\nPrediction      Depressed Not Depressed\n  Depressed            25            52\n  Not Depressed        25           192\n                                          \n               Accuracy : 0.7381          \n                 95% CI : (0.6839, 0.7874)\n    No Information Rate : 0.8299          \n    P-Value [Acc &gt; NIR] : 0.999973        \n                                          \n                  Kappa : 0.2362          \n                                          \n Mcnemar's Test P-Value : 0.003047        \n                                          \n            Sensitivity : 0.50000         \n            Specificity : 0.78689         \n         Pos Pred Value : 0.32468         \n         Neg Pred Value : 0.88479         \n             Prevalence : 0.17007         \n         Detection Rate : 0.08503         \n   Detection Prevalence : 0.26190         \n      Balanced Accuracy : 0.64344         \n                                          \n       'Positive' Class : Depressed       \n                                          \n\n\n\n192 people were correctly predicted to not be depressed (True Negative, \\(n_{11}\\))\n52 people were incorrectly predicted to be depressed (False Positive, \\(n_{21}\\))\n25 people were incorrectly predicted to not be depressed (False Negative, \\(n_{12}\\))\n25 people were correctly predicted to be depressed (True Positive, \\(n_{22}\\))\n\nOther terminology:\n\nSensitivity/Recall/True positive rate: P(predicted positive | total positive) = 25/(25+25) = .50\nSpecificity/true negative rate: P(predicted negative | total negative) = 192/(52+192) = .7869\nPrecision/positive predicted value: P(true positive | predicted positive) = 25/(25+52) = .3247\nAccuracy: (TP + TN)/ Total: (25 + 192)/(25+52+25+192) = .7381\nBalanced Accuracy: \\([(n_{11}/n_{.1}) + (n_{22}/n_{.2})]/2\\) - This is to adjust for class size imbalances (like in this example)\nF1 score: the harmonic mean of precision and recall. This ranges from 0 (bad) to 1 (good): \\(2*\\frac{precision*recall}{precision + recall}\\) = 2*(.3247*.50)/(.3247+.50) = .3937",
    "crumbs": [
      "Regression Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Classification of Binary outcomes</span>"
    ]
  },
  {
    "objectID": "multivariate_intro.html",
    "href": "multivariate_intro.html",
    "title": "13  Introduction",
    "section": "",
    "text": "There is an important distinction between multivariable and multivariate models.\n\nmultivariable : Multiple predictor variables (\\(\\mathbf{x}\\)).\nmultivariate: Multiple response variables (\\(\\mathbf{Y}\\)).\n\nOften analysts will misuse multivariate when they really mean multivariable.\nMultivariate techniques are\n\nPrimarily used as an exploratory technique\nRestructure interrelated variables\nSimplify description\nReduce dimensionality\nAvoid multicollinearity problems in regression\n\nWe will discuss two different, but related techniques: Principal Component Analysis and Factor Analysis.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "PCA.html",
    "href": "PCA.html",
    "title": "14  Principal Component Analysis",
    "section": "",
    "text": "14.1 When is Principal Components Analysis (PCA) used?\nNot variable selection\nPrincipal Components Analysis (PCA) differs from variable selection in two ways:\nWe are trying to understand a phenomenon by collecting a series of component measurements, but the underlying mechanics is complex and not easily understood by simply looking at each component individually. The data could be redundant and high levels of multicolinearity may be present.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#when-is-principal-components-analysis-pca-used",
    "href": "PCA.html#when-is-principal-components-analysis-pca-used",
    "title": "14  Principal Component Analysis",
    "section": "",
    "text": "simplify the description of a set of interrelated variables.\ntransform a set of correlated variables, to a new set of uncorrelated variables\ndimension reduction: collapse many variables into a few number of variables while maintaining the same amount of variation present in the data.\n\nStatistical modeling is all about explaining variance in an outcome based on the variance in predictors.\nThe new variables are called principal components, and they are ordered by the amount of variance they contain.\nSo the first few principal components, may contain the same amount of variance (information) contained in a much larger set of original variables.\n\nmultivariable outlier detection\n\nindividual records that have high values on the principal components variables are candidates for outliers or blunders on multiple variables.\n\nas a solution for multicollinearity\n\noften is it useful to obtain the first few principal components corresponding to a set of highly correlated X variables, and then conduct regression analysis on the selected components.\n\nas a step towards factor analysis (next section)\nas an exploratory technique that may be used in gaining a better understanding of the relationships between measures.\n\n\n\n\nNo dependent variable exists\nVariables are not eliminated but rather summary variables, i.e., principal components, are computed from all of the original variables.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#basic-idea",
    "href": "PCA.html#basic-idea",
    "title": "14  Principal Component Analysis",
    "section": "14.2 Basic Idea - change of coordinates",
    "text": "14.2 Basic Idea - change of coordinates\nLet’s simulate a data set that consists of 100 random pairs of observations \\(X_{1}\\) and \\(X_{2}\\) that are correlated. Let \\(X_{1} \\sim \\mathcal{N}(100, 100)\\), \\(X_{2} \\sim \\mathcal{N}(50, 50)\\), with \\(\\rho\\) the correlation between \\(X_{1}\\) and \\(X_{12}\\) set to $.\nIn matrix notation this is written as: \\(\\mathbf{X} \\sim \\mathcal{N}\\left(\\mathbf{\\mu}, \\mathbf{\\Sigma}\\right)\\) where \\[\\mathbf{\\mu} =\n  \\left(\\begin{array}\n  {r}\n  \\mu_{1} \\\\\n  \\mu_{2}\n  \\end{array}\\right),\n  \\mathbf{\\Sigma} =\n  \\left(\\begin{array}\n  {cc}\n  \\sigma_{1}^{2} & \\rho\\sigma_{1}\\sigma_{2} \\\\\n  \\rho\\sigma_{1}\\sigma_{2} & \\sigma_{2}^{2}\n  \\end{array}\\right)\n\\].\n\n\n\n\n\n\n\n\n\nGoal: Create two new variables \\(C_{1}\\) and \\(C_{2}\\) as linear combinations of \\(\\mathbf{x_{1}}\\) and \\(\\mathbf{x_{2}}\\)\n\\[ \\mathbf{C_{1}} = a_{11}\\mathbf{x_{1}} + a_{12}\\mathbf{x_{2}} \\] \\[ \\mathbf{C_{2}} = a_{21}\\mathbf{x_{1}} + a_{22}\\mathbf{x_{2}} \\]\nor more simply \\(\\mathbf{C = aX}\\), where\n\nThe \\(\\mathbf{x}\\)’s have been centered by subtracting their mean (\\(\\mathbf{x_{1}} = x_{1}-\\bar{x_{1}}\\))\n\\(Var(C_{1})\\) is as large as possible\n\nGraphically we’re creating two new axes, where now \\(C_{1}\\) and \\(C_{2}\\) are uncorrelated.\n\nPCA is mathematically defined as an orthogonal linear transformation that transforms the data to a new coordinate system such that the greatest variance by some projection of the data comes to lie on the first coordinate (called the first principal component), the second greatest variance on the second coordinate, and so on. Wikipedia\n\n\nIn Linear Algebra terms, this is a change of basis. We are changing from a coordinate system of \\((x_{1},x_{2})\\) to \\((c_{1}, c_{2})\\). If you want to see more about this concept, here is a good YouTube Video.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#more-generally",
    "href": "PCA.html#more-generally",
    "title": "14  Principal Component Analysis",
    "section": "14.3 More Generally",
    "text": "14.3 More Generally\nWe want\n\nFrom \\(P\\) original variables \\(X_{1}, \\ldots , X_{P}\\) get \\(P\\) principal components \\(C_{1}, \\ldots , C_{P}\\)\nWhere each \\(C_{j}\\) is a linear combination of the \\(X_{i}\\)’s: \\(C_{j} = a_{j1}X_{1} + a_{j2}X_{2} + \\ldots + a_{jP}X_{P}\\)\nThe coefficients are chosen such that \\(Var(C_{1}) \\geq Var(C_{2}) \\geq \\ldots \\geq Var(C_{P})\\)\n\nVariance is a measure of information. Consider modeling prostate cancer.\n\nGender has 0 variance. No information.\nSize of tumor: the variance is &gt; 0, it provides useful information.\n\n\nAny two PC’s are uncorrelated: \\(Cov(C_{i}, C_{j})=0, \\quad \\forall i \\neq j\\)\n\nWe have\n\\[\n  \\left[\n    \\begin{array}{r}\n      C_{1} \\\\\n      C_{2} \\\\\n      \\vdots \\\\\n      C_{P}\n    \\end{array}\n  \\right]\n  =\n  \\left[\n    \\begin{array}{cccc}\n      a_{11} & a_{12} & \\ldots & a_{1P} \\\\\n      a_{21} & a_{22} & \\ldots & a_{2P} \\\\\n      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n      a_{P1} & a_{P2} & \\ldots & a_{PP}\n    \\end{array}\n  \\right]\n  \\left[\n    \\begin{array}{r}\n      X_{1} \\\\\n      X_{2} \\\\\n      \\vdots \\\\\n      X_{P}\n  \\end{array}\n  \\right]\n\\]\n\nHotelling (1933) showed that the columns of the matrix \\(a_{ij}\\) are solutions to \\((\\mathbf{\\Sigma} -\\lambda\\mathbf{I})\\mathbf{a}=\\mathbf{0}\\).\n\n\\(\\mathbf{\\Sigma}\\) is the variance-covariance matrix of the \\(\\mathbf{X}\\) variables.\n\n\nThis means \\(\\lambda\\) is an eigenvalue and \\(\\mathbf{a}\\) an eigenvector of the covariance matrix \\(\\mathbf{\\Sigma}\\).\n\n(Optional) Learn more about eigenvalues [in this video].\n\nProblem: There are infinite number of possible \\(\\mathbf{a}\\)’s\nSolution: Choose \\(a_{ij}\\)’s such that the sum of the squares of the coefficients for any one eigenvector is = 1.\n\n\\(P\\) unique eigenvalues and \\(P\\) corresponding eigenvectors.\n\n\nWhich gives us\n\nVariances of the \\(C_{j}\\)’s add up to the sum of the variances of the original variables (total variance).\nCan be thought of as variance decomposition into orthogonal (independet) vectors (variables).\nWith \\(Var(C_{1}) \\geq Var(C_{2}) \\geq \\ldots \\geq Var(C_{P})\\).",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#r-commands",
    "href": "PCA.html#r-commands",
    "title": "14  Principal Component Analysis",
    "section": "14.4 R commands",
    "text": "14.4 R commands\n\n\n\n\n\n\nCorresponding reading\n\n\n\nPMA6 Ch 14.3-14.4\n\n\nCalculating the principal components in R can be done using the function prcomp(), princomp() and functions from the factoextra package. This section of notes uses princomp() to generate the PCAs and helper functions from factoextra package. STHDA is a great reference for these functions.\n\n14.4.1 Generating PC’s\nThe matrix that is used in princomp must be fully numeric.\n\npr &lt;- princomp(data)\n\n\n\n14.4.2 Viewing the amount of variance contained by each PC\nUse summary or get_eigenvalue to see the variance breakdown.\n\nsummary(pr)\n\nImportance of components:\n                           Comp.1    Comp.2\nStandard deviation     11.4019265 4.2236767\nProportion of Variance  0.8793355 0.1206645\nCumulative Proportion   0.8793355 1.0000000\n\nfactoextra::get_eigenvalue(pr)\n\n      eigenvalue variance.percent cumulative.variance.percent\nDim.1  130.00393         87.93355                    87.93355\nDim.2   17.83944         12.06645                   100.00000\n\n\nThe first PC (Comp.1) will always explain the highest proportion of variance (by mathematical design).\n\n\n14.4.3 Visualize Loadings\n\nMatrixVector plotHeatmapStrength of representationCorrelation circle\n\n\n\nThe values for the matrix \\(\\mathbf{A}\\) is contained in pr$loadings. Alternatively the loadings function will extract this matrix.\n\n\npr$loadings\n\n\nLoadings:\n   Comp.1 Comp.2\nX1  0.854  0.519\nX2  0.519 -0.854\n\n               Comp.1 Comp.2\nSS loadings       1.0    1.0\nProportion Var    0.5    0.5\nCumulative Var    0.5    1.0\n\nloadings(pr)\n\n\nLoadings:\n   Comp.1 Comp.2\nX1  0.854  0.519\nX2  0.519 -0.854\n\n               Comp.1 Comp.2\nSS loadings       1.0    1.0\nProportion Var    0.5    0.5\nCumulative Var    0.5    1.0\n\n\n\\[\nC_{1} = 0.854x_1 + 0.519X_2 \\\\\nC_{2} =  0.519x_1 - 0.854X_2\n\\]\n\n\nTo visualize how these two new PC’s create new axes these new axes, we plot the centered data.\n\na &lt;- pr$loadings\nx1 &lt;- with(data, X1 - mean(X1))\nx2 &lt;- with(data, X2 - mean(X2))\n\nplot(c(-40, 40), c(-20, 20), type=\"n\",xlab=\"x1\", ylab=\"x2\")\npoints(x=x1, y=x2, pch=16)\nabline(0, a[2,1]/a[1,1]); text(30, 10, expression(C[1]))\nabline(0, a[2,2]/a[1,2]); text(-10, 20, expression(C[2]))\n\n\n\n\n\n\n\n\nAnother useful plot is called a biplot. Here the PC’s are on the dominant axes, and the red vectors show you the magnitude and direction of the original variables on this new axis.\n\nbiplot(pr)\n\n\n\n\n\n\n\nlibrary(factoextra)\nfviz_pca_biplot(pr)\n\n\n\n\n\n\n\n\n\nX1 is positively correlated with both PC1 and PC2\nX2 is positively correlated with PC1 but negatively correlated with PC2.\n\nThis information was also seen in the loading values.\n\n\n\nOften in high dimensional studies, the loadings are visualized using a heatmap.\nHere we use the heatmap.2() in the gplots package. I encourage you to play with the options such as dendogram and trace to see what they remove/add, and review the ?heatmap.2 help file.\n\n\nlibrary(gplots)\nheatmap.2(pr$loadings, dendrogram=\"none\", trace=\"none\", density.info=\"none\")\n\n\n\n\n\n\n\n\n\n\nContribution of rows/columns to the PC’s. For a given dimension, any row/column with a contribution above the reference line could be considered as important in contributing to the dimension.\n\nfviz_contrib(pr, choice = \"var\", axes = 1)\n\n\n\n\n\n\n\n\nX1 contributes more than half of the amount of information to PC1 compared to X2\n\n\nWith only 2 PC’s this isn’t that informative. The later example and the vignette are likely more helpful.\nSee STDHA correlation circle for detailed information.\n\nfviz_pca_var(pr, col.var = \"contrib\", axes=c(1,2),\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE # Avoid text overlapping\n             )",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#data-reduction",
    "href": "PCA.html#data-reduction",
    "title": "14  Principal Component Analysis",
    "section": "14.5 Data Reduction",
    "text": "14.5 Data Reduction\n\n\n\n\n\n\nCorresponding reading\n\n\n\nPMA6 Ch 14.5\n\n\n\nKeep first \\(m\\) principal components as representatives of original P variables\nKeep enough to explain a large percentage of original total variance.\nIdeally you want a small number of PC’s that explain a large percentage of the total variance.\n\n\n14.5.1 Choosing \\(m\\)\n\nRely on existing theory\nExplain a given % of variance (cumulative percentage plot)\nAll eigenvalues &gt; 1 (Scree plot)\nElbow rule (Scree Plot)\n\nA Scree plot is created by plotting the eigenvalue against the PC number.\n\nfviz_eig(pr, addlabels = TRUE)\n\n\n\n\n\n\n\n\nThese are best understood using an example containing more than two PC’s, but there is one more thing to consider first and that is how the data is prepared before calculating the principal components.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#standardizing",
    "href": "PCA.html#standardizing",
    "title": "14  Principal Component Analysis",
    "section": "14.6 Standardizing",
    "text": "14.6 Standardizing\nOften researchers will standardize the \\(x\\) variables before conducting a PCA.\n\nStandardizing: Take \\(X\\) and divide each element by \\(\\sigma_{x}\\).\n\\[\\frac{X}{\\sigma_{X}}\\]\nNormalizing: Centering and standardizing.\n\\[Z = \\frac{(X-\\bar{X})}{\\sigma_{X}}\\]\nEquivalent to analyzing the correlation matrix (\\(\\mathbf{R}\\)) instead of covariance matrix (\\(\\mathbf{\\Sigma}\\)).\n\n\n\n\nUsing correlation matrix vs covariance matrix will generate different PC’s\n\n\nThis makes sense given the difference in matricies:\n\ncov(data) #Covariance Matrix\n\n          X1       X2\nX1 100.74146 50.29187\nX2  50.29187 48.59528\n\ncor(data) #Correlation Matrix\n\n          X1        X2\nX1 1.0000000 0.7187811\nX2 0.7187811 1.0000000\n\n\nStandardizing your data prior to analysis (using \\(\\mathbf{R}\\) instead of \\(\\mathbf{\\Sigma}\\)) aids the interpretation of the PC’s in a few ways\n\nThe total variance is the number of variables \\(P\\)\nThe proportion explained by each PC is the corresponding eigenvalue / \\(P\\)\nThe correlation between \\(C_{i}\\) and standardized variable \\(x_{j}\\) can be written as \\(r_{ij} = a_{ij}SD(C_{i})\\)\n\nThis last point means that for any given \\(C_{i}\\) we can quantify the relative degree of dependence of the PC on each of the standardized variables. This is a.k.a. the factor loading (we will return to this key term later).\nTo calculate the principal components using the correlation matrix using princomp, set the cor argument to TRUE.\n\npr_corr &lt;- princomp(data, cor=TRUE)\nsummary(pr_corr)\n\nImportance of components:\n                          Comp.1    Comp.2\nStandard deviation     1.3110229 0.5303008\nProportion of Variance 0.8593906 0.1406094\nCumulative Proportion  0.8593906 1.0000000\n\npr_corr$loadings\n\n\nLoadings:\n   Comp.1 Comp.2\nX1  0.707  0.707\nX2  0.707 -0.707\n\n               Comp.1 Comp.2\nSS loadings       1.0    1.0\nProportion Var    0.5    0.5\nCumulative Var    0.5    1.0\n\n\n\nIf we use the covariance matrix and change the scale of a variable (i.e. in to cm) that will change the results of the PC’s\nMany researchers prefer to use the correlation matrix\n\nIt compensates for the units of measurements for the different variables.\nInterpretations are made in terms of the standardized variables.\n\n\n\\[\nC_{1} = 0.707x_1 + 0.707X_2 \\\\\nC_{2} = 0.707x_1 - 0.707X_2\n\\]\nI want to compare them side by side in a nice table.\n\ndata.frame(PC1.cov = loadings(pr)[,1],\n           PC2.cov = loadings(pr)[,2],\n           PC1.cor = loadings(pr_corr)[,1],\n           PC2.cor = loadings(pr_corr)[,2]) |&gt; kable(digits=2)\n\n\n\n\n\nPC1.cov\nPC2.cov\nPC1.cor\nPC2.cor\n\n\n\n\nX1\n0.85\n0.52\n0.71\n0.71\n\n\nX2\n0.52\n-0.85\n0.71\n-0.71",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#example",
    "href": "PCA.html#example",
    "title": "14  Principal Component Analysis",
    "section": "14.7 Example",
    "text": "14.7 Example\n\n\n\n\n\n\nData\n\n\n\nThis example follows Analysis of depression data set section in PMA6 Section 14.5. This survey asks 20 questions on emotional states that relate to depression. The data is recorded as numeric, but are categorical in nature where 0 - “rarely or none of the time”, 1 - “some or a little of the time” and so forth.\n\n\n\ndepress &lt;- read.delim(\"https://www.norcalbiostat.com/data/Depress.txt\", header=TRUE)\ntable(depress$c1)\n\n&lt; table of extent 0 &gt;\n\n\nThese questions are typical of what is asked in survey research, and often are thought of, or treated as pseudo-continuous. They are ordinal categorical variables, but they are not truly interval measures since the “distance” between 0 and 1 (rarely and some of the time), would not be considered the same as the distance between 2 (moderately) and 3 (most or all of the time). And “moderately” wouldn’t be necessarily considered as “twice” the amount of “rarely”.\nOur options to use these ordinal variables in a model come down to three options.\n\nconvert to a factor and include it as a categorical (series of indicators) variable.\n\nThis can be even more problematic when there are 20 categorical variables. You run out of degrees of freedom very fast with that many predictors.\n\nleave it as numeric and treat it as pseudo-continuous ordinal measure. Where you can interpret as “as x increases y changes by…”, but\naggregate across multiple likert-type-ordinal variables and create a new calculated scale variable that can be treated as continuous.\n\nThis is what PCA does by creating new variables \\(C_{1}\\) that are linear combinations of the original \\(x's\\).\n\n\nIn this example I use PCA to reduce these 20 correlated variables down to a few uncorrelated variables that explain the most variance.\n1. Read in the data and run princomp on the C1:C20 variables.\n\npc_dep  &lt;- princomp(depress[,9:28], cor=TRUE)\nsummary(pc_dep)\n\nImportance of components:\n                          Comp.1     Comp.2     Comp.3     Comp.4     Comp.5\nStandard deviation     2.6562036 1.21883931 1.10973409 1.03232021 1.00629648\nProportion of Variance 0.3527709 0.07427846 0.06157549 0.05328425 0.05063163\nCumulative Proportion  0.3527709 0.42704935 0.48862483 0.54190909 0.59254072\n                           Comp.6     Comp.7     Comp.8     Comp.9    Comp.10\nStandard deviation     0.98359581 0.97304489 0.87706188 0.83344885 0.81248191\nProportion of Variance 0.04837304 0.04734082 0.03846188 0.03473185 0.03300634\nCumulative Proportion  0.64091375 0.68825457 0.72671645 0.76144830 0.79445464\n                          Comp.11    Comp.12    Comp.13    Comp.14    Comp.15\nStandard deviation     0.77950975 0.74117295 0.73255278 0.71324438 0.67149280\nProportion of Variance 0.03038177 0.02746687 0.02683168 0.02543588 0.02254513\nCumulative Proportion  0.82483641 0.85230328 0.87913496 0.90457083 0.92711596\n                          Comp.16    Comp.17    Comp.18    Comp.19     Comp.20\nStandard deviation     0.61252016 0.56673129 0.54273638 0.51804873 0.445396635\nProportion of Variance 0.01875905 0.01605922 0.01472814 0.01341872 0.009918908\nCumulative Proportion  0.94587501 0.96193423 0.97666237 0.99008109 1.000000000\n\n\n2. Pick a subset of PC’s to work with\nIn the cumulative percentage plot below, I drew a reference line at 80%. So the first 10 PC’s can explain around 80% of the variance in the data.\n\n(create.cumvar.plot &lt;- get_eigenvalue(pc_dep) %&gt;%\n  mutate(PC = paste0(\"PC\", 1:20), # create a new variable containing the PC name\n         PC = forcats::fct_reorder(PC, cumulative.variance.percent))  # reorder this by the value of the cumulative variance\n ) \n\n       eigenvalue variance.percent cumulative.variance.percent   PC\nDim.1   7.0554177       35.2770884                    35.27709  PC1\nDim.2   1.4855693        7.4278463                    42.70493  PC2\nDim.3   1.2315098        6.1575488                    48.86248  PC3\nDim.4   1.0656850        5.3284251                    54.19091  PC4\nDim.5   1.0126326        5.0631630                    59.25407  PC5\nDim.6   0.9674607        4.8373036                    64.09138  PC6\nDim.7   0.9468164        4.7340818                    68.82546  PC7\nDim.8   0.7692375        3.8461877                    72.67164  PC8\nDim.9   0.6946370        3.4731850                    76.14483  PC9\nDim.10  0.6601269        3.3006343                    79.44546 PC10\nDim.11  0.6076355        3.0381773                    82.48364 PC11\nDim.12  0.5493373        2.7466867                    85.23033 PC12\nDim.13  0.5366336        2.6831679                    87.91350 PC13\nDim.14  0.5087176        2.5435878                    90.45708 PC14\nDim.15  0.4509026        2.2545129                    92.71160 PC15\nDim.16  0.3751809        1.8759047                    94.58750 PC16\nDim.17  0.3211844        1.6059218                    96.19342 PC17\nDim.18  0.2945628        1.4728139                    97.66624 PC18\nDim.19  0.2683745        1.3418724                    99.00811 PC19\nDim.20  0.1983782        0.9918908                   100.00000 PC20\n\nggplot(create.cumvar.plot, \n       aes(y = PC, \n           x = cumulative.variance.percent)) + \n  geom_point(size=4) + \n  geom_vline(xintercept = 80)\n\n\n\n\n\n\n\n\n3. Create a Scree plot by plotting the eigenvalue or the proportion of variance from that eigenvalue against the PC number.\n\ngridExtra::grid.arrange(\n  fviz_eig(pc_dep, choice = \"eigenvalue\", addlabels = TRUE),\n  fviz_screeplot(pc_dep, addlabels = TRUE)\n)\n\n\n\n\n\n\n\n\n\nOption 1: Take all eigenvalues &gt; 1 (\\(m=5\\))\n\nOption 2: Use a cutoff point where the lines joining consecutive points are steep to the left of the cutoff point and flat right of the cutoff point. Point where the two slopes meet is the elbow. (\\(m=2\\)).\n\n4. Examine the loadings\n\npc_dep$loadings[1:3,1:5]\n\n      Comp.1      Comp.2     Comp.3       Comp.4      Comp.5\nC1 0.2774384  0.14497938 0.05770239  0.002723687  0.08826773\nC2 0.3131829 -0.02713557 0.03162990 -0.247811083  0.02439748\nC3 0.2677985  0.15471968 0.03459037 -0.247246879 -0.21830547\n\n\nHere\n\n\\(X_{1}\\) = “I felt that I could not shake…”\n\\(X_{2}\\) = “I felt depressed…”\n\nSo the PC’s are calculated as\n\\[\nC_{1} = 0.277x_{1} + 0.313x_{2} + \\ldots \\\\\nC_{2} = -0.1449x_{1} + 0.0271x_{2} + \\ldots\n\\]\netc…\n\n\n\nThe full question text for the depression data used here can be found on Table 14.2 in the PMA6 textbook.\n\n\n5. Interpret the PC’s\n\nVisualize the loadings using heatmap.2() in the gplots package.\n\nI reversed the colors so that red was high positive correlation and yellow/white is low.\nhalf the options I use below come from this SO post. I had no idea what they did, so I took what the solution showed, and played with it (added/changed some to see what they did), and reviewed ?heatmap.2 to see what options were available.\n\n\n\nheatmap.2(pc_dep$loadings[,1:5], scale=\"none\", Rowv=NA, Colv=NA, density.info=\"none\",\n          dendrogram=\"none\", trace=\"none\", col=rev(heat.colors(256)))\n\n\n\n\n\n\n\n\n\nLoadings over 0.5 (red) help us interpret what these components could “mean”\n\nMust know exact wording of component questions\n\n\\(C_{1}\\): a weighted average of most items. High value indicates the respondent had many symptoms of depression. Note sign of loadings are all positive and all roughly the same color.\n\nRecall\n\n\\(C_{2}\\): lethargy (high energetic). High loading on c14, 16, 17, low on 4, 8, 20\n\\(C_{3}\\): friendliness of others. Large negative loading on c19, c9\n\netc.\nContributions*\n\nfviz_contrib(pc_dep, choice = \"var\", axes = 1, top=10)\n\n\n\n\n\n\n\nfviz_contrib(pc_dep, choice = \"var\", axes = 2, top=10)\n\n\n\n\n\n\n\n\n\nfviz_pca_var(pc_dep, col.var = \"contrib\", axes=c(1,2),\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE # Avoid text overlapping\n             )\n\n\n\n\n\n\n\nfviz_pca_var(pc_dep, col.var = \"contrib\", axes=c(3,4),\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE # Avoid text overlapping\n             )",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#use-in-multiple-regression",
    "href": "PCA.html#use-in-multiple-regression",
    "title": "14  Principal Component Analysis",
    "section": "14.8 Use in Multiple Regression",
    "text": "14.8 Use in Multiple Regression\n\nChoose a handful of few principal components to use as predictors in a regression model\n\nLeads to more stable regression estimates.\n\nAlternative to variable selection\n\nEx: several measures of behavior.\nUse PC\\(_{1}\\) or PC\\(_{1}\\) and PC\\(_{2}\\) as summary measures of all.\n\n\n\n14.8.1 Example: Modeling acute illness\nThe 20 depression questions C1:C20 were designed to be added together to create the CESD scale directly. While this is a validate measure, what if some components (e.g. had crying spells) contributes more to someones level of depression than another measure (e.g. people were unfriendly). Since the PC’s are linear combinations of the \\(x\\)’s, the coefficients \\(a\\), or the loadings, aren’t all equal as we’ve seen. So let’s see if the first two PC’s (since that’s what was chosen from the scree plot) can predict chronic illness better than the straight summative score of cesd.\n1. Extract PC scores and attach them to the data. \nThe scores for each PC for each observation is stored in the scores list object in the pc_dep object.\n\ndim(pc_dep$scores); kable(pc_dep$scores[1:5, 1:5])\n\n[1] 294  20\n\n\n\n\n\nComp.1\nComp.2\nComp.3\nComp.4\nComp.5\n\n\n\n\n-2.446342\n0.6236068\n0.1288289\n-0.2546597\n-0.1624772\n\n\n-1.452116\n-0.1763085\n0.5861563\n-0.6781969\n-0.3225529\n\n\n-1.468211\n-0.4350019\n0.2893955\n-0.3243790\n-0.2513590\n\n\n-1.324852\n1.7766419\n1.0833599\n1.2651869\n-1.1339350\n\n\n-1.449606\n2.3576522\n-0.7489288\n1.9464680\n1.2229057\n\n\n\n\ndepress$pc1 &lt;- pc_dep$scores[,1]\ndepress$pc2 &lt;- pc_dep$scores[,2]\n\n2. Fit a model using those PC scores as covariates\nAlong with any other covariates chosen by other methods.\n\nglm(ACUTEILL~pc1+pc2, data=depress, family='binomial') %&gt;% summary()\n\n\nCall:\nglm(formula = ACUTEILL ~ pc1 + pc2, family = \"binomial\", data = depress)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.87695    0.12901  -6.798 1.06e-11 ***\npc1          0.07921    0.04608   1.719   0.0856 .  \npc2          0.10321    0.10409   0.992   0.3214    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 357.13  on 293  degrees of freedom\nResidual deviance: 353.09  on 291  degrees of freedom\nAIC: 359.09\n\nNumber of Fisher Scoring iterations: 4\n\nglm(ACUTEILL~CESD, data=depress, family='binomial') %&gt;% summary()\n\n\nCall:\nglm(formula = ACUTEILL ~ CESD, family = \"binomial\", data = depress)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.09721    0.18479  -5.938 2.89e-09 ***\nCESD         0.02494    0.01392   1.792   0.0731 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 357.13  on 293  degrees of freedom\nResidual deviance: 353.97  on 292  degrees of freedom\nAIC: 357.97\n\nNumber of Fisher Scoring iterations: 4\n\n\nIn this example, the model using the PC’s and the model using cesd were very similar. However, this is an example where an aggregate measure such as cesd has already been figured out scientifically and validated. This is not often the case, expecially in exploratory data analysis when you are not sure -how- the measures are correlated.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#things-to-watch-out-for",
    "href": "PCA.html#things-to-watch-out-for",
    "title": "14  Principal Component Analysis",
    "section": "14.9 Things to watch out for",
    "text": "14.9 Things to watch out for\n\nEigenvalues are estimated variances of the PC’s and so are subject to large sample variations.\nThe size of variance of last few principal components can be useful as indicator of multicollinearity among original variables\nPrincipal components derived from standardized variables differ from those derived from original variables\nImportant that measurements are accurate, especially for detection of collinearity\n\n\n\n\n\n\n\nCaution\n\n\n\nArbitrary cutoff points should not be taken too seriously.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "PCA.html#additional-references",
    "href": "PCA.html#additional-references",
    "title": "14  Principal Component Analysis",
    "section": "14.10 Additional References",
    "text": "14.10 Additional References\nA collection of other tools and websites that do a good job of explaining PCA.\n\nPrincipal Component Analysis Essentials in R tutorial by STHDA\nStack Overflow This has animations, and walks through the explanation using wine and “how you would explain it to your grandma”.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "FA.html",
    "href": "FA.html",
    "title": "15  Factor Analysis",
    "section": "",
    "text": "15.1 Introduction\nNo attempt will be made to present a comprehensive treatment of this subject. For more detail see the references mentioned in PMA6 Chapter 15.2 and the links in the Additional Resources section for more information.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factor Analysis</span>"
    ]
  },
  {
    "objectID": "FA.html#introduction",
    "href": "FA.html#introduction",
    "title": "15  Factor Analysis",
    "section": "",
    "text": "This intro comes from A gentle non-technical introduction to factor analysis\n\n\n\n\n\n15.1.1 Latent Constructs\nLatent variables are ones that cannot be measured directly; e.g. Depression, Anxiety, Mathematical ability. They drive how we would respond to various tasks and questions that can be measured; vocabulary, arithmetic, statistical reasoning.\nFactor Analysis aims to\n\nGeneralize of principal components analysis\nExplain interrelationships among a set of variables\nWhere we select a small number of factors to convey essential information\nCan perform additional analyses to improve interpretation\n\n\n\n15.1.2 Comparison with PCA\n\nSimilar in that no dependent variable\nPCA:\n\nSelect a number of components that explain as much of the total variance as possible.\n\nFA: Factors selected mainly to explain the interrelationships among the original variables.\n\nIdeally, the number of factors expected is known in advance.\nMajor emphasis is placed on obtaining easily understandable factors that convey the essential information contained in the original set of variables.\n\n\n\n\n\nReference\n\n\n\nMirror image of PCA\n\nEach PC is expressed as a linear combination of X’s\nEach \\(X\\) is expressed as a linear combination of Factors\n\n\n\n\n15.1.3 EFA vs CFA\nExploratory Factor Analysis\n\nExplore the possible underlying factor structure of a set of observed variables\nDoes not impose a preconceived structure on the outcome.\n\nConfirmatory Factor Analysis\n\nVerifies the theoretical factor structure of a set of observed variables\nTest the relationship between observed variables and theoretical underlying latent constructs\nVariable groupings are determined ahead of time.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factor Analysis</span>"
    ]
  },
  {
    "objectID": "FA.html#factor-model",
    "href": "FA.html#factor-model",
    "title": "15  Factor Analysis",
    "section": "15.2 Factor Model",
    "text": "15.2 Factor Model\n\nStart with P standardized variables. That is \\(\\frac{(x_{i}-\\bar{x})}{s_{i}}\\).\n\nSo for the rest of these FA notes, understand that each \\(X\\) written has already been standardized.\n\nExpress each variable as (its own) linear combination of \\(m\\) common factors plus a unique factor \\(e\\).\n\n\\[\n\\begin{equation}\n\\begin{aligned}\nX_{1} = l_{11}F_{1} + l_{12}F_{2} + \\ldots + l_{1m}F_{m} + e_{1} \\\\\nX_{2} = l_{21}F_{1} + l_{22}F_{2} + \\ldots + l_{2m}F_{m} + e_{1} \\\\\n\\vdots \\\\\nX_{P} = l_{P1}F_{1} + l_{P2}F_{2} + \\ldots + l_{Pm}F_{m} + e_{P} \\\\\n\\end{aligned}\n\\end{equation}\n\\]\n\n\\(m\\) is the number of common factors, typicall \\(m &lt;&lt; P\\). Somemtimes, \\(m\\) is known in advance.\n\\(X_{i}    = \\sum l_{ij} F_{j}+ \\epsilon_{i}\\)\n\\(F_{j}\\) = common or latent factors.\n\nThey are uncorrelated and each having mean 0 and variance 1\n\n\\(l_{ij}\\) = coefficients of common factors = factor loadings\n\\(e_{i}\\) = unique factors relating to one of the original variables.\n\n\\(e_{i}\\)’s and \\(F_{j}\\)’s are uncorrelated\n\n\n\n15.2.1 Components of Variance\nRecall that \\(x_{i}\\) is standardized, so \\(Var(X)=1\\).\nSince each response variable \\(x_{i}\\) is broken into two parts, so is the variance.\n\ncommunality: part due to common factors. Denoted as \\(h^{2}_{i}\\).\nspecificity: part due to a unique factor. Denoted as \\(u^{2}_{i}\\).\n\n\\(V(X_{i}) = h^{2}_{i} + u^{2}_{i}\\)\n\n\n\n\n\n\nCaution\n\n\n\nIf the number \\(m\\) of common factors is not known (EFA), it is recommended that you start with the default option available in the softare program. Often this is the number of factors with eigenvalues greater than 1.\nSince the results are highly dependent on \\(m\\), you should always try several factors to gain further insight into the data.\n\n\n\n\n15.2.2 Two big steps\n\nThe first step is to numerical find estimates of the loadings \\(l_{ij}\\), and the communalities \\(h^{2}_{i}\\). This process is called initial factor extraction. There are a number of methods to solve, we will explore three: principal components, iterated components, and maximum likelihood. The mathematical details of each are left in the textbook for interested readers.\nThe second step is to obtain a new set of factors, called rotated factors which is done to improve interpretation.\n\nWe will first explore these steps using simulated data.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factor Analysis</span>"
    ]
  },
  {
    "objectID": "FA.html#fa-example",
    "href": "FA.html#fa-example",
    "title": "15  Factor Analysis",
    "section": "15.3 Example data setup",
    "text": "15.3 Example data setup\nGenerate 100 data points from the following multivariate normal distribution:\n\\[\\mathbf{\\mu} =\n  \\left(\\begin{array}\n  {r}\n  0.163 \\\\\n  0.142 \\\\\n  0.098 \\\\\n  -0.039 \\\\\n  -0.013\n  \\end{array}\\right),\n  \\mathbf{\\Sigma} =\n  \\left(\\begin{array}\n  {cc}\n  1     &       &   &   &     &  \\\\\n  0.757 & 1     &   &   &     &  \\\\\n  0.047 & 0.054 & 1 &   &     &  \\\\\n  0.155 & 0.176 & 0.531 & 1   &  \\\\\n  0.279 & 0.322 & 0.521 & 0.942 & 1\n  \\end{array}\\right)\n\\].\n\nset.seed(456)\nm &lt;- c(0.163, 0.142, 0.098, -0.039, -0.013)\ns &lt;- matrix(c(1.000, 0.757, 0.047, 0.155, 0.279, \n              0.757, 1.000, 0.054, 0.176, 0.322, \n              0.047, 0.054, 1.000, 0.531, 0.521, \n              0.155, 0.176, 0.531, 1.000, 0.942, \n              0.279, 0.322, 0.521, 0.942, 1.000), \n            nrow=5)\ndata &lt;- data.frame(MASS::mvrnorm(n=100, mu=m, Sigma=s))\ncolnames(data) &lt;- paste0(\"X\", 1:5)\n\nStandardize the \\(X\\)’s.\n\nstan.dta &lt;- as.data.frame(scale(data))\n\nThe hypothetical data model is that these 5 variables are generated from 2 underlying factors.\n\\[\n\\begin{equation}\n\\begin{aligned}\nX_{1} &=  (1)*F_{1} +    (0)*F_{2} + e_{1} \\\\\nX_{2} &=  (1)*F_{1} +    (0)*F_{2} + e_{2} \\\\\nX_{3} &=  (0)*F_{1} +   (.5)*F_{2} + e_{3} \\\\\nX_{4} &=  (0)*F_{1} + (1.5)*F_{2} + e_{4} \\\\\nX_{5} &=  (0)*F_{1} +    (2)*F_{2} + e_{5} \\\\\n\\end{aligned}\n\\end{equation}\n\\]\nImplications\n\n\\(F_{1}, F_{2}\\) and all \\(e_{i}\\)’s are independent normal variables\nThe first two \\(X\\)’s are inter-correlated, and the last 3 \\(X\\)’s are inter-correlated\nThe first 2 \\(X\\)’s are NOT correlated with the last 3 \\(X\\)’s\n\n\n#library(corrplot)\ncorrplot(cor(stan.dta), tl.col=\"black\")",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factor Analysis</span>"
    ]
  },
  {
    "objectID": "FA.html#fa-extract",
    "href": "FA.html#fa-extract",
    "title": "15  Factor Analysis",
    "section": "15.4 Factor Extraction Methods",
    "text": "15.4 Factor Extraction Methods\nMethods\n\nPrincipal Components\nIterated Components\nMaximum Likelihood\n\n\n15.4.1 Principal components (PC Factor model)\nRecall that \\(\\mathbf{C} = \\mathbf{A}\\mathbf{X}\\), C’s are a function of X\n\\[ C_{1} = a_{11}X_{1} + a_{12}X_{2} + \\ldots + a_{1P}X_{p} \\]\nWe want the reverse: X’s are a function of F’s.\n\nUse the inverse! –&gt; If \\(c = 5x\\) then \\(x = 5^{-1}C\\)\n\nThe inverse PC model is \\(\\mathbf{X} = \\mathbf{A}^{-1}\\mathbf{C}\\).\nSince \\(\\mathbf{A}\\) is orthogonal, \\(\\mathbf{A}^{-1} = \\mathbf{A}^{T} = \\mathbf{A}^{'}\\), so\n\\[ X_{1} = a_{11}C_{1} + a_{21}C_{2} + \\ldots + a_{P1}C_{p} \\]\nBut there are more PC’s than Factors…\n\\[\n\\begin{equation}\n\\begin{aligned}\nX_{i} &=  \\sum_{j=1}^{P}a_{ji}C_{j} \\\\\n&= \\sum_{j=1}^{m}a_{ji}C_{j} + \\sum_{j=m+1}^{m}a_{ji}C_{j} \\\\\n&= \\sum_{j=1}^{m}l_{ji}F_{j} + e_{i} \\\\\n\\end{aligned}\n\\end{equation}\n\\]\nAdjustment\n\n\\(V(C_{j}) = \\lambda_{j}\\) not 1\nWe transform: \\(F_{j} = C_{j}\\lambda_{j}^{-1/2}\\)\nNow \\(V(F_{j}) = 1\\)\nLoadings: \\(l_{ij} = \\lambda_{j}^{1/2}a_{ji}\\)\n\n\n\n\n\\(l_{ij}\\) is the correlation coefficient between variable \\(i\\) and factor \\(j\\)\n\n\nThis is similar to \\(a_{ij}\\) in PCA.\nR code\nFactor extraction via principal components can be done using the principal function in the psych package. We choose nfactors=2 here because we know there are 2 underlying factors in the data generation model.\n\n#library(psych)\npc.extract.norotate &lt;- principal(stan.dta, nfactors=2, rotate=\"none\")\nprint(pc.extract.norotate)\n\nPrincipal Components Analysis\nCall: principal(r = stan.dta, nfactors = 2, rotate = \"none\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n    PC1   PC2   h2    u2 com\nX1 0.57  0.75 0.89 0.112 1.9\nX2 0.61  0.72 0.89 0.113 1.9\nX3 0.58 -0.51 0.59 0.406 2.0\nX4 0.87 -0.38 0.89 0.109 1.4\nX5 0.92 -0.27 0.91 0.086 1.2\n\n                       PC1  PC2\nSS loadings           2.63 1.55\nProportion Var        0.53 0.31\nCumulative Var        0.53 0.83\nProportion Explained  0.63 0.37\nCumulative Proportion 0.63 1.00\n\nMean item complexity =  1.7\nTest of the hypothesis that 2 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.09 \n with the empirical chi square  16.62  with prob &lt;  4.6e-05 \n\nFit based upon off diagonal values = 0.96\n\n\n\\[\n\\begin{equation}\n\\begin{aligned}\nX_{1} &=  0.53F_{1} + 0.78F_{2} + e_{1} \\\\\nX_{2} &=  0.59F_{1} + 0.74F_{2} + e_{2} \\\\\nX_{3} &=  0.70F_{1} - 0.39F_{2} + e_{3} \\\\\nX_{4} &=  0.87F_{1} - 0.38F_{2} + e_{4} \\\\\nX_{5} &=  0.92F_{1} - 0.27F_{2} + e_{5} \\\\\n\\end{aligned}\n\\end{equation}\n\\]\nThese equations come from the top of the output, under Standardized loadings.\n\n\n15.4.2 Iterated components\nSelect common factors to maximize the total communality\n\nGet initial communality estimates\nUse these (instead of original variances) to get the PC’s and factor loadings\nGet new communality estimates\nRinse and repeat\nStop when no appreciable changes occur.\n\nR code not shown, but can be obtained using the factanal package in R.\n\n\n15.4.3 Maximum Likelihood\n\nAssume that all the variables are normally distributed\nUse Maximum Likelihood to estimate the parameters\n\nR code\nThe cutoff argument hides loadings under that value for ease of interpretation. Here I am setting that cutoff at 0 so that all loadings are being displayed. I encourage you to adjust this cutoff value in practice to see how it can be useful in reducing cognitave load of looking through a grid of numbers.\n\nml.extract.norotate &lt;- factanal(stan.dta, factors=2, rotation=\"none\")\nprint(ml.extract.norotate, digits=2, cutoff=0)\n\n\nCall:\nfactanal(x = stan.dta, factors = 2, rotation = \"none\")\n\nUniquenesses:\n  X1   X2   X3   X4   X5 \n0.33 0.06 0.72 0.08 0.01 \n\nLoadings:\n   Factor1 Factor2\nX1  0.35    0.74  \nX2  0.41    0.88  \nX3  0.50   -0.18  \nX4  0.94   -0.19  \nX5  0.99   -0.07  \n\n               Factor1 Factor2\nSS loadings       2.41    1.39\nProportion Var    0.48    0.28\nCumulative Var    0.48    0.76\n\nTest of the hypothesis that 2 factors are sufficient.\nThe chi square statistic is 0.4 on 1 degree of freedom.\nThe p-value is 0.526 \n\n\nThe factor equations now are:\n\\[\n\\begin{equation}\n\\begin{aligned}\nX_{1} &=  -0.06F_{1} + 0.79F_{2} + e_{1} \\\\\nX_{2} &=  -0.07F_{1} + 1F_{2} + e_{2} \\\\\nX_{3} &=  0.58F_{1} + 0.19F_{2} + e_{3} \\\\\n\\vdots\n\\end{aligned}\n\\end{equation}\n\\]\n\n\n15.4.4 Uniqueness\nRecall Factor analysis splits the variance of the observed X’s into a part due to the communality \\(h_{i}^{2}\\) and specificity \\(u_{i}^{2}\\). This last term is the portion of the variance that is due to the unique factor. Let’s look at how those differ depending on the extraction method:\n\npc.extract.norotate$uniquenesses\n\n        X1         X2         X3         X4         X5 \n0.11151283 0.11336123 0.40564130 0.10890203 0.08591098 \n\nml.extract.norotate$uniquenesses\n\n        X1         X2         X3         X4         X5 \n0.33432315 0.05506386 0.71685548 0.07508356 0.01414656 \n\n\nHere we see that the uniqueness for X2, X4 and X5 under ML is pretty low compared to the PC extraction method, but that’s almost offset by a much higher uniqueness for x1 and X3.\nIdeally we want the variance in the X’s to be captured by the factors. So we want to see a low unique variance.\n\n\n15.4.5 Resulting factors\n\npar(mfrow=c(1,2)) # grid of 2 columns and 1 row\n\npc.load &lt;- pc.extract.norotate$loadings[,1:2]\nplot(pc.load, type=\"n\", main=\"PCA Extraction\") # set up the plot but don't put points down\ntext(pc.load, labels=rownames(pc.load)) # put names instead of points\n\nml.load &lt;- ml.extract.norotate$loadings[,1:2]\nplot(ml.load, type=\"n\", main=\"ML Extraction\") \ntext(ml.load, labels=rownames(ml.load))\n\n\n\n\n\n\n\n\nPCA Extraction\n\nX1 and X2 load high on PC1, and low on PC1.\nX3, 4 and 5 are negative on PC2, and moderate to high on PC1.\nPC1 is not highly correlated with X3\n\nML Extraction\n\nSame overall split, X3 still not loading high on Factor 1.\nX1 loading lower on Factor 2 compared to PCA extraction method.\n\n\n\n\n\n\n\nNeither extraction method reproduced our true hypothetical factor model. Rotating the factors will achieve our desired results.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factor Analysis</span>"
    ]
  },
  {
    "objectID": "FA.html#rotating-factors",
    "href": "FA.html#rotating-factors",
    "title": "15  Factor Analysis",
    "section": "15.5 Rotating Factors",
    "text": "15.5 Rotating Factors\n\nFind new factors that are easier to interpret\nFor each \\(X\\), we want some high/large (near 1) loadings and some low/small (near zero)\nTwo common rotation methods: Varimax rotation, and oblique rotation.\n\nSame(ish) goal as PCA, find a new set of axes to represent the factors.\n\n15.5.1 Varimax Rotation\n\nRestricts the new axes to be orthogonal to each other. (Factors are independent)\nMaximizes the sum of the variances of the squared factor loadings within each factor \\(\\sum Var(l_{ij}^{2}|F_{j})\\)\nInterpretations slightly less clear\n\nVarimax rotation with principal components extraction.\n\npc.extract.varimax &lt;- principal(stan.dta, nfactors=2, rotate=\"varimax\")\nprint(pc.extract.varimax)\n\nPrincipal Components Analysis\nCall: principal(r = stan.dta, nfactors = 2, rotate = \"varimax\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n    RC1   RC2   h2    u2 com\nX1 0.06  0.94 0.89 0.112 1.0\nX2 0.11  0.93 0.89 0.113 1.0\nX3 0.76 -0.10 0.59 0.406 1.0\nX4 0.93  0.16 0.89 0.109 1.1\nX5 0.91  0.28 0.91 0.086 1.2\n\n                       RC1  RC2\nSS loadings           2.30 1.88\nProportion Var        0.46 0.38\nCumulative Var        0.46 0.83\nProportion Explained  0.55 0.45\nCumulative Proportion 0.55 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.09 \n with the empirical chi square  16.62  with prob &lt;  4.6e-05 \n\nFit based upon off diagonal values = 0.96\n\n\nVarimax rotation with maximum likelihood extraction. Here I’m using the cutoff argument to only show the values of loadings over 0.3.\n\nml.extract.varimax &lt;- factanal(stan.dta, factors=2, rotation=\"varimax\")\nprint(ml.extract.varimax, digits=2, cutoff=.3)\n\n\nCall:\nfactanal(x = stan.dta, factors = 2, rotation = \"varimax\")\n\nUniquenesses:\n  X1   X2   X3   X4   X5 \n0.33 0.06 0.72 0.08 0.01 \n\nLoadings:\n   Factor1 Factor2\nX1          0.81  \nX2          0.97  \nX3  0.53          \nX4  0.95          \nX5  0.96          \n\n               Factor1 Factor2\nSS loadings       2.13    1.67\nProportion Var    0.43    0.33\nCumulative Var    0.43    0.76\n\nTest of the hypothesis that 2 factors are sufficient.\nThe chi square statistic is 0.4 on 1 degree of freedom.\nThe p-value is 0.526 \n\n\nCommunalities are unchanged after varimax (part of variance due to common factors). This will always be the case for orthogonal (perpendicular) rotations.\n\n\n15.5.2 Oblique rotation\n\nSame idea as varimax, but drop the orthogonality requirement\nLess restrictions allow for greater flexibility\nFactors are still correlated\nBetter interpretation\nMethods:\n\nquartimax or quartimin minimizes the number of factors needed to explain each variable\ndirect oblimin standard method, but results in diminished interpretability of factors\npromax is computationally faster than direct oblimin, so good for very large datasets\n\n\n\npc.extract.quartimin &lt;- principal(stan.dta, nfactors=2, rotate=\"quartimin\")\nml.extract.promax&lt;- factanal(stan.dta, factors=2, rotation=\"promax\")\n\n\npar(mfrow=c(2,3))\nplot(pc.extract.norotate, title=\"PC + norotate\")\nplot(pc.extract.varimax, title=\"PC + Varimax\")\nplot(pc.extract.quartimin, title=\"PC + quartimin\")\n\n\nload &lt;- ml.extract.norotate$loadings[,1:2]\nplot(load, type=\"n\", main=\"ML + norotate\")\ntext(load, labels=rownames(load))\n\nload &lt;- ml.extract.varimax$loadings[,1:2]\nplot(load, type=\"n\", main=\"ML + Varimax\") \ntext(load, labels=rownames(load)) \n\nload &lt;- ml.extract.promax$loadings[,1:2]\nplot(load, type=\"n\", main= \"ML + Promax\") \ntext(load, labels=rownames(load)) \n\n\n\n\n\n\n\n\nVarimax vs oblique here doesn’t make much of a difference, and typically this is the case. You almost always use some sort of rotation. Recall, this is a hypothetical example and we set up the variables in a distinct two-factor model. So this example will look nice.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factor Analysis</span>"
    ]
  },
  {
    "objectID": "FA.html#factor-scores",
    "href": "FA.html#factor-scores",
    "title": "15  Factor Analysis",
    "section": "15.6 Factor Scores",
    "text": "15.6 Factor Scores\nWe could obtain Factor scores for an individual based on only the X’s that highly load on that factor. Essentially here, FA would identify subgroups of correlated variables.\nIn our hypothetical example where after rotation x1 and x2 loaded highly on factor 2, and x3-5 loaded highly on factor 1, we could calculate factor scores as\n\nfactor score 2 for person \\(i\\) = \\(x_{i1} + x_{i2}\\)\nfactor score 3 for person \\(i\\) = \\(x_{i3} + x_{i4} + x_{i5}\\)\n\nIn some simple applications, this approach may be sufficient.\nMore commonly, we will use a regression procedure to compute factor scores. This method accounts for the correlation between the \\(x_{i}\\)’s and uses the factor loadings \\(l_{ij}\\) to calculate the factor scores.\n\nCan be used as dependent or independent variables in other analyses\nCan be generated by adding the scores=\"regression\" option to factanal(), or scores=TRUE in principal()\nEach record in the data set with no missing data will have a corresponding factor score.\n\nprincipal() also has a missing argument that if set to TRUE it will impute missing values.\n\n\n\nfa.ml.varimax &lt;- factanal(stan.dta, factors=2, rotation=\"varimax\", scores=\"regression\")\nsummary(fa.ml.varimax$scores)\n\n    Factor1            Factor2         \n Min.   :-2.47094   Min.   :-2.335593  \n 1st Qu.:-0.70659   1st Qu.:-0.737829  \n Median : 0.08397   Median :-0.002978  \n Mean   : 0.00000   Mean   : 0.000000  \n 3rd Qu.: 0.67114   3rd Qu.: 0.792273  \n Max.   : 2.13449   Max.   : 1.670956  \n\nhead(fa.ml.varimax$scores)\n\n        Factor1     Factor2\n[1,]  0.9713019  1.29838695\n[2,] -1.1676730  0.57888326\n[3,] -0.6068270 -0.09329792\n[4,]  1.2569753  0.31231783\n[5,]  1.3817494 -0.77707241\n[6,]  0.2311359  1.11142513\n\n\n\n#library(ggforitfy)\nautoplot(fa.ml.varimax) # see vignette for more info. Link at bottom\n\n\n\n\n\n\n\n\nTo merge these scores back onto the original data set providing there is no missing data you can use the bind_cols() function in dplyr.\n\ndata.withscores &lt;- bind_cols(data, data.frame(fa.ml.varimax$scores))\nkable(head(data.withscores))\n\n\n\n\n\n\n\n\n\n\n\n\n\nX1\nX2\nX3\nX4\nX5\nFactor1\nFactor2\n\n\n\n\n0.5989843\n1.3729499\n1.0871992\n0.8597854\n1.2485892\n0.9713019\n1.2983869\n\n\n0.7429206\n0.3819301\n-0.0113714\n-1.1316383\n-1.1316216\n-1.1676730\n0.5788833\n\n\n-0.5699028\n-0.1331253\n-0.3594030\n-0.7153705\n-0.7274903\n-0.6068270\n-0.0932979\n\n\n1.6526585\n0.2216533\n0.6564431\n1.4564378\n1.1959989\n1.2569753\n0.3123178\n\n\n-0.8582815\n-0.6310620\n1.2474978\n1.2291103\n1.0684566\n1.3817494\n-0.7770724\n\n\n1.1682966\n0.9849325\n-0.8860830\n-0.0713417\n0.5105760\n0.2311359\n1.1114251",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factor Analysis</span>"
    ]
  },
  {
    "objectID": "FA.html#what-to-watch-out-for",
    "href": "FA.html#what-to-watch-out-for",
    "title": "15  Factor Analysis",
    "section": "15.7 What to watch out for",
    "text": "15.7 What to watch out for\n\nNumber of factors should be chosen with care. Check default options.\nThere should be at least two variables with non-zero weights per factor\nIf the factors are to be correlated, try oblique factor analysis\nResults usually are evaluated by reasonableness to investigator rather than by formal tests\nMotivate theory, not replace it.\nMissing data - factors will only be created using available data.",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factor Analysis</span>"
    ]
  },
  {
    "objectID": "FA.html#help",
    "href": "FA.html#help",
    "title": "15  Factor Analysis",
    "section": "15.8 Additional Resources",
    "text": "15.8 Additional Resources\n\nA gentle non-technical introduction to factor analysis\nTutorial by a Psych 253 student at Stanford\nggfortify vignette for the autoplot() function\n\nThe FactomineR package looks promising, it has some helpful graphics for determining/confirming variable groupings and aiding interpretations.\n\nSTHDA tutorial using FactomineR",
    "crumbs": [
      "Multivariate Analysis",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Factor Analysis</span>"
    ]
  },
  {
    "objectID": "MLM_intro.html",
    "href": "MLM_intro.html",
    "title": "16  Introduction",
    "section": "",
    "text": "16.1 Example School Data\nThe data used in this first example comes from a publicly available data set called the National Education Longitudinal Study of 1988 (yes it’s a bit old data, but sufficient for our purposes here). In this data set math scores are recorded for 519 students from 23 schools.\nThe School23 data set contains the following variables:\nImagine a model of math score based on school type (\\(X_{1}\\) 1 for public, 0 for private) and SES (\\(X_{2}\\)).\n\\(Y_{i} = \\beta_{0} + \\beta_{1}X_{1i} + \\beta_{2}X_{2i} + \\epsilon_{i}, \\qquad i = 1, \\ldots, n=519\\)\nThis model does not take into the account the hierarchical nature of the data in that students are nested within schools. School type is a macro level variable, SES is a micro level variable. We could consider adding indicator variables for each of the 23 schools to create a Fixed Effects model,\n\\(Y_{i} = \\beta_{0} + \\beta_{1}(SchoolType)_{1i} + \\beta_{2}(SES)_{2i} + \\beta_{3}(School2)_{i} + \\ldots + \\beta_{24}(School23)_{i} + \\epsilon_{i}\\)\nbut we already are well aware of fitting models with that many parameters, and when some school only have a few students in them. So we need a different model.",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "MLM_intro.html#example-school-data",
    "href": "MLM_intro.html#example-school-data",
    "title": "16  Introduction",
    "section": "",
    "text": "Think about it\n\n\n\nList a few characteristics that you think are associated with math performance, and at what level they are measured.\n\n\n\n\n\nSchool (macro) level variables\n\nSchool type\nclass structure\nschool size\nurbanity\ngeographic region\npercent minority\nstudent-teacher ratio\n\nStudent (micro) level variables\n\nGender\nRace\nTime spent on math homework\nSES\nparental education\nmath score",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "MLM_intro.html#multi-level-models",
    "href": "MLM_intro.html#multi-level-models",
    "title": "16  Introduction",
    "section": "16.2 Multi-level models",
    "text": "16.2 Multi-level models\nHere we specify separate models for the the fixed micro level effect of SES and the random macro level school effect.\n\\[\\begin{equation*}\n  \\begin{aligned}\n  MathScore_{ij} & = \\beta_{0j} + \\beta_{1}SES_{ij} + \\epsilon_{ij}, & \\qquad i = 1, \\ldots, n_{j}\\\\\n  \\beta_{0j} & = \\gamma_{00} + U_{0j}, & \\qquad j=1, \\ldots, 23\n  \\end{aligned}\n\\end{equation*}\\]\nwhere\n\n\\(\\gamma_{00}\\) is the average intercept across all schools\n\\(U_{0j}\\) is the difference between the intercept for school \\(j\\) and the average intercept across all schools (random effect of school)\n\nIf we substitute the intercept \\(\\beta_{0j}\\) in the first model with the information from the second model,\n\\(MathScore_{ij} = \\overbrace{\\gamma_{00} + \\beta_{1}SES_{ij}}^{^{\\mbox{fixed part}}} + \\overbrace{U_{0j} + \\epsilon_{ij}}^{\\mbox{random part}}\\)\nInstead of assuming that there is an overall average of math scores (\\(\\beta_0\\)) from which each school deviates by a fixed amount, the above model assumes that the adjusted average school math scores are normally distributed and are centered at \\(\\gamma_{00}\\).\nBecause we assume that there is a distribution of intercepts, this model is also called a Random intercept model.\nWe’ll look at this type of model more closely in the next section using a different example, and using the concept of pooling information.\n\n\n\n\n\n\nLearn more\n\n\n\nMore complex models are possible. That’s a constant theme in all of statistical modeling. Just remember that\n\nthe underlying complex effects being modeled must be strong enough that a simpler model that doesn’t account for these effects will be invalid\nyou have to have enough data to estimate any additional parameters\nyou have to be able to explain the model and results to an audience\n\nWe are not going to cover models that have random slopes, or interactions between fixed and random effects in this notebook.",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "random_intercept.html",
    "href": "random_intercept.html",
    "title": "17  Random Intercept Models",
    "section": "",
    "text": "17.1 Pooling\nTo highlight the benefits of random intercepts models we will compare three linear regression models:\nComplete Pooling\nThe complete pooling model pools all counties together to give one single estimate of the \\(log(radon)\\) level.\nNo Pooling\nNo pooling refers to the fact that no information is shared among the counties. Each county is independent of the next.\nPartial Pooling\nThe partial pooling model, partially shares information among the counties.\nEach county should get a unique intercept such that the collection of county intercepts are randomly sampled from a normal distribution with mean \\(0\\) and variance \\(\\sigma^2_{\\alpha}\\).\nBecause all county intercepts are randomly sampled from the same theoretical population, \\(N(0, \\sigma^2_{\\alpha})\\), information is shared among the counties. This sharing of information is generally referred to as shrinkage, and should be thought of as a means to reduce variation in estimates among the counties. When a county has little information to offer, it’s estimated intercept will be shrunk towards to overall mean of all counties.\nThe plot below displays the overall mean as the complete pooling estimate (solid, horizontal line), the no pooling and partial pooling estimates for 8 randomly selected counties contained in the radon data. The amount of shrinkage from the partial pooling fit is determined by a data dependent compromise between the county level sample size, the variation among the counties, and the variation within the counties.\nGenerally, we can see that counties with smaller sample sizes are shrunk more towards the overall mean, while counties with larger sample sizes are shrunk less.",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#sec-pool",
    "href": "random_intercept.html#sec-pool",
    "title": "17  Random Intercept Models",
    "section": "",
    "text": "complete pooling\nno pooling\npartial pooling (the random intercept model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe fitted values corresponding to different observations within each county of the no-pooling model are jittered to help the eye determine approximate sample size within each county.\nEstimates of variation within each county should not be determined from this arbitrary jittering of points.",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#sec-mathri",
    "href": "random_intercept.html#sec-mathri",
    "title": "17  Random Intercept Models",
    "section": "17.2 Mathematical Models",
    "text": "17.2 Mathematical Models\nThe three models considered set \\(y_n=log(radon)\\), and \\(x_n\\) records floor (0=basement, 1=first floor) for homes \\(n=1, \\ldots, N\\).\n\n17.2.1 Complete Pooling\nThe complete pooling model pools all counties together to give them one single estimate of the \\(log(radon)\\) level, \\(\\hat{\\alpha}\\).\n\nThe error term \\(\\epsilon_n\\) may represent variation due to measurement error, within-house variation, and/or within-county variation.\n\nFans of the random intercept model think that \\(\\epsilon_n\\), here, captures too many sources of error into one term, and think that this is a fault of the completely pooled model.\n\n\\[\\begin{equation*}\n\\begin{split}\n\n        y_n = \\alpha & + \\epsilon_n \\\\\n            & \\epsilon_n \\sim N(0, \\sigma_{\\epsilon}^{2})\n\n\\end{split}\n\\end{equation*}\\]\n\n\n17.2.2 No Pooling\n\nThe no pooling model gives each county an independent estimate of \\(log(radon\\)), \\(\\hat{\\alpha}_{j[n]}\\).\n\nRead the subscript \\(j[n]\\) as home \\(n\\) is nested within county \\(j\\). Hence, all homes in each county get their own independent estimate of \\(log(radon)\\).\n\nThis is equivalent to the fixed effects model\nHere again, one might argue that the error term captures too much noise.\n\n\\[\\begin{equation*}\n\\begin{split}\n\n        y_n = \\alpha_{j[n]} & + \\epsilon_n \\\\\n            \\epsilon_n & \\sim N(0, \\sigma_{\\epsilon}^{2})\n\n\\end{split}\n\\end{equation*}\\]\n\n\n17.2.3 Partial Pooling (RI)\n\nThe random intercept model, better known as the partial pooling model, gives each county an intercept term \\(\\alpha_j[n]\\) that varies according to its own error term, \\(\\sigma_{\\alpha}^2\\).\n\nThis error term measures within-county variation\n\nSeparating measurement error (\\(\\sigma_{\\epsilon}^{2}\\)) from county level error (\\(\\sigma_{\\alpha}^{2}\\)) .\n\nThis multi-level modeling shares information among the counties to the effect that the estimates \\(\\alpha_{j[n]}\\) are a compromise between the completely pooled and not pooled estimates.\n\nWhen a county has a relatively smaller sample size and/or the variance \\(\\sigma^{2}_{\\epsilon}\\) is larger than the variance \\(\\sigma^2_{\\alpha}\\), estimates are shrunk more from the not pooled estimates towards to completely pooled estimate.\n\n\\[\\begin{equation*}\n\\begin{split}\n\n        y_n = \\alpha_{j[n]} & + \\epsilon_n \\\\\n            \\epsilon_n & \\sim N(0, \\sigma_{\\epsilon}^{2}) \\\\\n            \\alpha_j[n] & \\sim N(\\mu_{\\alpha}, \\sigma_{\\alpha}^2)\n\n\\end{split}\n\\end{equation*}\\]",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#components-of-variance",
    "href": "random_intercept.html#components-of-variance",
    "title": "17  Random Intercept Models",
    "section": "17.3 Components of Variance",
    "text": "17.3 Components of Variance\nStatistics can be thought of as the study of uncertainty, and variance is a measure of uncertainty (and information). So yet again we see that we’re partitioning the variance. Recall that\n\nMeasurement error: \\(\\sigma^{2}_{\\epsilon}\\)\nCounty level error: \\(\\sigma^{2}_{\\alpha}\\)\n\nThe intraclass correlation (ICC, \\(\\rho\\)) is interpreted as\n\nthe proportion of total variance that is explained by the clusters.\n\nthe expected correlation between two individuals who are drawn from the same cluster.\n\n\\[\n\\rho = \\frac{\\sigma^{2}_{\\alpha}}{\\sigma^{2}_{\\alpha} + \\sigma^{2}_{\\epsilon}}\n\\]\n\nWhen \\(\\rho\\) is large, a lot of the variance is at the macro level\n\nunits within each group are very similar\n\nIf \\(\\rho\\) is small enough, one may ask if fitting a multi-level model is worth the complexity.\nNo hard and fast rule to say “is it large enough?”\n\nrules of thumb include\n\nunder 10% (0.1) then a single level analysis may still be appropriate,\nover 10% (0.1) then a multilevel model can be justified.",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#fitri",
    "href": "random_intercept.html#fitri",
    "title": "17  Random Intercept Models",
    "section": "17.4 Fitting models in R",
    "text": "17.4 Fitting models in R\nComplete Pooling\nThe complete pooling model is fit with the function lm, and is only modeled by 1 and no covariates. This is the simple mean model, and is equivelant to estimating the mean.\n\nfit_completepool &lt;- lm(log_radon ~ 1, data=radon)\nfit_completepool\n\n\nCall:\nlm(formula = log_radon ~ 1, data = radon)\n\nCoefficients:\n(Intercept)  \n      1.265  \n\nmean(radon$log_radon)\n\n[1] 1.264779\n\n\nNo Pooling\nThe no pooling model is also fit with the function lm, but gives each county a unique intercept in the model.\nfit_nopool &lt;- lm(log_radon ~ -1 + county, data=radon)\nfit_nopool.withint &lt;- lm(log_radon ~ county, data=radon)\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nlog_radon\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n0.715* (0.383)\n\n\n\n\ncountyAITKIN\n\n\n0.715* (0.383)\n\n\n\n\n\n\ncountyANOKA\n\n\n0.891*** (0.106)\n\n\n0.176 (0.398)\n\n\n\n\ncountyBECKER\n\n\n1.090** (0.443)\n\n\n0.375 (0.585)\n\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\nThe first model (fit_nopool) is coded as lm(log_radon ~ -1 + county, data=radon), and so does not have the global intercept (that’s what the -1 does). Each \\(\\beta\\) coefficient is the estimate of the mean log_radon for that county.\nThe second model (fit_nopool.withint) is coded as lm(log_radon ~ county, data=radon) and is what we are typically used to fitting.\n\nEach estimate is the difference in log(radon) for that county compared to a reference county.\nBecause county is alphabetical, the reference group is AITKIN.\nAitkin’s mean level of log(radon) shows up as the intercept or Constant term.\n\nFor display purposes only, only the first 3 county estimates are being shown.\n\nPartial Pooling\n\nThe partial pooling model is fit with the function lmer(), which is part of the lme4 package.\nThe extra notation around the input variable (1|county) dictates that each county should get its own unique intercept \\(\\alpha_{j[n]}\\).\n\n\nfit_partpool &lt;- lmer(log_radon ~ (1 |county), data=radon)\n\nThe fixed effects portion of the model output of lmer is similar to output from lm, except no p-values are displayed. The fact that no p-values are displayed is a much discussed topic. The author of the library lme4, Douglas Bates, believes that there is no “obviously correct” solution to calculating p-values for models with randomly varying intercepts (or slopes); see here for a general discussion.\n\nsummary(fit_partpool)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: log_radon ~ (1 | county)\n   Data: radon\n\nREML criterion at convergence: 2184.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.6880 -0.5884  0.0323  0.6444  3.4186 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n county   (Intercept) 0.08861  0.2977  \n Residual             0.58686  0.7661  \nNumber of obs: 919, groups:  county, 85\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)    1.350      0.047   28.72\n\n\n\nThe random effects portion of the lmer output provides a point estimate of the variance of component \\(\\sigma^2_{\\alpha} = 0.09\\) and the model’s residual variance, \\(\\sigma_\\epsilon = 0.57\\).\nThe fixed effect here is interpreted in the same way that we would in a normal fixed effects mean model, as the global predicted value of the outcome of log_radon.\nThe random intercepts aren’t automatically shown in this output. We can visualize these using a forestplot. We use the plot_model() function from the sjPlot package, on the fit_partpool model, we want to see the random effects (type=\"re\"), and we want to sort on the name of the random variable, here it’s \"(Intercept)\".\n\n\nsjPlot::plot_model(fit_partpool, type=\"re\", sort.est = \"(Intercept)\", y.offset = .4)\n\n\n\n\n\n\n\n\nNotice that these effects are centered around 0. Refering back @ref(mathri), the intercept \\(\\beta_{0j}\\) was modeled equal to some average intercept across all groups \\(\\gamma_{00}\\), plus some difference. What is plotted above is listed in a table below, showing that if you add that random effect to the fixed effect of the intercept, you get the value of the random intercept for each county.\n\nshowri &lt;- data.frame(Random_Effect   = unlist(ranef(fit_partpool)), \n                     Fixed_Intercept = fixef(fit_partpool), \n                     RandomIntercept = unlist(ranef(fit_partpool))+fixef(fit_partpool))\n                \nrownames(showri) &lt;- rownames(coef(fit_partpool)$county)\nkable(head(showri))\n\n\n\n\n\nRandom_Effect\nFixed_Intercept\nRandomIntercept\n\n\n\n\nAITKIN\n-0.2390574\n1.34983\n1.1107728\n\n\nANOKA\n-0.4071256\n1.34983\n0.9427047\n\n\nBECKER\n-0.0809977\n1.34983\n1.2688325\n\n\nBELTRAMI\n-0.0804277\n1.34983\n1.2694025\n\n\nBENTON\n-0.0254506\n1.34983\n1.3243796\n\n\nBIGSTONE\n0.0582831\n1.34983\n1.4081133\n\n\n\n\n\n\n17.4.1 Comparison of estimates\n\nBy allowing individuals within counties to be correlated, and at the same time let counties be correlated, we allow for some information to be shared across counties.\nThus we come back to that idea of shrinkage. Below is a numeric table version of the plot in Section 17.1.\n\n\ncmpr.est &lt;- data.frame(Mean_Model       = coef(fit_completepool), \n                       Random_Intercept = unlist(ranef(fit_partpool))+fixef(fit_partpool), \n                       Fixed_Effects    = coef(fit_nopool))\nrownames(cmpr.est) &lt;- rownames(coef(fit_partpool)$county)\nkable(head(cmpr.est))\n\n\n\n\n\nMean_Model\nRandom_Intercept\nFixed_Effects\n\n\n\n\nAITKIN\n1.264779\n1.1107728\n0.7149352\n\n\nANOKA\n1.264779\n0.9427047\n0.8908486\n\n\nBECKER\n1.264779\n1.2688325\n1.0900084\n\n\nBELTRAMI\n1.264779\n1.2694025\n1.1933029\n\n\nBENTON\n1.264779\n1.3243796\n1.2822379\n\n\nBIGSTONE\n1.264779\n1.4081133\n1.5367889",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#estimation-methods",
    "href": "random_intercept.html#estimation-methods",
    "title": "17  Random Intercept Models",
    "section": "17.5 Estimation Methods",
    "text": "17.5 Estimation Methods\n\nSimilar to logistic regression, estimates from multi-level models typically aren’t estimated directly using maximum likelihood (ML) methods.\nIterative methods like Restricted (residual) Maximum Likelihood (REML) are used to get approximations.\nREML is typically the default estimation method for most packages.\n\nDetails of REML are beyond the scope of this class, but knowing the estimation method is important for two reasons\n\nSome type of testing procedures that use the likelihood ratio may not be valid.\n\nComparing models with different fixed effects using a likelihood ratio test is not valid. (Must use Wald Test instead)\nCan still use AIC/BIC as guidance (not as formal tests)\n\nIterative procedures are procedures that perform estimation steps over and over until the change in estimates from one step to the next is smaller than some tolerance.\n\nSometimes this convergence to an answer never happens.\nYou will get some error message about the algorithm not converging.\nThe more complex the model, the higher chance this can happen\nscaling, centering, and avoiding collinearity can alleviate these problems with convergence.\n\n\nYou can change the fitting algorithm to use the Log Likelihood anyhow, it may be slightly slower but for simple models the estimates are going to be very close to the REML estimate. Below is a table showing the estimates for the random intercepts,\n\n\n\n\n\n\nREML\nMLE\n\n\n\n\nAITKIN\n1.1107728\n1.1143654\n\n\nANOKA\n0.9427047\n0.9438526\n\n\nBECKER\n1.2688325\n1.2700351\n\n\nBELTRAMI\n1.2694025\n1.2702493\n\n\nBENTON\n1.3243796\n1.3245917\n\n\nBIGSTONE\n1.4081133\n1.4068866\n\n\n\n\n\n\n\nand the same estimates for the variance terms.\n\nVarCorr(fit_partpool)\n\n Groups   Name        Std.Dev.\n county   (Intercept) 0.29767 \n Residual             0.76607 \n\nVarCorr(fit_partpool_MLE)\n\n Groups   Name        Std.Dev.\n county   (Intercept) 0.29390 \n Residual             0.76607 \n\n\nSo does it matter? Yes and no. In general you want to fit the models using REML, but if you really want to use a Likelihood Ratio test to compare models then you need to fit the models using ML.",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#including-covariates",
    "href": "random_intercept.html#including-covariates",
    "title": "17  Random Intercept Models",
    "section": "17.6 Including Covariates",
    "text": "17.6 Including Covariates\nA similar sort of shrinkage effect is seen with covariates included in the model.\nConsider the covariate \\(floor\\), which takes on the value \\(1\\) when the radon measurement was read within the first floor of the house and \\(0\\) when the measurement was taken in the basement. In this case, county means are shrunk towards the mean of the response, \\(log(radon)\\), within each level of the covariate.\n\n\n\n\n\n\n\n\n\nCovariates are fit using standard + notation outside the random effects specification, i.e. (1|county).\n\nri.with.x &lt;- lmer(log_radon ~ floor + (1 |county), data=radon)\ntab_model(ri.with.x, show.r2=FALSE)\n\n\n\n \nlog radon\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n1.49\n1.40 – 1.59\n&lt;0.001\n\n\nfloor [first floor]\n-0.66\n-0.80 – -0.53\n&lt;0.001\n\n\nRandom Effects\n\n\n\nσ2\n0.53\n\n\n\nτ00 county\n0.10\n\n\nICC\n0.16\n\n\nN county\n85\n\nObservations\n919\n\n\n\n\n\n\nNote that in this table format, \\(\\tau_{00} = \\sigma^{2}_{\\alpha}\\) and \\(\\sigma^{2} = \\sigma^{2}_{\\epsilon}\\). The estimated random effects can also be easily visualized using functions from the sjPlot package.\n\nplot_model(ri.with.x, type=\"re\", sort.est = \"(Intercept)\", y.offset = .4)\n\n\n\n\n\n\n\n\nFunction enhancements –\n\nDisplay the fixed effects by changing type=\"est\".\nPlot the slope of the fixed effect for each level of the random effect sjp.lmer(ri.with.x, type=\"ri.slope\") – this is being depreciated in the future but works for now. Eventually I’ll figure out how to get this plot out of plot_model().",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#more-random-effects",
    "href": "random_intercept.html#more-random-effects",
    "title": "17  Random Intercept Models",
    "section": "17.7 More Random Effects",
    "text": "17.7 More Random Effects\n\n\n\n\n\n\nThis section has not been built yet. Reference this set of notes in the meantime.\n\n\n\nWhat if you think the slope along some \\(x\\) should vary (such as over time)?",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#centering-terms",
    "href": "random_intercept.html#centering-terms",
    "title": "17  Random Intercept Models",
    "section": "17.8 Centering terms",
    "text": "17.8 Centering terms\n\nSometimes it might be better to measure the effect of a specific level relative to the average within cluster, rather than overall average.\nThe “frog pond” effect\n\nA student with an average IQ may be more confident and excel in a group of students with less than average IQ\nBut they may be discouraged and not perform to their potential in a group of students with higher than average IQ.\n\nIf the effect of a specific level of a factor is dependent on where the level is in reference to other cluster members, more so than where the level is in reference to all other participants, the model should be adjusted for as follows:\nInstead of using the actual value in the regression model you would…\n\ncalculate the cluster specific average\ncalculate the difference between individual and specific cluster average\nboth cluster average (macro) and difference (micro) are included in the model.\n\n\n\n17.8.1 A generic dplyr approach to centering.\ngroup.means &lt;- data %&gt;% group_by(cluster) %&gt;% summarise(c.ave=mean(variable))\nnewdata &lt;- data %&gt;% left_join(group.means) %&gt;% mutate(diff = variable - c.ave)\n\nCreate a new data set that I call group.means that\n\ntakes the original data set and then (%&gt;%)…\ngroups it by the clustering variable so that all subsequent actions are done on each group\nmakes a new variable that I call c.ave that is the average of the variable of interest\n\nI then take the original data set, and then\n\nmerge onto data, this group.means data set that only contains the clustering variable, and the cluster average variable c.ave.\nI also toss in a mutate to create a new variable that is the difference between the variable of interest and the group averages.\nand assign all of this to a newdata set",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#specifying-correlation-structures",
    "href": "random_intercept.html#specifying-correlation-structures",
    "title": "17  Random Intercept Models",
    "section": "17.9 Specifying Correlation Structures",
    "text": "17.9 Specifying Correlation Structures\n\nIndependence: In standard linear models, the assumption on the residuals \\(\\epsilon_{i} \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2})\\) means that\nThe variance of each observation is \\(\\sigma_{\\epsilon}^{2}\\)\nThe covariance between two different observations \\(0\\)\n\nConsider \\(n=4\\) observations, \\(y_{1}, \\ldots , y_{4}\\). Visually the covariance matrix between these four observations would look like this:\n\\[\n\\begin{array}{c|cccc}\n  & y_{1} & y_{2} & y_{3} & y_{4}\\\\\n  \\hline\n  y_{1} & \\sigma_{\\epsilon}^{2} & 0 & 0 & 0\\\\\n  y_{2} & 0 & \\sigma_{\\epsilon}^{2} & 0 & 0\\\\\n  y_{3} & 0 & 0 & \\sigma_{\\epsilon}^{2} & 0\\\\\n  y_{4} & 0& 0 & 0 & \\sigma_{\\epsilon}^{2}\n\\end{array}\n\\]\nWe can also write the covariance matrix as \\(\\sigma_{\\epsilon}^{2}\\) times the correlation matrix.\n\\[\n\\begin{bmatrix}\n  \\sigma_{\\epsilon}^{2} & 0 & 0 & 0\\\\\n  0 & \\sigma_{\\epsilon}^{2} & 0 & 0\\\\\n  0 & 0 & \\sigma_{\\epsilon}^{2} & 0\\\\\n  0& 0 & 0 & \\sigma_{\\epsilon}^{2}\n\\end{bmatrix}\n=\n\\sigma_{\\epsilon}^2\n\\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n& 1 & 0 & 0 \\\\\n& & 1 & 0 \\\\\n& & & 1\n\\end{bmatrix}\n\\]\n\nCompound Symmetry or Exchangeable: The simplest covariance structure that includes correlated errors is compound symmetry (CS). Here we see correlated errors between individuals, and note that these correlations are presumed to be the same for each pair of responses, namely \\(\\rho\\).\n\n\\[\n\\sigma_{\\epsilon}^{2}\n\\begin{bmatrix}\n1 & \\rho & \\rho & \\rho \\\\\n& 1 & \\rho & \\rho \\\\\n& & 1 & \\rho \\\\\n& & & 1\n\\end{bmatrix}\n\\]\n\nAutoregressive: Imagine that \\(y_{1}, \\ldots , y_{4}\\) were 4 different time points on the same person. The autoregressive (Lag 1) structure considers correlations to be highest for time adjacent times, and a systematically decreasing correlation with increasing distance between time points. This structure is only applicable for evenly spaced time intervals for the repeated measure.\n\n\\[\n\\sigma_{\\epsilon}^{2}\n\\begin{bmatrix}\n1 & \\rho & \\rho^{2} & \\rho^{3} \\\\\n& 1 & \\rho & \\rho^{2} \\\\\n& & 1 & \\rho \\\\\n& & & 1\n\\end{bmatrix}\n\\]\n\nUnstructured: The Unstructured covariance structure (UN) is the most complex because it is estimating unique correlations for each pair of observations. It is not uncommon to find out that you are not able to use this structure simply because there are too many parameters to estimate.\n\n\\[\n\\begin{bmatrix}\n\\sigma_{1}^{2} & \\rho_{12} & \\rho_{13} & \\rho_{14} \\\\\n& \\sigma_{2}^{2} & \\rho_{23} & \\rho_{24} \\\\\n& & \\sigma_{3}^{2} & \\rho_{34} \\\\\n& & & \\sigma_{4}^{2}\n\\end{bmatrix}\n\\]\n\nRandom Intercept Model\n\nLet \\(y_{1}\\) and \\(y_{2}\\) be from group 1, and \\(y_{3}\\) and \\(y_{4}\\) be from group 2.\n\nerror terms between groups are uncorrelated (groups are independent)\ntwo different observations from the same group have covariance \\(\\sigma_{\\alpha}^{2}\\)\nindividuals now have the error associated with their own observation but also due to the group \\(\\sigma_{\\epsilon}^{2} + \\sigma_{\\alpha}^{2}\\)\n\n\\[\n\\left[\n\\begin{array}{cc|cc}\n  \\sigma_{\\epsilon}^{2} + \\sigma_{\\alpha}^{2} & \\sigma_{\\alpha}^{2} & 0 & 0\\\\\n\\sigma_{\\alpha}^{2} & \\sigma_{\\epsilon}^{2} + \\sigma_{\\alpha}^{2} & 0 & 0\\\\\n\\hline\n  0 & 0 & \\sigma_{\\epsilon}^{2} + \\sigma_{\\alpha}^{2} & \\sigma_{\\alpha}^{2}\\\\\n  0 & 0 & \\sigma_{\\alpha}^{2} & \\sigma_{\\epsilon}^{2} + \\sigma_{\\alpha}^{2}\n\\end{array}\n\\right]\n\\]\n\n17.9.1 Changing covariance structures in R\n\n\n\n\n\n\nCaution\n\n\n\nThis is very hard to do as the model becomes more complex. These types of models is where Bayesian statistics has a much easier time fitting models.\n\n\n\n\n\n\n\n\nSection In Progress\n\n\n\nThis section has been commented out of the notes until figured out in a cleaner manner.",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "random_intercept.html#additional-references",
    "href": "random_intercept.html#additional-references",
    "title": "17  Random Intercept Models",
    "section": "17.10 Additional References",
    "text": "17.10 Additional References\n\nRandom effects ANOVA in SAS and R - STLA\nICCs in mixed models - The Analysis Factor\nVery nice introduction to mixed models in R Michael Clark\nInteresting blog by Tristan Mahr about pooling and shrinkage.\nDerivation of the covariance structures - Video\nMixed models with R - Michael Clark\n\n\n17.10.1 Lecture notes from other classes found on the interwebs\n\nBIOL 202: Ecological Statistics from Stanford This is a graduate level class.",
    "crumbs": [
      "Multi-level Modeling",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Random Intercept Models</span>"
    ]
  },
  {
    "objectID": "missing_data.html",
    "href": "missing_data.html",
    "title": "18  Missing Data",
    "section": "",
    "text": "18.1 Identifying missing data\nsurvey &lt;- MASS::survey # to avoid loading the MASS library which will conflict with dplyr\nhead(survey$Pulse)\n\n[1]  92 104  87  NA  35  64\n\nmean(survey$Pulse)\n\n[1] NA\nThe summary() function will always show missing.\nsummary(survey$Pulse)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  35.00   66.00   72.50   74.15   80.00  104.00      45\nThe is.na() function is helpful to identify rows with missing data\ntable(is.na(survey$Pulse))\n\n\nFALSE  TRUE \n  192    45\nThe function table() will not show NA by default.\ntable(survey$M.I)\n\n\nImperial   Metric \n      68      141 \n\ntable(survey$M.I, useNA=\"always\")\n\n\nImperial   Metric     &lt;NA&gt; \n      68      141       28\nround(prop.table(table(is.na(survey)))*100,1)\n\n\nFALSE  TRUE \n 96.2   3.8\n4% of the data points are missing.\nprop.miss &lt;- apply(survey, 2, function(x) round(sum(is.na(x))/NROW(x),4))\nprop.miss\n\n   Sex Wr.Hnd NW.Hnd  W.Hnd   Fold  Pulse   Clap   Exer  Smoke Height    M.I \n0.0042 0.0042 0.0042 0.0042 0.0000 0.1899 0.0042 0.0000 0.0042 0.1181 0.1181 \n   Age \n0.0000\nThe amount of missing data per variable varies from 0 to 19%.",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#identifying-missing-data",
    "href": "missing_data.html#identifying-missing-data",
    "title": "18  Missing Data",
    "section": "",
    "text": "Missing data in R is denoted as NA\nArithmetic functions on missing data will return missing\n\n\n\n\n\n\n\n\n\nWhat percent of the data set is missing?\n\n\n\n\nHow much missing is there per variable?\n\n\n\n\n18.1.1 Visualize missing patterns\n\nggplot2miceVIM\n\n\n\npmpv &lt;- data.frame(variable = names(survey), pct.miss =prop.miss)\n\nggplot(pmpv, aes(x=variable, y=pct.miss)) +\n  geom_bar(stat=\"identity\") + ylab(\"Percent\") + scale_y_continuous(labels=scales::percent, limits=c(0,1)) + \n  geom_text(data=pmpv, aes(label=paste0(round(pct.miss*100,1),\"%\"), y=pct.miss+.025), size=4)\n\n\n\n\n\n\n\n\n\n\n\nlibrary(mice)\nmd.pattern(survey)\n\n\n\n\n\n\n\n\n    Fold Exer Age Sex Wr.Hnd NW.Hnd W.Hnd Clap Smoke Height M.I Pulse    \n168    1    1   1   1      1      1     1    1     1      1   1     1   0\n38     1    1   1   1      1      1     1    1     1      1   1     0   1\n20     1    1   1   1      1      1     1    1     1      0   0     1   2\n7      1    1   1   1      1      1     1    1     1      0   0     0   3\n1      1    1   1   1      1      1     1    1     0      0   0     1   3\n1      1    1   1   1      1      1     0    1     1      1   1     1   1\n1      1    1   1   1      0      0     1    0     1      1   1     1   3\n1      1    1   1   0      1      1     1    1     1      1   1     1   1\n       0    0   0   1      1      1     1    1     1     28  28    45 107\n\n\nThis somewhat ugly output tells us that 168 records have no missing data, 38 records are missing only Pulse and 20 are missing both Height and M.I.\n\n\n\nlibrary(VIM)\naggr(survey, col=c('chartreuse3','mediumvioletred'),\n              numbers=TRUE, sortVars=TRUE,\n              labels=names(survey), cex.axis=.7,\n              gap=3, ylab=c(\"Missing data\",\"Pattern\"))\n\n\n\n\n\n\n\n\nThe plot on the left is a simplified, and ordered version of the ggplot from above, except the bars appear to be inflated because the y-axis goes up to 15% instead of 100%.\nThe plot on the right shows the missing data patterns, and indicate that 71% of the records has complete cases, and that everyone who is missing M.I. is also missing Height.\nAnother plot that can be helpful to identify patterns of missing data is a marginplot (also from VIM).\n\nTwo continuous variables are plotted against each other.\n\nBlue bivariate scatterplot and univariate boxplots are for the observations where values on both variables are observed.\nRed univariate dotplots and boxplots are drawn for the data that is only observed on one of the two variables in question.\n\nThe darkred text indicates how many records are missing on both.\n\n\nmarginplot(survey[,c(6,10)])\n\n\n\n\n\n\n\n\nThis shows us that the observations missing pulse have the same median height, but those missing height have a higher median pulse rate.\n\n\n\n\n\n18.1.2 Example: Parental HIV\nIdentify missing\nEntire data set:\n\ntable(is.na(hiv)) |&gt; prop.table()\n\n\n     FALSE       TRUE \n0.96330127 0.03669873 \n\n\nOnly 3.7% of all values in the data set are missing.\nExamine missing data patterns of scale variables.\nThe parental bonding and BSI scale variables are aggregated variables, meaning they are sums or means of a handful of component variables. That means if any one component variable is missing, the entire scale is missing. E.g. if y = x1+x2+x3, then y is missing if any of x1, x2 or x3 are missing. \n\nscale.vars &lt;- hiv %&gt;% select(parent_care:bsi_psycho, gender, siblings, age)\naggr(scale.vars, sortVars=TRUE, combined=TRUE, numbers=TRUE, cex.axis=.7)\n\n\n\n\n\n\n\n\n\n Variables sorted by number of missings: \n              Variable Count\n           bsi_overall    93\n           bsi_depress    93\n parent_overprotection    44\n            bsi_psycho     2\n           parent_care     1\n             bsi_somat     1\n            bsi_obcomp     1\n            bsi_interp     1\n           bsi_anxiety     1\n              siblings     1\n            bsi_hostil     0\n            bsi_phobic     0\n          bsi_paranoid     0\n                gender     0\n                   age     0\n\n\n34.7% of records are missing both bsi_overall and bsi_depress. This makes sense since bsi_depress is a subscale containing 9 component variables and the bsi_overall is an average of all 52.\nAnother 15.5% of records are missing parental_overprotection.\nIs there a bivariate pattern between missing and observed values of bsi_depress and parent_overprotection?\n\nmarginplot(hiv[,c('bsi_depress', 'parent_overprotection')])\n\n\n\n\n\n\n\n\nWhen someone is missing parent_overprotection, they have a lower bsi_depress score. Those missing bsi_depress have a slightly lower parental_overprotection score. Only 4 individuals are missing both values.",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#effects-of-nonresponse",
    "href": "missing_data.html#effects-of-nonresponse",
    "title": "18  Missing Data",
    "section": "18.2 Effects of Nonresponse",
    "text": "18.2 Effects of Nonresponse\n\n\n\n\n\n\nTextbook example\n\n\n\nExample reported in W.G. Cochran, Sampling Techniques, 3rd edition, 1977, ch. 13:\nConsider data that come form an experimental sampling of fruit orcharts in North Carolina in 1946. Three successive mailings of the same questionnaire were sent to growers. For one of the questions the number of fruit trees, complete data were available for the population…\n\n\n\n\n\n\n\n\n\n\n\nAve. # trees\n# of growers\n% of pop’n\nAve # trees/grower\n\n\n\n\n1st mailing responders\n300\n10\n456\n\n\n2nd mailing responders\n543\n17\n382\n\n\n3rd mailing responders\n434\n14\n340\n\n\nNonresponders\n1839\n59\n290\n\n\n\n——–\n——–\n——–\n\n\nTotal population\n3116\n100\n329\n\n\n\n\nThe overall response rate was very low.\nThe rate of non response is clearly related to the average number of trees per grower.\nThe estimate of the average trees per grower can be calculated as a weighted average from responders \\(\\bar{Y_{1}}\\) and non responders \\(\\bar{Y_{2}}\\).\n\nBias: The difference between the observed estimate \\(\\bar{y}_{1}\\) and the true parameter \\(\\mu\\).\n\\[\n  \\begin{aligned}\n  E(\\bar{y}_{1}) - \\mu & = \\bar{Y_{1}} - \\bar{Y} \\\\\n  & = \\bar{Y}_{1} - \\left[(1-w)\\bar{Y}_{1} - w\\bar{Y}_{2}\\right] \\\\\n  & = w(\\bar{Y}_{1} - \\bar{Y}_{2})\n  \\end{aligned}\n\\]\nWhere \\(w\\) is the proportion of non-response.\n\nThe amount of bias is the product of the proportion of non-response and the difference in the means between the responders and the non-responders.\nThe sample provides no information about \\(\\bar{Y_{2}}\\), the size of the bias is generally unknown without information gained from external data.",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#missing-data-mechanisms",
    "href": "missing_data.html#missing-data-mechanisms",
    "title": "18  Missing Data",
    "section": "18.3 Missing Data Mechanisms",
    "text": "18.3 Missing Data Mechanisms\nProcess by which some units observed, some units not observed\n\nMissing Completely at Random (MCAR): The probability that a data point is missing is completely unrelated (independent) of any observed and unobserved data or parameters.\n\nP(Y missing| X, Y) = P(Y missing)\nEx: Miscoding or forgetting to log in answer\n\nMissing at Random (MAR): The probability that a data point is missing is independent can be explained or modeled by other observed variables.\n\nP(Y missing|x, Y) = P(Y missing | X)\nEx: Y = age, X = sex\n- Pr (Y miss| X = male) = 0.2\n- Pr (Y miss| X = female) = 0.3\n- Males people are less likely to fill out an income survey\n- The missing data on income is related to gender\n- After accounting for gender the missing data is unrelated to income.\n\n\nNot missing at Random (NMAR): The probability that a data point is missing depends on the value of the variable in question.\n\nP(Y missing | X, Y) = P (Y missing|X, Y)\n\nEx: Y = income, X = immigration status\n\nRicher person may be less willing to disclose income\n\nUndocumented immigrant may be less willing to disclose income\n\n\n\n\n\n\n\n\n\nThink about it\n\n\n\nWrite down an example of each.\n\n\nDoes it matter to inferences? Yes!\n\n18.3.1 Demonstration via Simulation\nWhat follows is just one method of approaching this problem via code. Simulation is a frequently used technique to understand the behavior of a process over time or over repeated samples.\n\nMCARNMAR: Missing related to dataNMAR: Pure Censoring\n\n\n\nDraw a random sample of size 100 from a standard Normal distribution (Z) and calculate the mean.\n\n\nset.seed(456) # setting a seed ensures the same numbers will be drawn each time\nz &lt;- rnorm(100)\nmean.z &lt;- mean(z)\nmean.z\n\n[1] 0.1205748\n\n\n\nDelete data at a rate of \\(p\\) and calculate the complete case (available) mean.\n\nSample 100 random Bernoulli (0/1) variables with probability \\(p\\).\n\nx &lt;- rbinom(100, 1, p=.5)\n\nFind out which elements are are 1’s\n\ndelete.these &lt;- which(x==1)\n\nSet those elements in z to NA.\n\nz[delete.these] &lt;- NA\n\nCalculate the complete case mean\n\nmean(z, na.rm=TRUE)\n\n[1] 0.1377305\n\n\n\nCalculate the bias as the sample mean minus the true mean (\\(E(\\hat\\theta) - \\theta\\)).\n\n\nmean(z, na.rm=TRUE) - mean.z\n\n[1] 0.01715565\n\n\nHow does the bias change as a function of the proportion of missing? Let \\(p\\) range from 0% to 99% and plot the bias as a function of \\(p\\).\n\ncalc.bias &lt;- function(p){ # create a function to handle the repeated calculations\n  mean(ifelse(rbinom(100, 1, p)==1, NA, z), na.rm=TRUE) - mean.z\n}\n\np &lt;- seq(0,.99,by=.01)\n\nplot(c(0,1), c(-1, 1), type=\"n\", ylab=\"Bias\", xlab=\"Proportion of missing\")\n  points(p, sapply(p, calc.bias), pch=16)\n  abline(h=0, lty=2, col=\"blue\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThink about it\n\n\n\nWhat is the behavior of the bias as \\(p\\) increases? Look specifically at the position/location of the bias, and the variance/variability of the bias.\n\n\n\n\nWhat if the rate of missing is related to the value of the outcome? Again, let’s setup a simulation to see how this works.\n\nRandomly draw 100 random data points from a Standard Normal distribution to serve as our population, and 100 uniform random values between 0 and 1 to serve as probabilities of the data being missing (\\(p=P(miss)\\))\n\n\nZ &lt;- rnorm(100)\np &lt;- runif(100, 0, 1)\n\n\nSort both in ascending order, shove into a data frame and confirm that \\(p(miss)\\) increases along with \\(z\\).\n\n\ndta &lt;- data.frame(Z=sort(Z), p=sort(p))\nhead(dta)\n\n          Z           p\n1 -2.898122 0.003673455\n2 -2.185058 0.013886146\n3 -2.076032 0.035447986\n4 -1.938288 0.039780643\n5 -1.930809 0.051362816\n6 -1.905331 0.054639596\n\nggplot(dta, aes(x=p, y=Z)) + geom_point() + xlab(\"P(missing)\") + ylab(\"Z~Normal(0,1)\")\n\n\n\n\n\n\n\n\n\nSet \\(Z\\) missing with probability equal to the \\(p\\) for that row. Create a new vector dta$z.miss that is either 0, or the value of dta$Z with probability 1-dta$p. Then change all the 0’s to NA.\n\n\ndta$Z.miss &lt;- dta$Z * (1-rbinom(NROW(dta), 1, dta$p))\nhead(dta) # see structure of data to understand what is going on\n\n          Z           p    Z.miss\n1 -2.898122 0.003673455 -2.898122\n2 -2.185058 0.013886146 -2.185058\n3 -2.076032 0.035447986 -2.076032\n4 -1.938288 0.039780643 -1.938288\n5 -1.930809 0.051362816 -1.930809\n6 -1.905331 0.054639596 -1.905331\n\ndta$Z.miss[dta$Z.miss==0] &lt;- NA\n\n\nCalculate the complete case mean and the bias\n\n\nmean(dta$Z.miss, na.rm=TRUE)\n\n[1] -0.7777319\n\nmean(dta$Z) - mean(dta$Z.miss, na.rm=TRUE)\n\n[1] 0.6830372\n\n\n\n\n\n\n\n\nThink about it\n\n\n\nDid the complete case estimate over- or under-estimate the true mean? Is the bias positive or negative?\n\n\n\n\nConsider a hypothetical blood test to measure a hormone that is normally distributed in the blood with mean 10\\(\\mu g\\) and variance 1. However the test to detect the compound only can detect levels above 10.\n\nz &lt;- rnorm(100, 10, 1)\ny &lt;- z\ny[y&lt;10] &lt;- NA\nmean(z) - mean(y, na.rm=TRUE)\n\n[1] -0.6850601\n\n\n\n\n\n\n\n\nThink about it\n\n\n\nDid the complete case estimate over- or under-estimate the true mean?\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n\nWhen the data is not missing at random, the bias can be much greater.\nUsually, you don’t know the missing data mechanism.\n\n\n\nDegrees of difficulty\n\nMCAR: is easiest to deal with.\nMAR: we can live with it.\nNMAR: most difficult to handle.\n\nEvidence?\nWhat can we learn from evidence in the data set at hand?\n\nMay be evidence in the data rule out MCAR - test responders vs. nonresponders.\n\nExample: Responders tend to have higher/lower average education than nonresponders by t-test\nExample: Response more likely in one geographic area than another by chi-square test\n\nNo evidence in data set to rule out MAR (although there may be evidence from an external data source)\n\nWhat is plausible?\n\nCochran example: when human behavior is involved, MCAR must be viewed as an extremely special case that would often be violated in practice\nMissing data may be introduced by design (e.g., measure some variables, don’t measure others for reasons of cost, response burden), in which case MCAR would apply\nMAR is much more common than MCAR\nWe cannot be too cavalier about assuming MAR, but anecdotal evidence shows that it often is plausible when conditioning on enough information\n\nIgnorable Missing\n\nIf missing-data mechanism is MCAR or MAR then nonresponse is said to be “ignorable”.\nOrigin of name: in likelihood-based inference, both the data model and missing-data mechanism are important but with MCAR or MAR, inference can be based solely on the data model, thus making inference much simpler\n\n“Ignorability” is a relative assumption: missingness on income may be NMAR given only gender, but may be MAR given gender, age, occupation, region of the country",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#general-strategies",
    "href": "missing_data.html#general-strategies",
    "title": "18  Missing Data",
    "section": "18.4 General strategies",
    "text": "18.4 General strategies\nStrategies for handling missing data include:\n\nComplete-case/available-case analysis: drop cases that make analysis inconvenient.\nIf variables are known to contribute to the missing values, then appropriate modeling can often account for the missingness.\nImputation procedures: fill in missing values, then analyze completed data sets using complete-date methods\nWeighting procedures: modify “design weights” (i.e., inverse probabilities of selection from sampling plan) to account for probability of response\n\nModel-based approaches: develop model for partially missing data, base inferences on likelihood under that model\n\n\n18.4.1 Complete cases analysis\nIf not all variables observed, delete case from analysis\n\nAdvantages:\n\nSimplicity\nCommon sample for all estimates\n\nDisadvantages:\n\nLoss of valid information\nBias due to violation of MCAR\n\n\n\n\n18.4.2 Available-case analysis\n\nUse all cases where the variable of interest is present\n\nPotentially different sets of cases for means of X and Y\nand complete pairs for \\(r_{XY}\\)\n\n\nTempting to think that available-case analysis will be superior to complete-case analysis\n\nBut it can distort relationships between variables by not using a common base of observations for all quantities being estimated.\n\n\n\n18.4.3 Imputation\nFill in missing values, analyze completed data set\n\nAdvantage:\n\nRectangular data set easier to analyze\nAnalysis data set \\(n\\) matches summary table \\(n\\)\n\nDisadvantage:\n\n“Both seductive and dangerous” (Little and Rubin)\nCan understate uncertainty due to missing values.\nCan induce bias if imputing under the wrong model.",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#imputation-methods",
    "href": "missing_data.html#imputation-methods",
    "title": "18  Missing Data",
    "section": "18.5 Imputation Methods",
    "text": "18.5 Imputation Methods\nThis section demonstrates each imputation method on the bsi_depress scale variable from the parental HIV example. To recap, 37% of the data on this variable is missing.\nCreate an index of row numbers containing missing values. This will be used to fill in those missing values with a data value.\n\nmiss.dep.idx&lt;- which(is.na(hiv$bsi_depress))\nhead(miss.dep.idx) \n\n[1]  2  4  5  9 13 14\n\n\nFor demonstration purposes I will also create a copy of the bsi_depress variable so that the original is not overwritten for each example.\n\n18.5.1 Unconditional mean substitution.\n\nImpute all missing data using the mean of observed cases\nArtificially decreases the variance\n\n\nbsi_depress.ums &lt;- hiv$bsi_depress # copy\ncomplete.case.mean &lt;- mean(hiv$bsi_depress, na.rm=TRUE)\nbsi_depress.ums[miss.dep.idx] &lt;- complete.case.mean\n\n\n\n\n\n\n\n\n\n\nOnly a single value was used to impute missing data.\n\n\n18.5.2 Hot deck imputation\n\nImpute values by randomly sampling values from observed data.\n\nGood for categorical data\nReasonable for MCAR and MAR\nhotdeck function in VIM available\n\n\nbsi_depress.hotdeck&lt;- hiv$bsi_depress # copy\nhot.deck &lt;- sample(na.omit(hiv$bsi_depress), size = length(miss.dep.idx))\nbsi_depress.hotdeck[miss.dep.idx] &lt;- hot.deck\n\n\n\n\n\n\n\n\n\n\nThe distribution of imputed values better matches the distribution of observed data, but the distribution (Q1, Q3) is shifted lower a little bit.\n\n\n18.5.3 Model based imputation\n\nConditional Mean imputation: Use regression on observed variables to estimate missing values\n\nPredictions only available for cases with no missing covariates\nImputed value is the model predicted mean \\(\\hat{\\mu}_{Y|X}\\)\nCould use VIM::regressionImp() function\n\nPredictive Mean Matching: Fills in a value randomly by sampling observed values whose regression-predicted values are closest to the regression-predicted value for the missing point.\n\nCross between hot-deck and conditional mean\nCategorical data can be imputed using classification models\nLess biased than mean substitution\nbut SE’s could be inflated\nTypically used in multivariate imputation (so not shown here)\n\n\nModel bsi_depress using gender, siblings and age as predictors using linear regression.\n\nreg.model &lt;- lm(bsi_depress ~ gender + siblings + age, hiv) \nneed.imp  &lt;- hiv[miss.dep.idx, c(\"gender\", \"siblings\", \"age\")]\nreg.imp.vals &lt;- predict(reg.model, newdata = need.imp)\nbsi_depress.lm &lt;- hiv$bsi_depress # copy\nbsi_depress.lm[miss.dep.idx] &lt;- reg.imp.vals\n\n\n\n\n\n\n\n\n\n\nIt seems like only values around 0.5 and 0.8 were imputed values for bsi_depress. The imputed values don’t quite match the distribution of observed values. Regression imputation and PMM seem to perform extremely similarily.\n\n\n18.5.4 Adding a residual\n\nImpute regression value \\(\\pm\\) a randomly selected residual based on estimated residual variance\nOver the long-term, we can reduce bias, on the average\n\n\nset.seed(1337)\nrmse &lt;- sqrt(summary(reg.model)$sigma)\neps &lt;- rnorm(length(miss.dep.idx), mean=0, sd=rmse)\nbsi_depress.lm.resid &lt;- hiv$bsi_depress # copy\nbsi_depress.lm.resid[miss.dep.idx] &lt;- reg.imp.vals + eps\n\n\n\n\n\n\n\n\n\n\nWell, the distribution of imputed values is spread out a bit more, but the imputations do not respect the truncation at 0 this bsi_depress value has.\n\n\n18.5.5 Comparison of Estimates\nCreate a table and plot that compares the point estimates and intervals for the average bsi depression scale.\n\nsingle.imp &lt;- bind_rows(\ndata.frame(value = na.omit(hiv$bsi_depress),  method = \"Observed\"),\n  data.frame(value = bsi_depress.ums, method = \"Mean Sub\"), \n  data.frame(value = bsi_depress.hotdeck, method = \"Hot Deck\"), \n  data.frame(value = bsi_depress.lm, method = \"Regression\"), \n  data.frame(value = bsi_depress.lm.resid, method = \"Reg + eps\"))\n\nsingle.imp$method &lt;- forcats::fct_relevel(single.imp$method , \n      c(\"Observed\", \"Mean Sub\", \"Hot Deck\", \"Regression\", \"Reg + eps\"))\n\nsi.ss &lt;- single.imp %&gt;%\n  group_by(method) %&gt;%\n  summarize(mean = mean(value), \n            sd = sd(value), \n            se = sd/sqrt(n()), \n            cil = mean-1.96*se, \n            ciu = mean+1.96*se)\nsi.ss\n\n# A tibble: 5 × 6\n  method      mean    sd     se   cil   ciu\n  &lt;fct&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Observed   0.723 0.782 0.0622 0.601 0.844\n2 Mean Sub   0.723 0.620 0.0391 0.646 0.799\n3 Hot Deck   0.738 0.783 0.0494 0.641 0.835\n4 Regression 0.682 0.631 0.0399 0.604 0.760\n5 Reg + eps  0.753 0.848 0.0536 0.648 0.858\n\n\n\nggviolin(single.imp, y = \"value\", \n          fill = \"method\", x = \"method\", \n          add = \"boxplot\", \n          alpha = .2)\n\n\n\n\n\n\n\nggplot(si.ss, aes(x=mean, y = method, col=method)) + \n  geom_point() + geom_errorbar(aes(xmin=cil, xmax=ciu), width=0.2) + \n  scale_x_continuous(limits=c(.5, 1)) + \n  theme_bw() + xlab(\"Average BSI Depression score\") + ylab(\"\")\n\n\n\n\n\n\n\n\n…but we can do better.",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#multiple-imputation-mi",
    "href": "missing_data.html#multiple-imputation-mi",
    "title": "18  Missing Data",
    "section": "18.6 Multiple Imputation (MI)",
    "text": "18.6 Multiple Imputation (MI)\n\n18.6.1 Goals\n\nAccurately reflect available information\nAvoid bias in estimates of quantities of interest\nEstimation could involve explicit or implicit model\nAccurately reflect uncertainty due to missingness\n\n\n\n18.6.2 Technique\n\nFor each missing value, impute \\(m\\) estimates (usually \\(m\\) = 5)\n\nImputation method must include a random component\n\nCreate \\(m\\) complete data sets\nPerform desired analysis on each of the \\(m\\) complete data sets\nPool final estimates in a manner that accounts for the between, and within imputation variance.\n\n\n\n\nDiagram of Multiple Imputation process. Credit\n\n\n\n\n18.6.3 MI as a paradigm\n\nLogic: “Average over” uncertainty, don’t assume most likely scenario (single imputation) covers all plausible scenarios\nPrinciple: Want nominal 95% intervals to cover targets of estimation 95% of the time\nSimulation studies show that, when MAR assumption holds:\n\nProper imputations will yield close to nominal coverage (Rubin 87)\nImprovement over single imputation is meaningful\nNumber of imputations can be modest - even 2 adequate for many purposes, so 5 is plenty\n\n\n(Rubin, Multiple Imputation for Nonresponse in Surveys, Wiley, 1987)\n\n\n18.6.4 Inference on MI (Pooling estimates)\nConsider \\(m\\) imputed data sets. For some quantity of interest \\(Q\\) with squared \\(SE = U\\), calculate \\(Q_{1}, Q_{2}, \\ldots, Q_{m}\\) and \\(U_{1}, U_{2}, \\ldots, U_{m}\\) (e.g., carry out \\(m\\) regression analyses, obtain point estimates and SE from each).\nThen calculate the average estimate \\(\\bar{Q}\\), the average variance \\(\\bar{U}\\), and the variance of the averages \\(B\\).\n\\[\n  \\begin{aligned}\n  \\bar{Q} & = \\sum^{m}_{i=1}Q_{i}/m \\\\\n  \\bar{U} & = \\sum^{m}_{i=1}U_{i}/m \\\\\n  B & = \\frac{1}{m-1}\\sum^{m}_{i=1}(Q_{i}-\\bar{Q})^2\n  \\end{aligned}\n\\]\nThen \\(T = \\bar{U} + \\frac{m+1}{m}B\\) is the estimated total variance of \\(\\bar{Q}\\).\nSignificance tests and interval estimates can be based on\n\\[\\frac{\\bar{Q}-Q}{\\sqrt{T}} \\sim t_{df}, \\mbox{ where } df = (m-1)(1+\\frac{1}{m+1}\\frac{\\bar{U}}{B})^2\\]\n\ndf are similar to those for comparison of normal means with unequal variances, i.e., using Satterthwaite approximation.\nRatio of (B = between-imputation variance) to (T = between + within-imputation variance) is known as the fraction of missing information (FMI).\n\nThe FMI has been proposed as a way to monitor ongoing data collection and estimate the potential bias resulting from survey non-responders (Wagner, 2018)\n\n\n\n\n18.6.5 Example\n\nCreate \\(m\\) imputed datasets using linear regression plus a small amount of random noise so all the imputed values are not identical\n\n\nset.seed(1061)\ndep.imp1 &lt;- dep.imp2 &lt;- dep.imp3 &lt;- regressionImp(bsi_depress ~ gender + siblings + age, hiv) \ndep.imp1$bsi_depress[miss.dep.idx] &lt;- dep.imp1$bsi_depress[miss.dep.idx] +\n  rnorm(length(miss.dep.idx), mean=0, sd=rmse/2)\n\ndep.imp2$bsi_depress[miss.dep.idx] &lt;- dep.imp2$bsi_depress[miss.dep.idx] + \n  rnorm(length(miss.dep.idx), mean=0, sd=rmse/2)\n\ndep.imp3$bsi_depress[miss.dep.idx] &lt;- dep.imp3$bsi_depress[miss.dep.idx] + \n  rnorm(length(miss.dep.idx), mean=0, sd=rmse/2)\n\nVisualize the distributions of observed and imputed\n\ndep.mi &lt;- bind_rows(\n  data.frame(value = dep.imp1$bsi_depress, imputed = dep.imp1$bsi_depress_imp, \n             imp = \"dep.imp1\"), \n  data.frame(value = dep.imp2$bsi_depress, imputed = dep.imp2$bsi_depress_imp, \n             imp =\"dep.imp2\"), \n  data.frame(value = dep.imp3$bsi_depress, imputed = dep.imp3$bsi_depress_imp, \n             imp =\"dep.imp3\"))\n\nggdensity(dep.mi, x = \"value\", color = \"imputed\", fill = \"imputed\", \n          add = \"mean\", rug=TRUE, palette = \"jco\") + \n  facet_wrap(~imp, ncol=1)\n\n\n\n\n\n\n\n\n\nCalculate the point estimate \\(Q\\) and the variance \\(U\\) from each imputation.\n\n\n(Q &lt;- c(mean(dep.imp1$bsi_depress), \n        mean(dep.imp2$bsi_depress), \n        mean(dep.imp3$bsi_depress)))\n\n[1] 0.6700139 0.6808710 0.6694280\n\nn.d &lt;- length(dep.imp1$bsi_depress)\n(U &lt;- c(sd(dep.imp1$bsi_depress)/sqrt(n.d), \n        sd(dep.imp2$bsi_depress)/sqrt(n.d), \n        sd(dep.imp3$bsi_depress)/sqrt(n.d)))\n\n[1] 0.04443704 0.04324317 0.04365866\n\n\n\nPool estimates and calculate a 95% CI\n\n\nQ.bar &lt;- mean(Q)          # average estimate\nU.bar &lt;- mean(U)           # average variance\nB &lt;- sd(Q)                 # variance of averages\nTv &lt;- U.bar + ((3+1)/3)*B  # Total variance of estimate\n\ndf &lt;- 2*(1+(U.bar/(4*B))^2) # degress of freedom\nt95 &lt;- qt(.975, df) # critical value for 95% CI\n\nmi.ss &lt;- data.frame(\n  method = \"MI Reg\", \n  mean = Q.bar, \n  se = sqrt(Tv), \n  cil = Q.bar - t95*sqrt(Tv),\n  ciu = Q.bar + t95*sqrt(Tv))\n\n(imp.ss &lt;- bind_rows(si.ss, mi.ss))\n\n# A tibble: 6 × 6\n  method      mean     sd     se   cil   ciu\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Observed   0.723  0.782 0.0622 0.601 0.844\n2 Mean Sub   0.723  0.620 0.0391 0.646 0.799\n3 Hot Deck   0.738  0.783 0.0494 0.641 0.835\n4 Regression 0.682  0.631 0.0399 0.604 0.760\n5 Reg + eps  0.753  0.848 0.0536 0.648 0.858\n6 MI Reg     0.673 NA     0.229  0.143 1.20 \n\n\n\nggplot(imp.ss, aes(x=mean, y = method, col=method)) + \n  geom_point() + geom_errorbar(aes(xmin=cil, xmax=ciu), width=0.2) + \n  scale_x_continuous(limits=c(-.3, 2)) + \n  theme_bw() + xlab(\"Average BSI Depression score\") + ylab(\"\")",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#multiple-imputation-using-chained-equations-mice",
    "href": "missing_data.html#multiple-imputation-using-chained-equations-mice",
    "title": "18  Missing Data",
    "section": "18.7 Multiple Imputation using Chained Equations (MICE)",
    "text": "18.7 Multiple Imputation using Chained Equations (MICE)\n\n\n18.7.1 Overview\n\nGenerates multiple imputations for incomplete multivariate data by Gibbs sampling.\nMissing data can occur anywhere in the data.\nImpute an incomplete column by generating ‘plausible’ synthetic values given other columns in the data.\nFor predictors that are incomplete themselves, the most recently generated imputations are used to complete the predictors prior to imputation of the target column.\nA separate univariate imputation model can be specified for each column.\nThe default imputation method depends on the measurement level of the target column.\n\n\n\n\n\n\n\nLearn more\n\n\n\nYour best reference guide to this section of the notes is the bookdown version of Flexible Imputation of Missing Data, by Stef van Buuren\nFor a more technical details about how the mice function works in R, see Journal of Statistical Software\n\n\n\n\n18.7.2 Process / Algorithm\nConsider a data matrix with 3 variables \\(y_{1}\\), \\(y_{2}\\), \\(y_{3}\\), each with missing values. At iteration \\((\\ell)\\):\n\nFit a model on \\(y_{1}^{(\\ell-1)}\\) using current values of \\(y_{2}^{(\\ell-1)}, y_{3}^{(\\ell-1)}\\)\nImpute missing \\(y_{1}\\), generating \\(y_{1}^{(\\ell)}\\)\nFit a model on \\(y_{2}^{(\\ell-1)}\\) using current versions of \\(y_{1}^{(\\ell)}, y_{3}^{(\\ell-1)}\\)\nImpute missing \\(y_{2}\\), generating \\(y_{2}^{(\\ell)}\\)\nFit a model on \\(y_{3}\\) using current versions of \\(y_{1}^{(\\ell)}, y_{2}^{(\\ell)}\\)\nImpute missing \\(y_{3}\\), generating \\(y_{3}^{(\\ell)}\\)\nStart next cycle using updated values \\(y_{1}^{(\\ell)}, y_{2}^{(\\ell)}, y_{3}^{(\\ell)}\\)\n\nwhere \\((\\ell)\\) cycles from 1 to \\(L\\), before an imputed value is drawn.\n\n\n18.7.3 Convergence\nHow many imputations (\\(m\\)) should we create and how many iterations (\\(L\\)) should I run between imputations?\n\nOriginal research from Rubin states that small amount of imputations (\\(m=5\\)) would be sufficient.\nAdvances in computation have resulted in very efficient programs such as mice - so generating a larger number of imputations (say \\(m=40\\)) are more common (Pan, 2016)\nYou want the number of iterations between draws to be long enough that the Gibbs sampler has converged.\nThere is no test or direct method for determing convergence.\n\nPlot parameter against iteration number, one line per chain.\nThese lines should be intertwined together, without showing trends.\nConvergence can be identified when the variance between lines is smaller (or at least no larger) than the variance within the lines.\n\n\n\n\n\n\n\n\nMandatory Reading\n\n\n\nRead 6.5.2: Convergence from Flexible Imputation of Missing Data\n\n\n\n\n18.7.4 Imputation Methods\nSome built-in imputation methods in the mice package are:\n\npmm: Predictive mean matching (any) DEFAULT FOR NUMERIC\nnorm.predict: Linear regression, predicted values (numeric)\nmean: Unconditional mean imputation (numeric)\nlogreg: Logistic regression (factor, 2 levels) DEFAULT\nlogreg.boot: Logistic regression with bootstrap\npolyreg: Polytomous logistic regression (factor, &gt;= 2 levels) DEFAULT\nlda: Linear discriminant analysis (factor, &gt;= 2 categories)\ncart: Classification and regression trees (any)\nrf: Random forest imputations (any)",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#diagnostics",
    "href": "missing_data.html#diagnostics",
    "title": "18  Missing Data",
    "section": "18.8 Diagnostics",
    "text": "18.8 Diagnostics\nQ: How do I know if the imputed values are plausible?\nA: Create diagnostic graphics that plot the observed and imputed values together.\nRefer to 6.6 Diagnostics of Flexible Imputation of Missing Data.",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#example-prescribed-amount-of-missing.",
    "href": "missing_data.html#example-prescribed-amount-of-missing.",
    "title": "18  Missing Data",
    "section": "18.9 Example: Prescribed amount of missing.",
    "text": "18.9 Example: Prescribed amount of missing.\nWe will demonstrate using the Palmer Penguins dataset where we can artificially create a prespecified percent of the data missing, (after dropping the 11 rows missing sex) This allows us to be able to estimate the bias incurred by using these imputation methods.\nFor the penguin data ) out we set a seed and use the prodNA() function from the missForest package to create 10% missing values in this data set.\n\nlibrary(missForest)\nset.seed(12345) # Raspberry, I HATE raspberry!\npen.nomiss &lt;- na.omit(pen)\npen.miss &lt;- prodNA(pen.nomiss, noNA=0.1)\nprop.table(table(is.na(pen.miss)))\n\n\n     FALSE       TRUE \n0.90015015 0.09984985 \n\n\nVisualize missing data pattern.\n\naggr(pen.miss, col=c('darkolivegreen3','salmon'),\n              numbers=TRUE, sortVars=TRUE,\n              labels=names(pen.miss), cex.axis=.7,\n              gap=3, ylab=c(\"Missing data\",\"Pattern\"))\n\n\n\n\n\n\n\n\n\n Variables sorted by number of missings: \n          Variable      Count\n            island 0.11411411\n               sex 0.11111111\n       body_mass_g 0.10510511\n flipper_length_mm 0.10210210\n    bill_length_mm 0.09909910\n           species 0.09009009\n     bill_depth_mm 0.09009009\n              year 0.08708709\n\n\nHere’s another example of where only 10% of the data overall is missing, but it results in only 58% complete cases.\n\n18.9.1 Multiply impute the missing data using mice()\n\nimp_pen &lt;- mice(pen.miss, m=10, maxit=25, meth=\"pmm\", seed=500, printFlag=FALSE)\nsummary(imp_pen)\n\nClass: mids\nNumber of multiple imputations:  10 \nImputation methods:\n          species            island    bill_length_mm     bill_depth_mm \n            \"pmm\"             \"pmm\"             \"pmm\"             \"pmm\" \nflipper_length_mm       body_mass_g               sex              year \n            \"pmm\"             \"pmm\"             \"pmm\"             \"pmm\" \nPredictorMatrix:\n                  species island bill_length_mm bill_depth_mm flipper_length_mm\nspecies                 0      1              1             1                 1\nisland                  1      0              1             1                 1\nbill_length_mm          1      1              0             1                 1\nbill_depth_mm           1      1              1             0                 1\nflipper_length_mm       1      1              1             1                 0\nbody_mass_g             1      1              1             1                 1\n                  body_mass_g sex year\nspecies                     1   1    1\nisland                      1   1    1\nbill_length_mm              1   1    1\nbill_depth_mm               1   1    1\nflipper_length_mm           1   1    1\nbody_mass_g                 0   1    1\n\n\n\n\n\n\n\n\nLearn more\n\n\n\nThis Stack Exchange post has a great explanation/description of what each of these arguments control. It is a very good idea to understand these controls.\n\n\n\n\n18.9.2 Check the imputation method used on each variable.\n\nimp_pen$meth\n\n          species            island    bill_length_mm     bill_depth_mm \n            \"pmm\"             \"pmm\"             \"pmm\"             \"pmm\" \nflipper_length_mm       body_mass_g               sex              year \n            \"pmm\"             \"pmm\"             \"pmm\"             \"pmm\" \n\n\nPredictive mean matching was used for all variables, even species and island. This is reasonable because PMM is a hot deck method of imputation.\n\n\n18.9.3 Check Convergence\n\nplot(imp_pen, c(\"bill_length_mm\", \"body_mass_g\", \"bill_depth_mm\"))\n\n\n\n\n\n\n\n\nThe variance across chains is no larger than the variance within chains.\n\n\n18.9.4 Look at the values generated for imputation\n\nimp_pen$imp$body_mass_g |&gt; head()\n\n      1    2    3    4    5    6    7    8    9   10\n3  3800 3750 3550 3900 3550 3300 3400 3900 3450 3900\n8  3300 3150 3525 3150 3500 3150 3325 3200 3325 3300\n13 4300 4050 4500 4000 4675 4550 4050 3950 4575 4550\n35 3400 3900 4075 3600 3900 3700 3900 3425 4725 3250\n41 3600 4300 3900 3600 3950 3900 3500 3900 4150 4100\n45 2700 3100 3625 3700 3525 3800 3575 3100 3575 3525\n\n\nThis is just for us to see what this imputed data look like. Each column is an imputed value, each row is a row where an imputation for body_mass_g was needed. Notice only imputations are shown, no observed data is showing here.\n\n\n18.9.5 Create a complete data set by filling in the missing data using the imputations\n\npen_1 &lt;- complete(imp_pen, action=1)\n\nAction=1 returns the first completed data set, action=2 returns the second completed data set, and so on.\nAlternative - Stack the imputed data sets in long format.\n\npen_long &lt;- complete(imp_pen, 'long')\n\nBy looking at the names of this new object we can confirm that there are indeed 10 complete data sets with \\(n=333\\) in each.\n\nnames(pen_long)\n\n [1] \".imp\"              \".id\"               \"species\"          \n [4] \"island\"            \"bill_length_mm\"    \"bill_depth_mm\"    \n [7] \"flipper_length_mm\" \"body_mass_g\"       \"sex\"              \n[10] \"year\"             \n\ntable(pen_long$.imp)\n\n\n  1   2   3   4   5   6   7   8   9  10 \n333 333 333 333 333 333 333 333 333 333 \n\n\n\n\n18.9.6 Visualize Imputations\nLet’s compare the imputed values to the observed values to see if they are indeed “plausible”. We want to see that the distribution of of the magenta points (imputed) matches the distribution of the blue ones (observed).\n\nUnivariatelyMultivariately\n\n\n\ndensityplot(imp_pen)\n\n\n\n\n\n\n\n\n\n\n\nxyplot(imp_pen, bill_length_mm ~ bill_depth_mm + flipper_length_mm  | species + island, cex=.8, pch=16)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyze and pool All of this imputation was done so we could actually perform an analysis!\nLet’s run a simple linear regression on body_mass_g as a function of bill_length_mm, flipper_length_mm and species.\n\nmodel &lt;- with(imp_pen, lm(body_mass_g ~ bill_length_mm + flipper_length_mm + species))\nsummary(pool(model))\n\n               term    estimate  std.error statistic        df      p.value\n1       (Intercept) -3758.87511 577.502100 -6.508851 205.80708 5.670334e-10\n2    bill_length_mm    51.61565   9.013278  5.726624  49.20373 6.081152e-07\n3 flipper_length_mm    28.67977   3.819019  7.509722  84.41687 5.618897e-11\n4  speciesChinstrap  -615.76862  97.112862 -6.340753  68.84331 2.051941e-08\n5     speciesGentoo   155.61083  92.618867  1.680120 298.97391 9.397845e-02\n\n\nPooled parameter estimates \\(\\bar{Q}\\) and their standard errors \\(\\sqrt{T}\\) are provided, along with a significance test (against \\(\\beta_p=0\\)). Note with this output that a 95% interval must be calculated manually.\nWe can leverage the gtsummary package to tidy and print the results of a mids object, but the mice object has to be passed to tbl_regression BEFORE you pool (reference this SO post). This function needs to access features of the original model first, then will do the appropriate pooling and tidying.\n\ngtsummary::tbl_regression(model)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\nbill_length_mm\n52\n34, 70\n&lt;0.001\n\n\nflipper_length_mm\n29\n21, 36\n&lt;0.001\n\n\nspecies\n\n\n\n\n\n\n\n\n    Adelie\n—\n—\n\n\n\n\n    Chinstrap\n-616\n-810, -422\n&lt;0.001\n\n\n    Gentoo\n156\n-27, 338\n0.094\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nAdditionally digging deeper into the object created by pool(model), specifically the pooled list, we can pull out additional information including the number of missing values, the fraction of missing information (fmi) as defined by Rubin (1987), and lambda, the proportion of total variance that is attributable to the missing data (\\(\\lambda = (B + B/m)/T)\\).\n\nkable(pool(model)$pooled[,c(1:4, 8:9)], digits=3)\n\n\n\n\nterm\nm\nestimate\nubar\ndf\nriv\n\n\n\n\n(Intercept)\n10\n-3758.875\n296028.896\n205.807\n0.127\n\n\nbill_length_mm\n10\n51.616\n50.961\n49.204\n0.594\n\n\nflipper_length_mm\n10\n28.680\n10.749\n84.417\n0.357\n\n\nspeciesChinstrap\n10\n-615.769\n6583.091\n68.843\n0.433\n\n\nspeciesGentoo\n10\n155.611\n8255.317\n298.974\n0.039\n\n\n\n\n\n\n\n18.9.7 Calculating bias\nThe penguins data set used here had no missing data to begin with. So we can calculate the “true” parameter estimates…\n\ntrue.model &lt;- lm(body_mass_g ~ bill_length_mm + flipper_length_mm + species, data = pen.nomiss)\n\nand find the difference in coefficients.\nThe variance of the multiply imputed estimates is larger because of the between-imputation variance.\n\ntm.est &lt;- true.model |&gt; coef() |&gt; broom::tidy() |&gt; mutate(model = \"True Model\") |&gt;\n  rename(est = x)\ntm.est$cil &lt;- confint(true.model)[,1]\ntm.est$ciu &lt;- confint(true.model)[,2]\ntm.est &lt;- tm.est[-1,] # drop intercept\n\nmi &lt;- tbl_regression(model)$table_body |&gt; \n  select(names = label, est = estimate, cil=conf.low, ciu=conf.high) |&gt; \n  mutate(model = \"MI\") |&gt; filter(!is.na(est))\n\npen.mi.compare &lt;- bind_rows(tm.est, mi)\npen.mi.compare$names &lt;- gsub(\"species\", \"\", pen.mi.compare$names)\n\nggplot(pen.mi.compare, aes(x=est, y = names, col=model)) + \n  geom_point() + geom_errorbar(aes(xmin=cil, xmax=ciu), width=0.2) + \n  theme_bw() \n\n\n\n\n\n\n\n\n\n\n\n\n\nnames\nTrue Model\nMI\nbias\n\n\n\n\nbill_length_mm\n60.11732\n51.61565\n-8.501672\n\n\nflipper_length_mm\n27.54429\n28.67977\n1.135481\n\n\nChinstrap\n-732.41667\n-615.76862\n116.648049\n\n\nGentoo\n113.25418\n155.61083\n42.356655\n\n\n\n\n\nMI over estimates the difference in body mass between Chinstrap and Adelie, but underestiamtes that difference for Gentoo. There is also an underestimation of the relationship between bill length and body mass.",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#post-mice-data-management",
    "href": "missing_data.html#post-mice-data-management",
    "title": "18  Missing Data",
    "section": "18.10 Post MICE data management",
    "text": "18.10 Post MICE data management\nSometimes you’ll have a need to do additional data management after imputation has been completed. Creating binary indicators of an event, re-creating scale variables etc. The general approach is to transform the imputed data into long format using complete with the argument include=TRUE , do the necessary data management, and then convert it back to a mids object type.\nContinuing with the penguin example, let’s create a new variable that is the ratio of bill length to depth.\nRecapping prior steps of imputing, and then creating the completed long data set.\n\n## imp_pen &lt;- mice(pen.miss, m=10, maxit=25, meth=\"pmm\", seed=500, printFlag=FALSE)\npen_long &lt;- complete(imp_pen, 'long', include=TRUE)\n\nWe create the new ratio variable on the long data:\n\npen_long$ratio &lt;- pen_long$bill_length_mm / pen_long$bill_depth_mm\n\nLet’s visualize this to see how different the distributions are across imputation. Notice imputation “0” still has missing data - this is a result of using include = TRUE and keeping the original data as part of the pen_long data.\n\nggboxplot(pen_long, y=\"ratio\", x=\"species\", facet.by = \".imp\")\n\n\n\n\n\n\n\n\nThen convert the data back to mids object, specifying the variable name that identifies the imputation number.\n\nimp_pen1 &lt;- as.mids(pen_long, .imp = \".imp\")\n\nNow we can conduct analyses such as an ANOVA (in linear model form) to see if this ratio differs significantly across the species.\n\nnova.ratio &lt;- with(imp_pen1, lm(ratio ~ species))\npool(nova.ratio) |&gt; summary()\n\n              term  estimate  std.error statistic       df       p.value\n1      (Intercept) 2.1221949 0.01435687 147.81738 281.7994 4.610006e-269\n2 speciesChinstrap 0.5217842 0.02569344  20.30807 245.0315  1.958440e-54\n3    speciesGentoo 1.0643029 0.02165568  49.14659 254.5258 6.526634e-132",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#final-thoughts",
    "href": "missing_data.html#final-thoughts",
    "title": "18  Missing Data",
    "section": "18.11 Final thoughts",
    "text": "18.11 Final thoughts\n\n\n\n\n\n\n“In our experience with real and artificial data…, the practical conclusion appears to be that multiple imputation, when carefully done, can be safely used with real problems even when the ultimate user may be applying models or analyses not contemplated by the imputer.” - Little & Rubin (Book, p. 218)\n\n\n\n\nDon’t ignore missing data.\nImpute sensibly and multiple times.\nIt’s typically desirable to include many predictors in an imputation model, both to\n\nimprove precision of imputed values\nmake MAR assumption more plausible\n\nBut the number of covariance parameters goes up as the square of the number of variables in the model,\n\nimplying practical limits on the number of variables for which parameters can be estimated well\n\nMI applies to subjects who have a general missingness pattern, i.e., they have measurements on some variables, but not on others.\nBut, subjects can be lost to follow up due to death or other reasons (i.e., attrition).\nHere we have only baseline data, but not the outcome or other follow up data.\nIf attrition subjects are eliminated from the sample, they can produce non-response or attrition bias.\nUse attrition weights.\n\nGiven a baseline profile, predict the probability that subject will stay and use the inverse probability as weight.\ne.g., if for a given profile all subjects stay, then the predicted probability is 1 and the attrition weight is 1. Such a subject “counts once”.\nFor another profile, the probability may be 0.5, attrition weight is 1/.5 = 2 and that person “counts twice”.\n\nFor differential drop-out, or self-selected treatment, you can consider using Propensity Scores.",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#additional-references",
    "href": "missing_data.html#additional-references",
    "title": "18  Missing Data",
    "section": "18.12 Additional References",
    "text": "18.12 Additional References\n\nLittle, R. and Rubin, D. Statistical Analysis with Missing Data, 2nd Ed., Wiley, 2002\n\nStandard reference\nRequires some math\n\nAllison, P. Missing Data, Sage, 2001\n\nSmall and cheap\nRequires very little math\n\nMultiple Imputation - Stef van Buuren\nApplied Missing Data Analysis with SPSS and (R) Studio Heymans and Eekhout\nTutorial on 5 Powerful R Packages used for imputing missing values - Analytics Vidhya\nImputing missing data with R; MICE package - R-bloggers\n\nImputation methods for complex survey data and data not missing at random is an open research topic. Read more about this here\n\n\n\nSource",
    "crumbs": [
      "Other Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Missing Data</span>"
    ]
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "Common error messages",
    "crumbs": [
      "Appendix"
    ]
  },
  {
    "objectID": "appendix.html#common-error-messages",
    "href": "appendix.html#common-error-messages",
    "title": "Appendix",
    "section": "",
    "text": "Function not found\n\nCheck the spelling and capitalization.\nDid you load the package in your first code chunk?\n\n\n\nObject not found\nR can’t find the object you are referring to. Here are some debugging steps:\n\nCheck the spelling and capitalization.\nIf you are referring to a variable inside a data set, did you use $ notation?\nCan you find this variable in some other manner? (i.e. )\nIf this piece of code works when you are working interactively, but not when you knit, then check where you created this variable. Is it written either in this current code file or your data management file?\nDid you create this variable in your data management file, and then forget to run the entire code document (hence recreating the analysis data set with this new variable)\nShut down and restart R studio entirely.\n\n\n\n\nObject of length 0\nThis object does not exist, or is empty. Check how you created this object initially.\n\n\nDiscrete scale applied to continuous object\nRead that error message carefully. It explains exactly what the problem is. It is up to you to problem solve to figure out which variable you are trying to apply a scale to (like color or fill), what it’s data type is.\n\n\nPackage inputenc error: Unicode char not set up for use with \nWhen you want to use certain symbols in math notation, such as Greek letters or the tilde (\\(\\sim\\)), it is important that you type in the commands for them (e.g., to write \\(\\sim\\), type or for the Greek letter \\(\\mu\\), type ). If you get this error message, there are a couple of possibilities. Either you omitted a around the notation, or you copied and pasted symbols straight from the course notes. In the latter case, find the symbol and replace it with its command (these are usually pretty self-explanatory but when in doubt, Google it).\n\n\nContinuous x aesthetic – did you forget aes(group=…)?\nThis ggplot2 error message will show up when the aesthetics of a plot don’t map to the geometry of your data. Try either of these solutions depending on your variable type:\n\nChange your x variable to a discrete data type, such as a factor.\nAdd the argument group=1 to the aesthetics of the plot, aes().",
    "crumbs": [
      "Appendix"
    ]
  }
]
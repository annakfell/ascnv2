[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Statistics",
    "section": "",
    "text": "Preface\nThis document is a set of course notes for several Applied Statistics courses at California State University, Chico. This is not a textbook replacement, and topics covered will vary depending on the instructor. To make this clear we use the term notebook to refer to this document so as not to be confused with a traditional textbook.\nSome data and examples in this notebook are drawn from Practical Multivariate Analysis, 6tth ed, Afifi, May, Donatello, Clark and used with permission by the authors.\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "dataprep.html",
    "href": "dataprep.html",
    "title": "1  Workflow and Data Cleaning",
    "section": "",
    "text": "1.1 Reproducible workflows\nReproducibility is the ability for any researcher to take the same data set and run the same set of software program instructions as another researcher and achieve the same results.\nThe goal is to create an exact record of what was done to a data set to produce a specific result. To achieve reproducibility, we believe that three things must be present:\nWhy do we need a codebook?\nFigure Credits: Roger Peng",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#reproducible-workflows",
    "href": "dataprep.html#reproducible-workflows",
    "title": "1  Workflow and Data Cleaning",
    "section": "",
    "text": "The un-processed data are connected directly to software code file(s) that perform data preparation techniques.\nThe processed data are connected directly to other software code file(s) that perform the analyses.\nAll data and code files are self-contained such that they could be given to another researcher to execute the code commands on a separate computer and achieve the same results as the original author.\n\n\n\n\nPrepareData\n\n\n\n\nYou are your own collaborator 6 months from now. Make sure you will be able to understand what you were doing.\nInvesting the time to do things clearly and in a reproducible manner will make your future self happy.\nComment your code with explanations and instructions.\n\nHow did you get from point A to B?\nWhy did you recode this variable in this manner?\n\nWe need to record those steps (not just for posterity).\nThis means your code must be saved in a script file.\n\nInclude sufficient notes to yourself describing what you are doing and why.\nFor R, this can be in a .R, .Rmd or .qmd file. I always prefer the latter.\nFor SPSS you can specify to paste the syntax and copy into a .sps script file.\nFor SAS you’ll use a .sas file\nFor STATA this will be a .do file\n\n\n\n\n\nRepro\n\n\n\n\n1.1.1 Literate programming\n\nProgramming paradigm introduced by Knuth (1984)\nExplain the logic of the program or analysis process in a natural language,\nSmall code snippets included at each step act as a full set of instructions that can be executed to reproduce the result/analysis being discussed.\n\nLiterate programming tools are integrated into most common statistical packages\n\nMarkdown (R, Stata), Quarto (R, Python, others)\n\\(\\LaTeX\\) (R, SAS, Stata)\n\n\n\n\n\n\n\nThe current gold standard for writing reproducible literate documents in R is to use Quarto. This works with Python, julia and other code editing platforms.\n\n\n\nPracticing reproducible research techniques using literate programming tools allows such major updates to be a simple matter of re-compiling all coded instructions using the updated data set.\nThe effort then is reduced to a careful review and update of any written results.\nUsing literate programming tools create formatted documents\n\nsection headers\nbold and italicized words\ntables and graphics with built-in captions\n\nin a streamlined manner that is fully synchronized with the code itself.\nThe author writes the text explanations, interpretations, and code in the statistical software program itself, and the program will execute all commands and combine the text, code and output all together into a final dynamic document.\n What stages of the pipeline shown above can we conduct using literate programming tools?",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#import-data",
    "href": "dataprep.html#import-data",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.2 Import data",
    "text": "1.2 Import data\nThis section uses the raw depression data set from the Afifi et.al. textbook. This is a tab-delimited data set, so we opt to use read.table here. We include arguments sep=\"\\t\" to indicate columns are separated with tabs and header=TRUE to indicate the first row of the data is the variable names.\n\nlibrary(ggplot2)  \ndepress_raw &lt;- read.table(here::here(\"data/Depress.txt\"), \n                      sep=\"\\t\", header=TRUE)  \n\n\n\n\n\n\n\nLearn more See R for Data Science 2nd edit for more instruction on importing different types of data and ways you can streamline your data import. https://r4ds.hadley.nz/data-import\n\n\n\nThe absolute first thing you should do is to look at your raw data table. Are the column headers variable names? Did all the rows get read in? Are there any extra columns or rows included?",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#data-management",
    "href": "dataprep.html#data-management",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.3 Data Management",
    "text": "1.3 Data Management\nQuestions to ask yourself while reviewing the codebook to choose variables to be used in an analysis.\n\nAre there codes that indicate missing? E.g. MISSING or -99?\nDo you need to make response codes more logical?\n\nSome systems will record 1=YES and 2=NO. This should be changed to 0=NO.\n\nDo you need to recode numerical variables to categorical?\n\nSometimes categorical data will be recorded as 1, 2, 3 etc when those numbers represent named categories.\n\nDo you need to create secondary variables such as an average across measures to create a score.\nAre the variable names user friendly? Mixtures of CAPS and lower case, names with spaces or special characters should all be changed.\n\nSome of these answers will come only after you look at your data. This can be looking at the raw data itself but also looking at tables and charts generated from the data. Often when you try to create a plot or table you will encounter an error or something odd looking that will be the notification that something has to be adjusted.\nThe next sections go over a few of the common data management processes, but is not comprehensive, and may only show one method for cleaning. There are always different ways to accomplish tasks.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#renaming-variable-names-for-sanity-sake",
    "href": "dataprep.html#renaming-variable-names-for-sanity-sake",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.4 Renaming variable names for sanity sake",
    "text": "1.4 Renaming variable names for sanity sake\nThe best method is to use the clean_names() function from the janitor package.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndepress &lt;- depress_raw %&gt;% janitor::clean_names()\n\nA base R soluion is to use `tolower() to turn all variable names to lower case.\n\n## names(depress) &lt;- tolower(names(depress))\ntolower(\"ThIs MIXTure of CAPS and lowercase WILL alL be conVERteD to LoWeR CAsE\")\n\n[1] \"this mixture of caps and lowercase will all be converted to lower case\"",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#identifying-variable-types",
    "href": "dataprep.html#identifying-variable-types",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.5 Identifying Variable Types",
    "text": "1.5 Identifying Variable Types\nThe str function is short for structure. This shows you the variable names, what data types R thinks each variable are, and some of the raw data.\n\nstr(depress)\n\n'data.frame':   294 obs. of  37 variables:\n $ id      : int  1 2 3 4 5 6 7 8 9 10 ...\n $ sex     : int  2 1 2 2 2 1 2 1 2 1 ...\n $ age     : int  68 58 45 50 33 24 58 22 47 30 ...\n $ marital : int  5 3 2 3 4 2 2 1 2 2 ...\n $ educat  : int  2 4 3 3 3 3 2 3 3 2 ...\n $ employ  : int  4 1 1 3 1 1 5 1 4 1 ...\n $ income  : int  4 15 28 9 35 11 11 9 23 35 ...\n $ relig   : int  1 1 1 1 1 1 1 1 2 4 ...\n $ c1      : int  0 0 0 0 0 0 2 0 0 0 ...\n $ c2      : int  0 0 0 0 0 0 1 1 1 0 ...\n $ c3      : int  0 1 0 0 0 0 1 2 1 0 ...\n $ c4      : int  0 0 0 0 0 0 2 0 0 0 ...\n $ c5      : int  0 0 1 1 0 0 1 2 0 0 ...\n $ c6      : int  0 0 0 1 0 0 0 1 3 0 ...\n $ c7      : int  0 0 0 0 0 0 0 0 0 0 ...\n $ c8      : int  0 0 0 3 3 0 2 0 0 0 ...\n $ c9      : int  0 0 0 0 3 1 2 0 0 0 ...\n $ c10     : int  0 0 0 0 0 0 0 0 0 0 ...\n $ c11     : int  0 0 0 0 0 0 0 0 0 0 ...\n $ c12     : int  0 1 0 0 0 1 0 0 3 0 ...\n $ c13     : int  0 0 0 0 0 2 0 0 0 0 ...\n $ c14     : int  0 0 1 0 0 0 0 0 3 0 ...\n $ c15     : int  0 1 1 0 0 0 3 0 2 0 ...\n $ c16     : int  0 0 1 0 0 2 0 1 3 0 ...\n $ c17     : int  0 1 0 0 0 1 0 1 0 0 ...\n $ c18     : int  0 0 0 0 0 0 0 1 0 0 ...\n $ c19     : int  0 0 0 0 0 0 0 1 0 0 ...\n $ c20     : int  0 0 0 0 0 0 1 0 0 0 ...\n $ cesd    : int  0 4 4 5 6 7 15 10 16 0 ...\n $ cases   : int  0 0 0 0 0 0 0 0 1 0 ...\n $ drink   : int  2 1 1 2 1 1 2 2 1 1 ...\n $ health  : int  2 1 2 1 1 1 3 1 4 1 ...\n $ regdoc  : int  1 1 1 1 1 1 1 2 1 1 ...\n $ treat   : int  1 1 1 2 1 1 1 2 1 2 ...\n $ beddays : int  0 0 0 0 1 0 0 0 1 0 ...\n $ acuteill: int  0 0 0 0 1 1 1 1 0 0 ...\n $ chronill: int  1 1 0 1 0 1 1 0 1 0 ...\n\n\nA tidyverse alternative is glimpse()\n\nglimpse(depress)\n\nRows: 294\nColumns: 37\n$ id       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ sex      &lt;int&gt; 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2…\n$ age      &lt;int&gt; 68, 58, 45, 50, 33, 24, 58, 22, 47, 30, 20, 57, 39, 61, 23, 2…\n$ marital  &lt;int&gt; 5, 3, 2, 3, 4, 2, 2, 1, 2, 2, 1, 2, 2, 5, 2, 1, 1, 4, 1, 5, 1…\n$ educat   &lt;int&gt; 2, 4, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 3, 3, 2, 4, 2, 6, 2, 3…\n$ employ   &lt;int&gt; 4, 1, 1, 3, 1, 1, 5, 1, 4, 1, 3, 2, 1, 4, 1, 1, 1, 3, 1, 4, 1…\n$ income   &lt;int&gt; 4, 15, 28, 9, 35, 11, 11, 9, 23, 35, 25, 24, 28, 13, 15, 6, 8…\n$ relig    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 2, 1, 1, 1, 1, 4, 2…\n$ c1       &lt;int&gt; 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 3, 1, 0, 0, 0…\n$ c2       &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 3, 0, 0, 0, 0…\n$ c3       &lt;int&gt; 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0…\n$ c4       &lt;int&gt; 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0…\n$ c5       &lt;int&gt; 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1, 3, 1, 0, 0, 0…\n$ c6       &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 1, 3, 0, 2, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0…\n$ c7       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0…\n$ c8       &lt;int&gt; 0, 0, 0, 3, 3, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 3, 0…\n$ c9       &lt;int&gt; 0, 0, 0, 0, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 3…\n$ c10      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0…\n$ c11      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0…\n$ c12      &lt;int&gt; 0, 1, 0, 0, 0, 1, 0, 0, 3, 0, 1, 0, 1, 1, 0, 1, 2, 0, 0, 0, 0…\n$ c13      &lt;int&gt; 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0…\n$ c14      &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0…\n$ c15      &lt;int&gt; 0, 1, 1, 0, 0, 0, 3, 0, 2, 0, 1, 2, 0, 0, 1, 1, 3, 0, 0, 0, 0…\n$ c16      &lt;int&gt; 0, 0, 1, 0, 0, 2, 0, 1, 3, 0, 1, 2, 1, 0, 3, 1, 2, 0, 0, 0, 0…\n$ c17      &lt;int&gt; 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0…\n$ c18      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0…\n$ c19      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0…\n$ c20      &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 3, 0, 0, 0, 0…\n$ cesd     &lt;int&gt; 0, 4, 4, 5, 6, 7, 15, 10, 16, 0, 18, 4, 8, 4, 8, 21, 42, 6, 0…\n$ cases    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0…\n$ drink    &lt;int&gt; 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1…\n$ health   &lt;int&gt; 2, 1, 2, 1, 1, 1, 3, 1, 4, 1, 2, 2, 3, 1, 1, 3, 1, 3, 2, 2, 1…\n$ regdoc   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1…\n$ treat    &lt;int&gt; 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1…\n$ beddays  &lt;int&gt; 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0…\n$ acuteill &lt;int&gt; 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0…\n$ chronill &lt;int&gt; 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1…\n\n\nRight away this tells me that R thinks all variables are numeric integers, not categorical variables. Many of these will have to be changed. We’ll get to that in a moment.\nJust check the data type of one variable\n\ntypeof(depress$marital)\n\n[1] \"integer\"\n\nclass(depress$age)\n\n[1] \"integer\"",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#convert-number-to-factor",
    "href": "dataprep.html#convert-number-to-factor",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.6 Convert number to factor",
    "text": "1.6 Convert number to factor\nWhen variables have numerical levels it is necessary to ensure that the program knows it is a factor variable.\nThe following code uses the factor() function to take the marital status variable and convert it into a factor variable with specified labels that match the codebook.\n\ndepress$marital &lt;- factor(depress$marital, \n      labels = c(\"Never Married\", \"Married\", \"Divorced\", \"Separated\", \"Widowed\"))\n\nIt is important to confirm the recode worked. If it did not you will have to re-read in the raw data set again since the variable marital was replaced.\n\ntable(depress$marital)\n\n\nNever Married       Married      Divorced     Separated       Widowed \n           73           127            43            13            38 \n\nclass(depress$marital)\n\n[1] \"factor\"\n\n\nSee more examples on Math 130 Lesson 06",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#identifying-outliers",
    "href": "dataprep.html#identifying-outliers",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.7 Identifying Outliers",
    "text": "1.7 Identifying Outliers\nLet’s look at the age variable in the depression data set.\n\npar(mfrow=c(1,2))\nboxplot(depress$age)\nhist(depress$age)\n\n\n\n\n\n\n\n\nJust looking at the data graphically raises no red flags. The boxplot shows no outlying values and the histogram does not look wildly skewed. This is where knowledge about the data set is essential. The codebook does not provide a valid range for the data, but the description of the data starting on page 3 in the textbook clarifies that this data set is on adults. In the research world, this specifies 18 years or older.\nNow look back at the graphics. See anything odd? It appears as if the data go pretty far below 20, possibly below 18. Let’s check the numerical summary to get more details.\n\nsummary(depress$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   28.00   42.50   44.38   59.00   89.00 \n\n\nThe minimum value is a 9, which is outside the range of valid values for this variable. This is where you, as a statistician, data analyst or researcher goes back to the PI and asks for advice. Should this data be set to missing, or edited in a way that changes this data point into a valid piece of data.\nAnother example\n\nboxplot(depress$income)\n\n\n\n\n\n\n\n\nWhile there is at least one potential outliers (denoted by the dots), there are none so far away from the rest of the group (or at values such as 99 or -99 that may indicate missing codes) that we need to be concerned about.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#changing-numeric-values",
    "href": "dataprep.html#changing-numeric-values",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.8 Changing numeric values",
    "text": "1.8 Changing numeric values\nAs an example of a common data entry error, and for demonstration purposes, I went in and changed a 19 to a 9. So the correct thing to do here is to change that 9, back to a 19. This is a very good use of the ifelse() function.\n\ndepress$age &lt;- ifelse(depress$age==9, 19, depress$age)\n\nThe logical statement is depress$age9. Wherever this is true, replace the value of depress$age with 19, wherever this is false then keep the value of depress$age unchanged (by “replacing” the new value with the same old value).\nAlternatively, you can change that one value using bracket notation. Here you are specifying that you only want the rows where age==9, and directly assign a value of 19 to those rows.\n\ndepress$age[depress$age==9] &lt;- 19\n\nConfirm the recode.\n\nsummary(depress$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   28.00   42.50   44.41   59.00   89.00 \n\n\nLooks like it worked.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#creating-secondary-variables",
    "href": "dataprep.html#creating-secondary-variables",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.9 Creating secondary variables",
    "text": "1.9 Creating secondary variables\nSee Math 130 lesson 05 for now.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#wrangling-factors",
    "href": "dataprep.html#wrangling-factors",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.10 Wrangling Factors",
    "text": "1.10 Wrangling Factors\nFor more help on renaming, releveling, lumping, and removing levels see Math 130 lesson 06 for now. Also the forcats vignette.\n\n1.10.1 Collapsing categorical variables into fewer categories\nFor unbiased and accurate results of a statistical analysis, sufficient data has to be present. Often times once you start slicing and dicing the data to only look at certain groups, or if you are interested in the behavior of certain variables across levels of another variable, sometimes you start to run into small sample size problems.\nFor example, consider marital status again. There are only 13 people who report being separated. This could potentially be too small of a group size for valid statistical analysis. One way to deal with insufficient data within a certain category is to collapse categories. The following code uses the recode() function from the car package to create a new variable that I am calling marital2 that combines the Divorced and Separated levels.\n\n⚠️ Note: See Math 130 lesson 06 for a better method using forcats\n\n\nlibrary(car)\nmarital2 &lt;- recode(depress$marital, \"'Divorced' = 'Sep/Div'; 'Separated' = 'Sep/Div'\")\n\nAlways confirm your recodes. Check a table of the old variable (marital) against the new one marital2.\n\ntable(depress$marital, marital2, useNA=\"always\")\n\n               marital2\n                Married Never Married Sep/Div Widowed &lt;NA&gt;\n  Never Married       0            73       0       0    0\n  Married           127             0       0       0    0\n  Divorced            0             0      43       0    0\n  Separated           0             0      13       0    0\n  Widowed             0             0       0      38    0\n  &lt;NA&gt;                0             0       0       0    0\n\n\nThis confirms that records where marital (rows) is Divorced or Separated have the value of Sep/Div for marital2 (columns). And that no missing data crept up in the process. Now I can drop the temporary marital2 variable and actually fix marital. (keeping it clean)\n\ndepress$marital &lt;- recode(depress$marital, \"'Divorced' = 'Sep/Div'; 'Separated' = 'Sep/Div'\")\nrm(marital2)",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#binning-a-continuous-variable-into-categorical-ranges.",
    "href": "dataprep.html#binning-a-continuous-variable-into-categorical-ranges.",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.11 Binning a continuous variable into categorical ranges.",
    "text": "1.11 Binning a continuous variable into categorical ranges.\nWe can use the cut function to create a new variable that categorizes income into the following ranges: &lt;30, [30, 40), [40,50), [50, 60), 60+.\n\ndepress$inc_cut &lt;- cut(depress$income, breaks=c(0, 30,40,50,60, 100))\ntable(depress$inc_cut)\n\n\n  (0,30]  (30,40]  (40,50]  (50,60] (60,100] \n     231       28       16        9       10",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#dichotomizing-a-measure-into-2-categories",
    "href": "dataprep.html#dichotomizing-a-measure-into-2-categories",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.12 Dichotomizing a measure into 2 categories",
    "text": "1.12 Dichotomizing a measure into 2 categories\nDichotomous variables tend to be binary indicator variables where a code of 1 is the level you’re interested in.\nFor example, in this study gender is coded as 2=Female and 1=Male. (This data was collected in the ’70s, and so only two genders were provided as options). We want to convert this 1=Female and 0=Male.\n\ndepress$sex &lt;- depress$sex -1 \ntable(depress$sex)\n\n\n  0   1 \n111 183 \n\n\n0/1 binary coding is mandatory for many analyses. One simple reason is that now you can calculate the mean and interpret it as a proportion.\n\nmean(depress$sex)\n\n[1] 0.622449\n\n\n62% of individuals in this data set are female.\nSometimes the data is recorded as 1/2 (Yes/No), so just subtracting from 1 doesn’t create a positive indicator of the variable. For example, drink=1 if they are a regular drinker, and drink=2 if they are not. We want not drinking to be coded as 0, not 2.\n\ntable(depress$drink)\n\n\n  1   2 \n234  60 \n\n\nThe ifelse() function says that if depress$DRINK has a value equal to 2 ==2, then change the value to 0. Otherwise leave it alone.\n\ndepress$drink &lt;- ifelse(depress$drink==2, 0, depress$drink)\ntable(depress$drink)\n\n\n  0   1 \n 60 234",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#sum-or-average-values-across-multiple-variables",
    "href": "dataprep.html#sum-or-average-values-across-multiple-variables",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.13 Sum or Average values across multiple variables",
    "text": "1.13 Sum or Average values across multiple variables\nThe Center for Epidemiological Studies Depression Scale (CESD) is series of questions asked to a person to measure their level of depression. CESD is calculated as the sum of all 20 component variables, and is already on this data set. Let’s create a new variable named sleep as subscale for sleep quality by adding up question numbers 5, 11, and 19.\nReference: http://cesd-r.com/cesdr/\n\ndepress$sleep &lt;- depress$c5 + depress$c11 + depress$c19\n## # depress &lt;- depress %&gt;% mutate(sleep = c5+c11+c19) # Not run. dplyr example\n## # depress &lt;- depress %&gt;% mutate(across(c(c5, c11, c19), mean)) # Not run, across() example\n\n\nsummary(depress$sleep)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   1.000   1.167   2.000   7.000",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#transformations-for-normality",
    "href": "dataprep.html#transformations-for-normality",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.14 Transformations for Normality",
    "text": "1.14 Transformations for Normality\nLet’s look at assessing normal distributions using the cleaned depression data set.\n\nhist(depress$income, prob=TRUE, xlab=\"Annual income (in thousands)\", \n     main=\"Histogram and Density curve of Income\", ylab=\"\")\nlines(density(depress$income), col=\"blue\")\n\n\n\n\n\n\n\nsummary(depress$income)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.00    9.00   15.00   20.57   28.00   65.00 \n\n\nThe distribution of annual income is slightly skewed right with a mean of $20.5k per year and a median of $15k per year income. The range of values goes from $2k to $65k. Reported income above $40k appear to have been rounded to the nearest $10k, because there are noticeable peaks at $40k, $50k, and $60k.\nIn general, transformations are more effective when the the standard deviation is large relative to the mean. One rule of thumb is if the sd/mean ratio is less than 1/4, a transformation may not be necessary.\n\nsd(depress$income) / mean(depress$income)\n\n[1] 0.743147\n\n\nAlternatively Hoaglin, Mosteller and Tukey (1985) showed that if the largest observation divided by the smallest observation is over 2, then the data may not be sufficiently variable for the transformation to be decisive.\n\nmax(depress$income) / (min(depress$income)+.1)\n\n[1] 30.95238\n\n\nNote these rules are not meaningful for data without a natural zero.\nAnother common method of assessing normality is to create a normal probability (or normal quantile) plot.\n\nqqnorm(depress$income);qqline(depress$income, col=\"red\")\n\n\n\n\n\n\n\n\nThe points on the normal probability plot do not follow the red reference line very well. The dots show a more curved, or U shaped form rather than following a linear line. This is another indication that the data is skewed and a transformation for normality should be created.\n\nCreate three new variables: log10inc as the log base 10 of Income, loginc as the natural log of Income, and xincome which is equal to the negative of one divided by the cubic root of income.\n\n\nlog10inc &lt;- log10(depress$income)\nloginc   &lt;- log(depress$income)\nxincome  &lt;- -1/(depress$income)^(-1/3)\n\n\nCreate a single plot that display normal probability plots for the original, and each of the three transformations of income. Use the base graphics grid organizer par(mfrow=c(r,c)) where r is the number of rows and c is the number of columns. Which transformation does a better job of normalizing the distribution of Income?\n\n\npar(mfrow=c(2,2)) # Try (4,1) and (1,4) to see how this works. \nqqnorm(depress$income, main=\"Income\"); qqline(depress$income,col=\"blue\")\nqqnorm(log10inc, main=\"Log 10\"); qqline(log10inc, col=\"blue\")\nqqnorm(loginc, main = \"Natural Log\"); qqline(loginc, col=\"blue\")\nqqnorm(xincome, main=\"-1/cuberoot(income)\"); qqline(xincome, col=\"blue\")",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#export-and-save",
    "href": "dataprep.html#export-and-save",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.15 Export and Save",
    "text": "1.15 Export and Save\nYou’ve just made a ton of changes!\n\nSave or export the new data set to your computer.\nEdit the codebook to reflect the changes that you made.\nKeep the data, codebook and data management file in the same folder.\n\n\ndepress_clean &lt;- depress %&gt;% select(var1, var2, var3)\n\n# Save as a .Rdata file for later use in R\nsave(depress_clean, \"data/depress_clean.Rdata\") \n\nNow every time you run your data cleaning script file, it will make all the changes and save/overwrite the depress_clean.Rdata data file. This ensures that any analysis script that uses this data has the most up to date varibles.\nNeed to export to a different software program? Look into the haven package.\nSPSS users commonly save cleaned data as a .sav format.\nSAVE outfile='FilePath\\depress_sysdate.sav'\n/KEEP = Variable_Name1 Variable_Name2.\nEXECUTE.\nSaving only selected variables\n\nIn SPSS the /KEEP statement demonstrated above only writes the variable names listed to the saved data set. This can be very useful when dealing with data sets with a large number of variables.\nFor R users, using dplyr select is generally the fastest.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#wide-long",
    "href": "dataprep.html#wide-long",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.16 Wide vs. Long data",
    "text": "1.16 Wide vs. Long data\nRead more on tidy data here: https://r4ds.hadley.nz/data-tidy\nThe data on Lung function originally was recorded in wide format, with separate variables for mother’s and father’s FEV1 score (MFEV1 and FFEV). In this format, the data is one record per family.\n\nfev &lt;- read.delim(here::here(\"data/Lung_081217.txt\"), \n                    sep=\"\\t\", header=TRUE)\nhead(fev)\n\n  ID AREA FSEX FAGE FHEIGHT FWEIGHT FFVC FFEV1 MSEX MAGE MHEIGHT MWEIGHT MFVC\n1  1    1    1   53      61     161  391  3.23    2   43      62     136  370\n2  2    1    1   40      72     198  441  3.95    2   38      66     160  411\n3  3    1    1   26      69     210  445  3.47    2   27      59     114  309\n4  4    1    1   34      68     187  433  3.74    2   36      58     123  265\n5  5    1    1   46      61     121  354  2.90    2   39      62     128  245\n6  6    1    1   44      72     153  610  4.91    2   36      66     125  349\n  MFEV1 OCSEX OCAGE OCHEIGHT OCWEIGHT OCFVC OCFEV1 MCSEX MCAGE MCHEIGHT\n1  3.31     2    12       59      115   296   2.79    NA    NA       NA\n2  3.47     1    10       56       66   323   2.39    NA    NA       NA\n3  2.65     1     8       50       59   114   1.11    NA    NA       NA\n4  2.06     2    11       57      106   256   1.85     1     9       49\n5  2.33     1    16       61       88   260   2.47     2    12       60\n6  3.06     1    15       67      100   389   3.55     1    13       57\n  MCWEIGHT MCFVC MCFEV1 YCSEX YCAGE YCHEIGHT YCWEIGHT YCFVC YCFEV1\n1       NA    NA     NA    NA    NA       NA       NA    NA     NA\n2       NA    NA     NA    NA    NA       NA       NA    NA     NA\n3       NA    NA     NA    NA    NA       NA       NA    NA     NA\n4       56   159   1.30    NA    NA       NA       NA    NA     NA\n5       85   268   2.34     2    10       50       53   154   1.43\n6       87   276   2.37     2    10       55       72   195   1.69\n\n\nTo analyze the effect of gender on FEV, the data need to be in long format, with a single variable for fev and a separate variable for gender. The following code chunk demonstrates one method of combining data on height, gender, age and FEV1 for both males and females.\n\nfev2 &lt;- data.frame(gender = c(fev$FSEX, fev$MSEX), \n                   rev = c(fev$FFEV1, fev$MFEV1), \n                   ht = c(fev$FHEIGHT, fev$MHEIGHT), \n                   age = c(fev$FAGE, fev$MAGE))\nfev2$gender &lt;- factor(fev2$gender, labels=c(\"M\", \"F\"))\nhead(fev2)  \n\n  gender  rev ht age\n1      M 3.23 61  53\n2      M 3.95 72  40\n3      M 3.47 69  26\n4      M 3.74 68  34\n5      M 2.90 61  46\n6      M 4.91 72  44\n\n\nNearly all analysis procedures and most graphing procedures require the data to be in long format. There are several R packages that can help with this including reshape2 and tidyr.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "dataprep.html#missing-data",
    "href": "dataprep.html#missing-data",
    "title": "1  Workflow and Data Cleaning",
    "section": "1.17 Missing data",
    "text": "1.17 Missing data\n\n1.17.1 Identifying missing data\nIn Excel, missing data can show up as a blank cell. In SPSS it is represented as a . period. R displays missing data as NA values.\nMissing Data in SPSS: https://stats.idre.ucla.edu/spss/modules/missing-data/\nWhy would data be missing? Other than the obvious data entry errors, tech glitches or just non-cooperative plants or people, sometimes values are out of range and you would rather delete them than change their value (data edit).\nLets look at the religion variable in the depression data set.\n\ntable(depress$relig, useNA=\"always\")\n\n\n   1    2    3    4    6 &lt;NA&gt; \n 155   51   30   56    2    0 \n\n\nLooking at the codebook, there is no category 6 for religion. Let’s change all values to NA.\n\ndepress$relig[depress$relig==6] &lt;- NA\n\nThis code says take all rows where relig is equal to 6, and change them to NA.\nConfirm recode.\n\ntable(depress$relig, useNA=\"always\")\n\n\n   1    2    3    4 &lt;NA&gt; \n 155   51   30   56    2 \n\n\nNotice the use of the useNA=\"always\" argument. If we just looked at the base table without this argument, we would have never known there was missing data!\n\ntable(depress$relig)\n\n\n  1   2   3   4 \n155  51  30  56 \n\n\nWhat about continuous variables? Well there happens to be no other missing data in this data set, so let’s make up a set of 7 data points stored in a variable named y.\n\ny &lt;- c(1, 2, 3, NA, 4, NA, 6)\ny\n\n[1]  1  2  3 NA  4 NA  6\n\n\nThe #1 way to identify missing data in a continuous variable is by looking at the summary() values.\n\nmean(y)\n\n[1] NA\n\nsummary(y)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n    1.0     2.0     3.0     3.2     4.0     6.0       2 \n\nmean(y, na.rm=TRUE)\n\n[1] 3.2\n\n\nIn R, any arithmetic function (like addition, multiplication) on missing data results in a missing value. The na.rm=TRUE toggle tells R to calculate the complete case mean. This is a biased measure of the mean, but missing data is a topic worthy of it’s own course and is introduced in Chapter @ref(mda).\n\n\n1.17.2 Model predictions\nSituation: You want to add model predictions to the data set, but you have missing data that was automatically dropped prior to analysis.\n\n\n1.17.3 Regression\nR objects created by methods such as lm and glm will store the data used in the model in the model object itself in model$data. See Chapter @ref(binary-classification) for an example.\n\n\n1.17.4 Factor Analysis and Principle Components\nIf your original data had missing values, here is one way to get the PC’s / factor scores for available data back onto the data set.\nMethod 1) Create an ID column and merge new variables onto original data. (add columns)\n\nIf no ID column exists, create one on the original dataset id = 1:NROW(data)\nUse select() to extract the ID and all variables used in the factor analysis, then do a na.omit() to drop rows with any missing data. Save this as a new complete case data set.\nConduct PCA / Factor analysis on this new complete case data set (MINUS THE ID). Extract the PCs or factor scores.\nUse bind_cols() to add the ID variable to the data containing factor scores.\nThen left_join(original_data, factor_score_data) the factor scores back to the original data, using the ID variable as the joining key.\n\nMethod 2) Split the data, analyze one part then concatenate back together. (add rows)\n\nUse the complete.cases() function to create a boolean vector for if each row is complete\nSplit the data into complete and incomplete.\nDo the analysis on the complete rows, extracting the PC’s/Factors\nAdd the PC/Factor data onto the complete rows using bind_cols\nThen bind_rows the two parts back together.\n\n\ncc.idx &lt;- hiv %&gt;% select(starts_with(\"pb\")) %&gt;% complete.cases() # 1\n\ncomplete.rows &lt;- hiv[cc.idx,] #2\nincomplete.rows &lt;- hiv[!cc.idx,]\n\npc.scores &lt;- princomp(pb)$scores #3 \n\ncomplete.add.pc &lt;- bind_cols(complete.rows, pc.scores) #4\n\nhiv.with.pcs &lt;- bind_rows(complete.add.pc, incomplete.rows) #5",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workflow and Data Cleaning</span>"
    ]
  },
  {
    "objectID": "data_viz.html",
    "href": "data_viz.html",
    "title": "2  Visualizing Data",
    "section": "",
    "text": "2.1 The syntax of ggplot\nThe reason we use the functions in ggplot2 is for consistency in the structure of it’s arguments. Here is a bare bones generic plotting function:\nggplot(data, aes(x=x, y=y, col=col, fill=fill, group=group)) +  geom_THING()",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#the-syntax-of-ggplot",
    "href": "data_viz.html#the-syntax-of-ggplot",
    "title": "2  Visualizing Data",
    "section": "",
    "text": "2.1.1 Required arguments\n\ndata: What data set is this plot using? This is ALWAYS the first argument.\naes(): This is the aestetics of the plot. What’s variable is on the x, what is on the y? Do you want to color by another variable, perhaps fill some box by the value of another variable, or group by a variable.\ngeom_THING(): Every plot has to have a geometry. What is the shape of the thing you want to plot? Do you want to plot points - use geom_points(). Want to connect those points with a line? Use geom_lines(). We will see many varieties in this lab.\n\n\n\n2.1.2 Optional but helpful arguments\n\nggtitle: This is the overall plot title\nxlab() and ylab() axis titles.\nscale_xy_blah to extend limits\nscale_fill_blah to specifying a fixed color, and change auto legend title\nthemes\n\nFor a full , and comprehensive tutorial and reference guide on how to do nearly anything in ggplot – this is by far my favorite reference http://www.cookbook-r.com/Graphs/ I reference things in there (like how to remove or change the title of a legend) constantly.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#the-data",
    "href": "data_viz.html#the-data",
    "title": "2  Visualizing Data",
    "section": "2.2 The Data",
    "text": "2.2 The Data\nWe will use a subset of the diamonds dataset that comes with the ggplot2 package. This dataset contains the prices and other attributes of almost 54,000 diamonds. Review ?diamonds to learn about the variables we will be using.\n\nlibrary(ggplot2)\ndata(\"diamonds\")\nset.seed(1410) # Make the sample reproducible\ndsmall &lt;- diamonds[sample(nrow(diamonds), 1000), ]",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#univariate-visualizations",
    "href": "data_viz.html#univariate-visualizations",
    "title": "2  Visualizing Data",
    "section": "2.3 Univariate Visualizations",
    "text": "2.3 Univariate Visualizations\n\n2.3.1 Categorical variables\nBoth Nominal and Ordinal data types can be visualized using the same methods: tables, barcharts and pie charts.\n\n2.3.1.1 Tables\nTables are the most common way to get summary statistics of a categorical variable. The table() function produces a frequency table, where each entry represents the number of records in the data set holding the corresponding labeled value.\n\ntable(dsmall$cut)\n\n\n     Fair      Good Very Good   Premium     Ideal \n       34        99       220       257       390 \n\n\nThere are 27 Fair quality diamonds, 83 good quality and 387 Ideal quality diamonds in this sample.\n\n\n2.3.1.2 Barcharts / Barplots\nA Barchart or barplot takes these frequencies, and draws bars along the X-axis where the height of the bars is determined by the frequencies seen in the table.\nbase To create a barplot/barchart in base graphics requires the data to be in summarized in a table form first. Then the result of the table is plotted. The first argument is the table to be plotted, the main argument controls the title.\n\ndc &lt;- table(dsmall$cut)\nbarplot(dc, main=\"Barchart using base graphics\")\n\n\n\n\n\n\n\n\nggplot The geometry needed to draw a barchart in ggplot is geom_bar().\n\nggplot(dsmall, aes(x=cut)) + geom_bar()\n\n\n\n\n\n\n\n\npretty The biggest addition to a barchart is the numbers on top of the bars. This isn’t mandatory, but it does make it nice.\n\nggplot(dsmall, aes(x=cut)) + theme_bw() + \n    geom_bar(aes(y = ..count..)) + ggtitle(\"Frequnency of diamonds by cut type\") + \n    geom_text(aes(y=..count.. + 10, label=..count..), stat='count', size = 5)\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\n\n\n2.3.1.3 Plotting Proportions\nOften you don’t want to compare counts but percents. To accomplish this, we have to aggregate the data to calculate the proportions first, then plot the aggregated data using geom_col to create the columns.\n\ncut.props &lt;- data.frame(prop.table(table(dsmall$cut)))\ncut.props # what does this data look like? \n\n       Var1  Freq\n1      Fair 0.034\n2      Good 0.099\n3 Very Good 0.220\n4   Premium 0.257\n5     Ideal 0.390\n\nggplot(cut.props, aes(x=Var1, y=Freq)) + geom_col() + \n  ylab(\"Proportion\") + xlab(\"Cut type\") + \n  ggtitle(\"Proportion of diamonds by cut type\")\n\n\n\n\n\n\n\n\n\n\n2.3.1.4 Cleveland Dot Plots\nAnother way to visualize categorical data that takes up less ink than bars is a Cleveland dot plot. Here again we are plotting summary data instead of the raw data. This uses the geom_segment that draws the lines from x=0 to the value of the proportion (named Freq because of the way data.frame works).\n\nggplot(cut.props, aes(x=Freq, y=Var1)) +  \n  geom_point(size = 3) + xlab(\"Proportion of diamonds\") + \n  theme_bw() + ylab(\"Cut Type\") +\n  geom_segment(aes(x=0, xend=Freq, y=Var1, yend=Var1), color='grey50')\n\n\n\n\n\n\n\n\n\n\n2.3.1.5 Pie Chart\nJust like barplot(), pie() takes a table object as it’s argument.\nbase\n\ndc &lt;- table(dsmall$cut)\npie(dc)\n\n\n\n\n\n\n\n\nPie charts are my least favorite plotting type. Human eyeballs can’t distinguish between angles as well as we can with heights. A mandatory piece needed to make the wedges readable is to add the percentages of each wedge.\n\npie(dc, labels = paste0(names(dc), ' (', prop.table(dc)*100, \"%)\"))\n\n\n\n\n\n\n\n\nggplot\nAnd here I thought pie charts couldn’t get worse… i’m not a fan at all of the ggplot version. So i’m not even going to show it. Here’s a link to another great tutorial that does show you how to make one.\nhttp://www.sthda.com/english/wiki/ggplot2-pie-chart-quick-start-guide-r-software-and-data-visualization\nHowever – Never say never. Here’s an example of a good use of pie charts. http://www.storytellingwithdata.com/blog/2019/8/8/forty-five-pie-charts-never-say-never\n\n\n2.3.1.6 Waffle Chart\nThis type of chart is not natively found in the ggplot2 package, but it’s own waffle package. These are great for infographics.\nReference: https://www.r-bloggers.com/making-waffle-charts-in-r-with-the-new-waffle-package/\n\nlibrary(waffle)\n\nwaffle(dc/10, rows=5, size=0.5, \n       title=\"Cut quality of diamond\", \n       xlab=\"1 square == 10 diamonds\")\n\n\n\n\n\n\n\n\n\n\n\n2.3.2 Continuous Measures\nHere we can look at the price, carat, and depth of the diamonds.\n\n2.3.2.1 Dotplot\n\nplot(dsmall$depth)\n\n\n\n\n\n\n\n\nThe base function plot() creates a dotplot for a continuous variable. The value of the variable is plotted on the y axis, and the index, or row number, is plotted on the x axis. This gives you a nice, quick way to see the values of the data.\nOften you are not interested in the individual values of each data point, but the distribution of the data. In other words, where is the majority of the data? Does it look symmetric around some central point? Around what values do the bulk of the data lie?\n\n\n2.3.2.2 Histograms\nRather than showing the value of each observation, we prefer to think of the value as belonging to a . The height of the bars in a histogram display the frequency of values that fall into those of those bins. For example if we cut the poverty rates into 7 bins of equal width, the frequency table would look like this:\n\ntable(cut(dsmall$depth, 7))\n\n\n(55.3,57.6] (57.6,59.8] (59.8,62.1] (62.1,64.4] (64.4,66.7] (66.7,68.9] \n          6          79         536         351          23           3 \n(68.9,71.2] \n          2 \n\n\nIn a histogram, the binned counts are plotted as bars into a histogram. Note that the x-axis is continuous, so the bars touch. This is unlike the barchart that has a categorical x-axis, and vertical bars that are separated.\nbase You can make a histogram in base graphics super easy.\n\nhist(dsmall$depth)\n\n\n\n\n\n\n\n\nAnd it doesn’t take too much to clean it up. Here you can specify the number of bins by specifying how many breaks should be made in the data (the number of breaks controls the number of bins, and bin width) and use col for the fill color.\n\nhist(dsmall$depth, xlab=\"depth\", main=\"Histogram of diamond depth\", col=\"cyan\", breaks=20)\n\n\n\n\n\n\n\n\nggplot\n\nggplot(dsmall, aes(x=depth)) + geom_histogram(binwidth = 2.2)\n\n\n\n\n\n\n\n\nThe binwidth here is set by looking at the cut points above that were used to create 7 bins. Notice that darkgrey is the default fill color, but makes it hard to differentiate between the bars. So we’ll make the outline black using colour, and fill the bars with white.\n\nggplot(dsmall, aes(x=depth)) + geom_histogram(colour=\"black\", fill=\"white\") + \n  ggtitle(\"Distribution of diamond depth\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNote I did not specify the binwidth argument here. The size of the bins can hide features from your graph, the default value for ggplot2 is range/30 and usually is a good choice.\n\n\n2.3.2.3 Density plots\nTo get a better idea of the true shape of the distribution we can “smooth” out the bins and create what’s called a density plot or curve. Notice that the shape of this distribution curve is much more… “wigglier” than the histogram may have implied.\nbase\n\nplot(density(dsmall$depth))\n\n\n\n\n\n\n\n\nAwesome title huh? (NOT)\nggplot2\n\nggplot(dsmall, aes(x=depth)) + geom_density()\n\n\n\n\n\n\n\n\n\n\n2.3.2.4 Histograms + density\nOften is is more helpful to have the density (or kernel density) plot on top of a histogram plot.\nBase Since the height of the bars in a histogram default to showing the frequency of records in the data set within that bin, we need to 1) scale the height so that it’s a relative frequency, and then use the lines() function to add a density() line on top.\n\nhist(dsmall$depth, prob=TRUE)\nlines(density(dsmall$depth), col=\"blue\")\n\n\n\n\n\n\n\n\nggplot The syntax starts the same, we’ll add a new geom, geom_density and color the line blue. Then we add the histogram geom using geom_histogram but must specify that the y axis should be on the density, not frequency, scale. Note that this has to go inside the aesthetic statement aes(). I’m also going to get rid of the fill by using NA so it doesn’t plot over the density line.\n\nggplot(dsmall, aes(x=depth)) + geom_density(col=\"blue\") + \n  geom_histogram(aes(y=..density..), colour=\"black\", fill=NA)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n2.3.2.5 Boxplots\nAnother very common way to visualize the distribution of a continuous variable is using a boxplot. Boxplots are useful for quickly identifying where the bulk of your data lie. R specifically draws a “modified” boxplot where values that are considered outliers are plotted as dots.\nbase\n\nboxplot(dsmall$depth)\n\n\n\n\n\n\n\n\nNotice that the only axis labeled is the y=axis. Like a dotplot the x axis, or “width”, of the boxplot is meaningless here. We can make the axis more readable by flipping the plot on it’s side.\n\nboxplot(dsmall$depth, horizontal = TRUE, main=\"Distribution of diamond prices\", xlab=\"Dollars\")\n\n\n\n\n\n\n\n\nHorizontal is a bit easier to read in my opinion.\nggplot What about ggplot? ggplot doesn’t really like to do univariate boxplots. We can get around that by specifying that we want the box placed at a specific x value.\n\nggplot(dsmall, aes(x=1, y=depth)) + geom_boxplot()\n\n\n\n\n\n\n\n\nTo flip it horizontal you may think to simply swap x and y? Good thinking. Of course it wouldn’t be that easy. So let’s just flip the whole darned plot on it’s coordinate axis.\n\nggplot(dsmall, aes(x=1, y=depth)) + geom_boxplot() + coord_flip()\n\n\n\n\n\n\n\n\n\n\n2.3.2.6 Violin plots\n\nggplot(dsmall, aes(x=1, y=depth)) + geom_violin()\n\n\n\n\n\n\n\n\n\n\n2.3.2.7 Boxplot + Violin plots\nOverlaying a boxplot and a violin plot serves a similar purpose to Histograms + Density plots.\n\nggplot(dsmall, aes(x=1, y=depth)) + geom_violin() + geom_boxplot()\n\n\n\n\n\n\n\n\nBetter appearance - different levels of transparency of the box and violin.\n\nggplot(dsmall, aes(x=1, y=depth)) + xlab(\"\") + theme_bw() + \n              geom_violin(fill=\"blue\", alpha=.1) + \n              geom_boxplot(fill=\"blue\", alpha=.5, width=.2) + \n              theme(axis.title.x=element_blank(),\n              axis.text.x=element_blank(),\n              axis.ticks.x=element_blank())\n\n\n\n\n\n\n\n\n\n\n2.3.2.8 Normal QQ plots\nThe last useful plot that we will do on a single continuous variable is to assess the normality of the distribution. Basically how close the data follows a normal distribution.\nbase\n\nqqnorm(dsmall$price)\nqqline(dsmall$price, col=\"red\")\n\n\n\n\n\n\n\n\nThe line I make red because it is a reference line. The closer the points are to following this line, the more “normal” the shape of the distribution is. Price has some pretty strong deviation away from that line. Below I have plotted what a normal distribution looks like as an example of a “perfect” fit.\n\nz &lt;- rnorm(1000)\nqqnorm(z)\nqqline(z, col=\"blue\")\n\n\n\n\n\n\n\n\nggplot qq (or qnorm) plots specifically plot the data against a theoretical distribution. That means in the aes() aesthetic argument we don’t specify either x or y, but instead the sample= is the variable we want to plot.\n\nggplot(dsmall, aes(sample=price)) + stat_qq()\n\n\n\n\n\n\n\n\nAdditional references on making qqplots in ggplot: http://www.sthda.com/english/wiki/ggplot2-qq-plot-quantile-quantile-graph-quick-start-guide-r-software-and-data-visualization",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#bivariate-visualizations",
    "href": "data_viz.html#bivariate-visualizations",
    "title": "2  Visualizing Data",
    "section": "2.4 Bivariate Visualizations",
    "text": "2.4 Bivariate Visualizations\n\n2.4.1 Categorical v. Categorical\n\n2.4.1.1 Two-way Frequency tables\nCross-tabs, cross-tabulations and two-way tables (all the same thing, different names) can be created by using the table() function.\nThe frequency table is constructed using the table() function.\n\ntable(dsmall$cut, dsmall$color)\n\n           \n             D  E  F  G  H  I  J\n  Fair       5  6  7  4  5  4  3\n  Good      18 23 11 16 17  7  7\n  Very Good 26 37 46 40 33 25 13\n  Premium   34 53 43 49 41 24 13\n  Ideal     54 63 79 92 53 34 15\n\n\nThere are 4 Fair diamonds with color D, and 21 Ideal quality diamonds with color J.\n\n\n2.4.1.2 Two-way Proprtion tables\nChoose your percentages depending on your research question. What are you wanting to compare?\nBest practices:\n\nExplanatory variable on the rows\nResponse variable on the columns\nCalculate row %’s as the % of the response for each explanatory group.\n\nHere are demonstrations of how the interpretation of the percents change depending on what the denominator is.\nCell proportions\nWrapping prop.table() around a table gives you the cell proportions.\n\nprop.table(table(dsmall$cut, dsmall$color))\n\n           \n                D     E     F     G     H     I     J\n  Fair      0.005 0.006 0.007 0.004 0.005 0.004 0.003\n  Good      0.018 0.023 0.011 0.016 0.017 0.007 0.007\n  Very Good 0.026 0.037 0.046 0.040 0.033 0.025 0.013\n  Premium   0.034 0.053 0.043 0.049 0.041 0.024 0.013\n  Ideal     0.054 0.063 0.079 0.092 0.053 0.034 0.015\n\n\n0.4% of all diamonds are D color and Fair cut, 2.1% are J color and Ideal cut.\nRow proportions\nTo get the row proportions, you specify margin=1. The percentages now add up to 1 across the rows.\n\nround(prop.table(table(dsmall$cut, dsmall$color), margin=1),3)\n\n           \n                D     E     F     G     H     I     J\n  Fair      0.147 0.176 0.206 0.118 0.147 0.118 0.088\n  Good      0.182 0.232 0.111 0.162 0.172 0.071 0.071\n  Very Good 0.118 0.168 0.209 0.182 0.150 0.114 0.059\n  Premium   0.132 0.206 0.167 0.191 0.160 0.093 0.051\n  Ideal     0.138 0.162 0.203 0.236 0.136 0.087 0.038\n\n\n14.8% of all Fair quality diamonds are color D. 5.4% of all Ideal quality diamonds have color J.\nColumn proportions\nTo get the column proportions, you specify margin=2. The percentages now add up to 1 down the columns.\n\nround(prop.table(table(dsmall$cut, dsmall$color), margin=2),3)\n\n           \n                D     E     F     G     H     I     J\n  Fair      0.036 0.033 0.038 0.020 0.034 0.043 0.059\n  Good      0.131 0.126 0.059 0.080 0.114 0.074 0.137\n  Very Good 0.190 0.203 0.247 0.199 0.221 0.266 0.255\n  Premium   0.248 0.291 0.231 0.244 0.275 0.255 0.255\n  Ideal     0.394 0.346 0.425 0.458 0.356 0.362 0.294\n\n\n2.7% of all D color diamonds are of Fair quality. 44.7% of all J color diamonds are of Ideal quality.\n\n\n2.4.1.3 Grouped bar charts\nTo compare proportions of one categorical variable within the same level of another, is to use grouped barcharts.\nbase As before, the object to be plotted needs to be the result of a table.\n\ncc &lt;- table(dsmall$cut, dsmall$color)\nbarplot(cc)\n\n\n\n\n\n\n\n\nStacked bars can be difficult to interpret, and very difficult to compare values between groups. A side by side barchart is preferable. The beside=TRUE is what controls the placement of the bars.\n\nbarplot(cc, main=\"quick side by side barchart using base graphics\", beside=TRUE)\n\n\n\n\n\n\n\n\nggplot Again plot the cut on the x axis, but then fill using the second categorical variable. This has the effect of visualizing the row percents from the table above. The percent of color, within each type of cut.\n\nggplot(dsmall, aes(x=cut, fill=color)) + geom_bar()\n\n\n\n\n\n\n\n\nAgain the default is a stacked barchart. So we just specify position=dodge to put the bars side by side.\n\nggplot(dsmall, aes(x=cut, fill=color)) + geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nAnd look, an automatic legend. What if I wanted to better compare cut within color group? This is the column percentages. Just switch which variable is the x axis and which one is used to fill the colors!\n\nggplot(dsmall, aes(x=color, fill=cut)) + geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nFor more than 2 colors I do not recommend choosing the colors yourself. I know little about color theory so I use the built-in color palettes. Here is a great cheatsheet about using color palettes.\nAnd this easy change is why we love ggplot2.\n\n\n\n2.4.2 Grouped bar charts with percentages\nNot as easy as one would hope, but the solution is to calculate the desired percentages first and then plot the summary data using either geom_bar(stat='identity') or geom_col().\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ncalc.props &lt;- diamonds %&gt;% group_by(color, cut) %&gt;%\n              summarise(count=n()) %&gt;%\n              mutate(pct=round(count/sum(count),3))\n\n`summarise()` has grouped output by 'color'. You can override using the\n`.groups` argument.\n\ncalc.props\n\n# A tibble: 35 × 4\n# Groups:   color [7]\n   color cut       count   pct\n   &lt;ord&gt; &lt;ord&gt;     &lt;int&gt; &lt;dbl&gt;\n 1 D     Fair        163 0.024\n 2 D     Good        662 0.098\n 3 D     Very Good  1513 0.223\n 4 D     Premium    1603 0.237\n 5 D     Ideal      2834 0.418\n 6 E     Fair        224 0.023\n 7 E     Good        933 0.095\n 8 E     Very Good  2400 0.245\n 9 E     Premium    2337 0.239\n10 E     Ideal      3903 0.398\n# ℹ 25 more rows\n\n\nSince we’re plotting summary data, the height of the bars is specified using y=pct.\n\nggplot(calc.props, aes(x=color, fill=cut, y=pct)) +\n                  geom_col(position=\"dodge\") + theme_bw() \n\n\n\n\n\n\n\n\nNow set some options to the y axis using scale_y_continuous() to make the graph more accurate and readable. The labels=percent comes from the scales package.\n\nlibrary(scales)\nggplot(calc.props, aes(x=color, fill=cut, y=pct)) +\n                  geom_col(position=\"dodge\") + theme_bw() +\n                  scale_y_continuous(limits=c(0,1), labels=percent)\n\n\n\n\n\n\n\n\n\n2.4.2.1 sjPlot\nsjPlot does a very nice job of being able to cleanly show not only n’s but percents.\n\nlibrary(sjPlot)\n\nLearn more about sjPlot with 'browseVignettes(\"sjPlot\")'.\n\nplot_xtab(dsmall$color, dsmall$cut, margin=\"row\", coord.flip = TRUE) \n\n\n\n\n\n\n\n\n\n\n2.4.2.2 Mosaic plots\nBut what if you want to know how two categorical variables are related and you don’t want to look at two different barplots? Mosaic plots are a way to visualize the proportions in a table. So here’s the two-way table we’ll be plotting.\n\ntable(dsmall$cut, dsmall$color)\n\n           \n             D  E  F  G  H  I  J\n  Fair       5  6  7  4  5  4  3\n  Good      18 23 11 16 17  7  7\n  Very Good 26 37 46 40 33 25 13\n  Premium   34 53 43 49 41 24 13\n  Ideal     54 63 79 92 53 34 15\n\n\nThe syntax for a mosaic plot uses model notation, which is basically y ~ x where the ~ is read as “twiddle” or “tilde”. It’s to the left of your 1 key.\n\nmosaicplot(cut~color, data=dsmall)\n\n\n\n\n\n\n\n\nHelpful, ish. Here are two very useful options. In reverse obviousness, color applies shades of gray to one of the factor levels, and shade applies a color gradient scale to the cells in order of what is less than expected (red) to what is more than expected (blue) if these two factors were completely independent.\n\npar(mfrow=c(1,2)) # display the plots in 1 row and 2 columns\nmosaicplot(cut~color, data=dsmall, color=TRUE)\nmosaicplot(cut~color, data=dsmall, shade=TRUE)\n\n\n\n\n\n\n\n\nFor example, there are fewer ‘Very Good’ cut diamonds that are color ‘G’, and fewer ‘Premium’ cut diamonds that are color ‘H’. As you can see, knowing what your data means when trying to interpret what the plots are telling you is essential.\nThat’s about all the ways you can plot categorical variables. If you are wondering why there was no 3D barcharts demonstrated see\nhere, here, and here for other ways you can really screw up your visualization.\n\n\n\n2.4.3 Continuous v. Continuous\n\n2.4.3.1 Scatterplot\nThe most common method of visualizing the relationship between two continuous variables is by using a scatterplot.\nbase Back to the plot() command. Here we use model notation again, so it’s \\(y~x\\).\n\nplot(price~carat, data=dsmall)\n\n\n\n\n\n\n\n\nLooks like for the most part as the carat value increases so does price. That makes sense.\nggplot With ggplot we specify both the x and y variables, and add a point.\n\nggplot(dsmall, aes(x=carat, y=price)) + geom_point()\n\n\n\n\n\n\n\n\nOther Resources\n\nhttp://www.statmethods.net/graphs/scatterplot.html\n\nhttps://www.r-bloggers.com/scatterplot-matrices/\n\n\n\n2.4.3.2 Adding lines to the scatterplots\nTwo most common trend lines added to a scatterplots are the “best fit” straight line and the “lowess” smoother line.\nbase The best fit line (in blue) gets added by using the abline() function wrapped around the linear model function lm(). Note it uses the same model notation syntax and the data= statement as the plot() function does. The lowess line is added using the lines() function, but the lowess() function itself doesn’t allow for the data= statement so we have to use $ sign notation.\n\nplot(price~carat, data=dsmall)\nabline(lm(price~carat, data=dsmall), col=\"blue\")\nlines(lowess(dsmall$price~dsmall$carat), col=\"red\")\n\n\n\n\n\n\n\n\nggplot With ggplot, we just add a geom_smooth() layer.\n\nggplot(dsmall, aes(x=carat, y=price)) + geom_point() + geom_smooth() \n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nHere the point-wise confidence interval for this lowess line is shown in grey. If you want to turn the confidence interval off, use se=FALSE. Also notice that the smoothing geom uses a different function or window than the lowess function used in base graphics.\nHere it is again using the ggplot plotting function and adding another geom_smooth() layer for the lm (linear model) line in blue, and the lowess line (by not specifying a method) in red.\n\nggplot(dsmall, aes(x=carat, y=price)) + geom_point() + \n  geom_smooth(se=FALSE, method=\"lm\", color=\"blue\") + \n  geom_smooth(se=FALSE, color=\"red\")\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\n\n\n2.4.3.3 Line plots\nLine plots connect each dot with a straight line. This is most often done when measuring trends of the response as the value of x increases (such as a time series)\nWe saw earlier that carat and price seemed possibly linear. Let see how the average price changes with carat.\n\nlibrary(dplyr)\nprice.per.carat &lt;- dsmall %&gt;% group_by(carat) %&gt;% summarise(mean = mean(price))\n\nbase For base graphics, type=‘b’ means both points and lines, ‘l’ gives you just lines and ‘p’ gives you only points. You can find more plotting character options under ?pch.\n\nplot(mean~carat, data=price.per.carat, type='l')\n\n\n\n\n\n\n\n\nggplot With ggplot we specify that we want a line geometry only.\n\nggplot(price.per.carat, aes(x=carat, y=mean)) + geom_line()\n\n\n\n\n\n\n\n\nHow does this relationship change with cut of the diamond? First lets get the average price per combination of carat and cut.\n\nppc2 &lt;- dsmall %&gt;% group_by(cut, carat) %&gt;% summarise(mean = mean(price))\n\n`summarise()` has grouped output by 'cut'. You can override using the `.groups`\nargument.\n\n\nbase This plot can be created in base graphics, but it takes an advanced knowledge of the graphics system to do so. So I do not show it here.\nggplot This is where ggplot starts to excel in it’s ease of creating more complex plots. All we have to do is specify that we want the lines colored by the cut variable.\n\nggplot(ppc2, aes(x=carat, y=mean, col=cut)) + geom_line()\n\n\n\n\n\n\n\n\nAnd we get one line per cut.\n\n\n\n2.4.4 Continuous v. Categorical\nCreate an appropriate plot for a continuous variable, and plot it for each level of the categorical variable.\n\n2.4.4.1 Dotplot/strip chart\nDotplots can be very useful when plotting dots against several categories. They can also be called stripcharts.\nbase\n\nstripchart(carat ~ cut, data=dsmall)\n\n\n\n\n\n\n\n\nDoesn’t look to pretty, but kinda gets the point across. Few fair quality diamonds in the data set, pretty spread out across the carat range except one high end outlier.\nggplot We can reproduce the same thing by plotting one continuous variable against one categorical variable, and adding a layer of points. I’d argue that horizontal looks better due to the axis-labels.\n\nlibrary(gridExtra)\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\na &lt;- ggplot(dsmall, aes(y=carat, x=cut)) + geom_point()\nb &lt;- ggplot(dsmall, aes(y=cut, x=carat)) + geom_point()\ngrid.arrange(a, b, ncol=2)\n\n\n\n\n\n\n\n\n\n\n2.4.4.2 Grouped boxplots\nbase Base graphics plots grouped boxplots with also just the addition of a twiddle (tilde) ~. Another example of where model notation works.\n\nboxplot(carat~color, data=dsmall)\n\n\n\n\n\n\n\n\nggplot A simple addition, just define your x and y accordingly.\n\nggplot(dsmall, aes(x=color, y=carat, fill=color)) + geom_boxplot()\n\n\n\n\n\n\n\n\nAdding violins Violin plots can be overlaid here as well.\n\nggplot(dsmall, aes(x=color, y=carat, fill=color)) +\n        geom_violin(alpha=.1) + \n        geom_boxplot(alpha=.5, width=.2)\n\n\n\n\n\n\n\n\n\n\n2.4.4.3 Grouped histograms\nbase There is no easy way to create grouped histograms in base graphics we will skip it.\nggplot By default ggplot wants to overlay all plots on the same grid. This doesn’t look to good with histograms. Instead you can overlay density plots\n\na &lt;- ggplot(dsmall, aes(x=carat, fill=color)) + geom_histogram()\nb &lt;- ggplot(dsmall, aes(x=carat, fill=color)) + geom_density() \ngrid.arrange(a,b, ncol=2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThe solid fills are still difficult to read, so we can either turn down the alpha (turn up the transparency) or only color the lines and not the fill.\n\nc &lt;- ggplot(dsmall, aes(x=carat, fill=color)) + geom_density(alpha=.2)\nd &lt;- ggplot(dsmall, aes(x=carat, col=color)) + geom_density() \ngrid.arrange(c,d, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n2.4.5 Joy plots / Ridgelines\nSomewhat new (2017), joylines have not been added to the base distribution of ggplot2 yet. For now it’s available in the ggjoy package. Really good way to visualize density plots without the overlapping issue.\n\nlibrary(ggjoy)\n\nLoading required package: ggridges\n\n\nThe ggjoy package has been deprecated. Please switch over to the\nggridges package, which provides the same functionality. Porting\nguidelines can be found here:\nhttps://github.com/clauswilke/ggjoy/blob/master/README.md\n\nggplot(dsmall, aes(x=carat, y=color)) + geom_joy()\n\nPicking joint bandwidth of 0.165",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#faceting-paneling",
    "href": "data_viz.html#faceting-paneling",
    "title": "2  Visualizing Data",
    "section": "2.5 Faceting / paneling",
    "text": "2.5 Faceting / paneling\nThis is a good place to introduce a term called faceting. The definition is a particular aspect or feature of something, or one side of something many-sided, especially of a cut gem. Basically instead of plotting the grouped graphics on the same plotting area, we let each group have it’s own plot, or facet.\nWe add a facet_wrap() and specify that we want to panel on the color group. Note the twiddle in front of color.\n\nggplot(dsmall, aes(x=carat, fill=color)) + geom_density() + facet_wrap(~color)\n\n\n\n\n\n\n\n\nThe grid placement can be semi-controlled by using the ncol argument in the facet_wrap() statement.\n\nggplot(dsmall, aes(x=carat, fill=color)) + geom_density() + facet_wrap(~color, ncol=4)\n\n\n\n\n\n\n\n\nIt is important to compare distributions across groups on the same scale, and our eyes can compare items vertically better than horizontally. So let’s force ncol=1.\n\nggplot(dsmall, aes(x=carat, fill=color)) + geom_density() + facet_wrap(~color, ncol=1)",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#multiple-plots-per-window",
    "href": "data_viz.html#multiple-plots-per-window",
    "title": "2  Visualizing Data",
    "section": "2.6 Multiple plots per window",
    "text": "2.6 Multiple plots per window\nbase I use par(mfrow=c(r,c)) for base graphics, where r is the number of rows and c the number of columns.\n\npar(mfrow=c(1,3))\nplot(dsmall$carat)\nplot(dsmall$color)\nplot(dsmall$price ~ dsmall$carat)\n\n\n\n\n\n\n\n\nOther resources including learning about layouts. Multipanel plotting with base graphics http://seananderson.ca/courses/11-multipanel/multipanel.pdf\nggplot Use the grid.arrange function in the gridExtra package. I’ve done it several times above. You assign the output of a ggplot object to an object (here it’s plot1 and plot2). Then you use grid.arrange() to arrange them either side by side or top and bottom.\n\na &lt;- ggplot(dsmall, aes(x=carat, fill=color)) + geom_density(alpha=.2)\nb &lt;- ggplot(dsmall, aes(x=carat, col=color)) + geom_density() \ngrid.arrange(a,b, ncol=2)",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#multivariate-3-variables",
    "href": "data_viz.html#multivariate-3-variables",
    "title": "2  Visualizing Data",
    "section": "2.7 Multivariate (3+ variables)",
    "text": "2.7 Multivariate (3+ variables)\nThis is not much more complicated than taking an appropriate bivariate plot and adding a third variable through paneling, coloring, or changing a shape.\nThis is trivial to do in ggplot, not trivial in base graphics. So I won’t show those examples.\n\n2.7.1 Three continuous\nContinuous variables can also be mapped to the size of the point. Here I set the alpha on the points so we could see the overplotting (many points on a single spot). So the darker the spot the more data points on that spot.\n\nggplot(dsmall, aes(x=carat, y=price, size=depth)) + geom_point(alpha=.2)\n\n\n\n\n\n\n\n\n\n\n2.7.2 Scatterplot matrix\nA scatterplot matrix allows you to look at the bivariate comparison of multiple pairs of variables simultaneously. First we need to trim down the data set to only include the variables we want to plot, then we use the pairs() function.\n\nc.vars &lt;- dsmall[,c('carat', 'depth', 'price', 'x', 'y', 'z')]\npairs(c.vars)\n\n\n\n\n\n\n\n\nWe can see price has a non-linear relationship with X, Y and Z and x & y have a near perfect linear relationship.\n\n\n2.7.3 Two categorical and one continuous\nThis is very similar to side by side boxplots, one violin plot per cut, within each level of color. This is difficult to really see due to the large number of categories each factor has.\n\nggplot(dsmall, aes(x=color, y=price, fill=cut)) + geom_violin()\n\n\n\n\n\n\n\n\nBest bet here would be to panel on color and change the x axis to cut.\n\nggplot(dsmall, aes(x=cut, y=price, fill=cut)) + geom_violin() + facet_wrap(~color)\n\n\n\n\n\n\n\n\n\n\n2.7.4 Two continuous and one categorical\n\na &lt;- ggplot(dsmall, aes(x=carat, y=price, color=cut)) + geom_point() + ggtitle(\"Colored by cut\")\nd &lt;- ggplot(dsmall, aes(x=carat, y=price, color=cut)) + geom_point() + \n      geom_smooth(se=FALSE) +ggtitle(\"Lowess line per cut\")\ngrid.arrange(a, d, nrow=1)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nChange the shape\n\nggplot(dsmall, aes(x=carat, y=price, shape=cut)) + geom_point() + ggtitle(\"Shape by cut\")\n\nWarning: Using shapes for an ordinal variable is not advised\n\n\n\n\n\n\n\n\n\nOr we just panel by the third variable\n\nggplot(dsmall, aes(x=carat, y=price)) + geom_point() + facet_wrap(~cut)",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#paneling-on-two-variables",
    "href": "data_viz.html#paneling-on-two-variables",
    "title": "2  Visualizing Data",
    "section": "2.8 Paneling on two variables",
    "text": "2.8 Paneling on two variables\nWho says we’re stuck with only faceting on one variable? A variant on facet_wrap is facet_grid. Here we can specify multiple variables to panel on.\n\nggplot(dsmall, aes(x=carat, fill=color)) + geom_density() + facet_grid(cut~color)\n\n\n\n\n\n\n\n\nHow about plotting price against caret, for all combinations of color and clarity, with the points further separated by cut?\n\nggplot(dsmall, aes(x=carat, y=price, color=cut)) + geom_point() + facet_grid(clarity~color)\n\n\n\n\n\n\n\n\nAnd lastly let’s look back at how we can play with scatterplots of using a third categorical variable (using ggplot2 only). We can color the points by cut,\n\nggplot(dsmall, aes(x=carat, y=price, color=cut)) + geom_point()\n\n\n\n\n\n\n\n\nWe could add a smoothing lowess line for each cut separately,\n\nggplot(dsmall, aes(x=carat, y=price, color=cut)) + geom_point() + geom_smooth(se=FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe could change the color by clarity, and shape by cut.\n\nggplot(dsmall, aes(x=carat, y=price, color=clarity, shape=cut)) + geom_point() \n\nWarning: Using shapes for an ordinal variable is not advised\n\n\n\n\n\n\n\n\n\nThat’s pretty hard to read. So note that just because you can change an aesthetic, doesn’t mean you should. And just because you can plot things on the same axis, doesn’t mean you have to.\nBefore you share your plot with any other eyes, always take a step back and try to explain what it is telling you. If you have to take more than a minute to get to the point then it may be too complex and simpler graphics are likely warranted.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#troubleshooting",
    "href": "data_viz.html#troubleshooting",
    "title": "2  Visualizing Data",
    "section": "2.9 Troubleshooting",
    "text": "2.9 Troubleshooting\nProblem: Missing data showing up as a category in ggplot?\nGet rid of that far right bar!\n\nggplot(NCbirths, aes(x=marital)) + geom_bar()\n\n\n\n\n\n\n\n\nSolution: Use dplyr to select only the variables you are going to plot, then pipe in the na.omit() at the end. It will create a temporary data frame (e.g) plot.data that you then provide to ggplot().\n\nplot.data &lt;- NCbirths %&gt;% select(marital) %&gt;% na.omit()\nggplot(plot.data, aes(x=marital)) + geom_bar()\n\n\n\n\n\n\n\n\nProblem: Got numerical binary 0/1 data but want to plot it as categorical? &gt; Other related error messages: &gt; * Continuous x aesthetic – did you forget aes(group=…)?\nConsider a continuous variable for the number of characters in an email num_char, and a 0/1 binary variable spam.\nSolution: Create a second variable var_factor for plotting and keep the binary var as 0/1 for analysis.\n\nemail$spam_cat &lt;- factor(email$spam, labels=c(\"Ham\", \"Spam\"))\nggplot(email, aes(y=num_char, x=spam_cat)) + geom_boxplot()\n\n\n\n\n\n\n\n\nProblem: You want to change the legend title for a fill or color scale.\nSolution: Add the name= argument to whatever layer you added that created the legend. Here I speciefied a fill, and it was a discrete variable. So I use the scale_fill_discrete() layer.\n\nggplot(email, aes(y=num_char, x=spam_cat, fill=spam_cat)) + geom_boxplot() + \n  scale_fill_discrete(name=\"Ya like Spam?\")\n\n\n\n\n\n\n\n\nHere, I colored the points by a discrete variable, so the layer is scale_color_discrete().\n\nggplot(email, aes(x=num_char, y=line_breaks, col=spam_cat)) + geom_point() +\n  scale_color_discrete(name=\"Ya like Spam?\")\n\n\n\n\n\n\n\n\nProblem: You want to add means to boxplots. Boxplots are great. Even better with violin overlays. Know what makes them even better than butter? Adding a point for the mean. stat_summary is the layer you want to add. Check out this stack overflow post for more context.\n\nggplot(email, aes(x=spam_cat, y=num_char, fill=spam_cat)) +\n  geom_boxplot() +\n  stat_summary(fun.y=\"mean\", geom=\"point\", size=3, pch=17,color=\"blue\")\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\n\n\nI suggest playing around with size and plotting character pch to get a feel for how these work. You can also look at ?pch (and scroll down in the help file) to see the 25 default plotting characters.",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#but-what-about",
    "href": "data_viz.html#but-what-about",
    "title": "2  Visualizing Data",
    "section": "2.10 But what about…",
    "text": "2.10 But what about…\n\nLegend adjustment: remove it, move it to another side, rename it\nCustom specified colors and shapes\n\nGo here http://www.cookbook-r.com/Graphs/ for these.\n\n2.10.1 Other plots not mentioned\n\nHeat maps https://www.r-bloggers.com/how-to-make-a-simple-heatmap-in-ggplot2/\nWord clouds https://rpubs.com/brandonkopp/creating-word-clouds-in-r , simpler: http://dangoldin.com/2016/06/06/word-clouds-in-r/\nInteractive plots - Look into plotly() and ggplotly()\nthe circle type plots",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "data_viz.html#additional-resources",
    "href": "data_viz.html#additional-resources",
    "title": "2  Visualizing Data",
    "section": "2.11 Additional Resources",
    "text": "2.11 Additional Resources\nFor any Google Search - be sure to limit searches to within the past year or so. R packages get updated very frequently, and many functions change or become obsolete.\n\nR Graphics: https://www.stat.auckland.ac.nz/~paul/RGraphics/rgraphics.html The best book about using base graphics\nR Graphics Cookbook: http://www.cookbook-r.com/Graphs/ or http://amzn.com/1449316956 The best book for using ggplot2\nSTHDA: Statisical tools for high-throughput data analysis. http://www.sthda.com/english/\nQuick-R: Basic Graphs\nQuick-R: ggplot2\nBooks\n\nggplot2 http://ggplot2.org/book/ or http://amzn.com/0387981403\nqplot http://ggplot2.org/book/qplot.pdf\n\nHelp lists\n\nggplot2 mailing list http://groups.google.com/group/ggplot2\nstackoverflow http://stackoverflow.com/tags/ggplot2\nChico R users group",
    "crumbs": [
      "Preparing Data for Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  }
]